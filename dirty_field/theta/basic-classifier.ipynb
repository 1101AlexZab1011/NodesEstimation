{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/nilearn/datasets/__init__.py:86: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import re\n",
    "from abc import *\n",
    "from copy import deepcopy\n",
    "from operator import itemgetter\n",
    "from typing import *\n",
    "\n",
    "from networkx.algorithms.approximation import large_clique_size\n",
    "\n",
    "from nodestimation.learning.connectoming import *\n",
    "from nodestimation.learning.modification import normalize_df\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import mne\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors._dist_metrics import DistanceMetric\n",
    "from sklearn.utils import shuffle\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nodestimation.learning.estimation import collect_statistic, \\\n",
    "    compute_importance, collect_cross_statistic, make_selection_map, \\\n",
    "    select, separate_datasets, selected_statistic, choose_best, selected_data, make_feature_selection\n",
    "from nodestimation.learning.informativeness import CrossInformativeness, Informativeness, SubjectsInformativeness, \\\n",
    "    NodesInformativeness\n",
    "from nodestimation.learning.networking import sparse_graph, graph_to_hemispheres, hemispheres_division_modularity, \\\n",
    "    metric_for_hemispheres\n",
    "from nodestimation.processing.features import prepare_features\n",
    "from nodestimation.project import find_subject_dir, conditions_unique_code\n",
    "from nodestimation.pipeline import pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nibabel\n",
    "import nilearn.plotting as nplt\n",
    "from nodestimation.project.actions import read\n",
    "import nodestimation as nd\n",
    "from nodestimation.learning.modification import append_series, promote\n",
    "import nodestimation.learning.modification as lmd\n",
    "from nodestimation.project.subject import Subject\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib as mpl\n",
    "from nodestimation.learning.selection import SubjectsStatistic, Wilcoxon, Mannwhitneyu, Test\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "from scipy.fftpack import fftfreq, irfft, rfft"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SUBJECTS = pipeline(\n",
    "    methods=['wpli', 'envelope', 'coh', 'imcoh', 'plv', 'ciplv', 'ppc', 'pli', 'pli2_unbiased', 'wpli2_debiased'],\n",
    "    freq_bands=(4, 8),\n",
    "    centrality_metrics=['eigen', 'between', 'degree', 'info']\n",
    "    )\n",
    "\n",
    "ENGEL1 = [\n",
    "    'B1C2',\n",
    "    'B1R1',\n",
    "    'G1R1',\n",
    "    'G1V2',\n",
    "    'J1T2',\n",
    "    'K1V1',\n",
    "    'L1P1',\n",
    "    'M1G2',\n",
    "    'M1N2',\n",
    "    'O1O2',\n",
    "    'R1D2',\n",
    "    'S1A2',\n",
    "    'S1B1',\n",
    "    'S1H1',\n",
    "    'S1U3'\n",
    "]\n",
    "ENGEL2 = [\n",
    "    'L2M1',\n",
    "    'M2S2',\n",
    "    'N2K2',\n",
    "    'P1H2'\n",
    "]\n",
    "ENGEL34 = [\n",
    "    'N3S2',\n",
    "    'S3R1',\n",
    "    'K4L2'\n",
    "]\n",
    "REJECTED = [\n",
    "    'S1U3',\n",
    "    'P1H2'\n",
    "]\n",
    "\n",
    "INCLUDED = [\n",
    "    'B1R1',\n",
    "    'G1R1',\n",
    "    'G1V2',\n",
    "    'L1P1',\n",
    "    'M1G2',\n",
    "    'M1N2',\n",
    "    'O1O2',\n",
    "    'R1D2',\n",
    "]\n",
    "\n",
    "# subjects = SUBJECTS.copy()\n",
    "subjects = [\n",
    "        subject\n",
    "        for subject in SUBJECTS\n",
    "        if subject.name not in REJECTED\n",
    "           # and subject.name not in ENGEL34\n",
    "    ]\n",
    "\n",
    "STAT = SubjectsStatistic(\n",
    "    subjects,\n",
    "    'resected',\n",
    "    centrality_metric='eigen'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GRAPHS = [\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.cluster.transitivity),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.smetric.s_metric, normalized=False),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.global_efficiency),\n",
    "    # additional metrics\n",
    "    # metric: accuracy | specificity | sensitivity with Engel 1&2 groups\n",
    "    # metric_for_hemispheres(subjects, nx.algorithms.cluster.average_clustering, weight='weight'), # 51 | 52 | 57\n",
    "    # metric_for_hemispheres(subjects, large_clique_size), # 62 | 68 | 60\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 75% of engel 1 and 2 -> train set, 25% engel 1 and 2 -> test set, the rest -> test set\n",
    "\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "for dataset, name in zip(GRAPHS, ['transitivity', 's_metric', 'global_efficiency']):\n",
    "# for dataset, name in zip(GRAPHS, ['average_clustering']):\n",
    "    for _ in range(1000):\n",
    "\n",
    "        y = dataset['resected'].to_numpy()\n",
    "        index = dataset.index\n",
    "        x = dataset[[\n",
    "            f'{name}_for_wpli_4-8Hz',\n",
    "            f'{name}_for_envelope_4-8Hz'\n",
    "        ]].to_numpy()\n",
    "        scaler = StandardScaler()\n",
    "        x = scaler.fit_transform(x)\n",
    "        x_train, y_train = list(), list()\n",
    "        x_test, y_test = list(), list()\n",
    "        for i, sample, sample_name in zip(index, x, y):\n",
    "            if any([subject in i for subject in ENGEL1]):\n",
    "                    x_train.append(sample)\n",
    "                    y_train.append(sample_name)\n",
    "            else:\n",
    "                x_test.append(sample)\n",
    "                y_test.append(sample_name)\n",
    "\n",
    "        x_train, x_test1, y_train, y_test1 = train_test_split(x_train, y_train, train_size=0.5)\n",
    "\n",
    "        x_train = np.array(x_train)\n",
    "        x_test = np.array([*x_test, *x_test1])\n",
    "        y_test = np.array([*y_test, *y_test1])\n",
    "\n",
    "        # x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "        # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "        # clf = AdaBoostClassifier(n_estimators=10)\n",
    "        # clf = svm.SVC(kernel='sigmoid')\n",
    "        clf = svm.SVC()\n",
    "        # clf = svm.SVC(kernel='linear')\n",
    "        # clf = svm.SVC(kernel='poly')\n",
    "        # clf = SGDClassifier()\n",
    "        # clf = KNeighborsClassifier(n_neighbors=7, metric='chebyshev')\n",
    "        # clf = LogisticRegression(class_weight={True: 1, False: .8})\n",
    "        # clf = LogisticRegression()\n",
    "        # clf = RandomForestClassifier(max_depth=20)\n",
    "        # clf = GaussianNB()\n",
    "        # clf = LinearDiscriminantAnalysis()\n",
    "        # clf = QuadraticDiscriminantAnalysis()\n",
    "        # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "        # clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=[0,1]).ravel()\n",
    "        if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "            spec.append(tn / (tn + fp))\n",
    "            sens.append(tp / (tp + fn))\n",
    "            negpred.append(tn/(tn + fn))\n",
    "            pospred.append(tp/(tp + fp))\n",
    "    spec = [s for s in spec if not np.isnan(s)]\n",
    "    sens = [s for s in sens if not np.isnan(s)]\n",
    "    print(name)\n",
    "    print('acc: ', np.array(acc).mean())\n",
    "    print('spec: ', np.array(spec).mean())\n",
    "    print('sens: ', np.array(sens).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# features = ['4-8Hz_wpli', '4-8Hz_envelope']\n",
    "\n",
    "# features = ['4-8Hz_plv', '4-8Hz_envelope']\n",
    "#\n",
    "#\n",
    "# true_data = stat.datasets['true'][features]\n",
    "# false_data = stat.datasets['false_mirror'][features]\n",
    "#\n",
    "# engel_1_true = true_data.loc[(elem[:4] in ENGEL1 for elem in true_data.index)]\n",
    "# engel_1_false = false_data.loc[(elem[:4] in ENGEL1 for elem in false_data.index)]\n",
    "#\n",
    "# engel_2_3_4_true = true_data.loc[(elem[:4] not in ENGEL1 for elem in true_data.index)]\n",
    "# engel_2_3_4_false = false_data.loc[(elem[:4] not in ENGEL1 for elem in false_data.index)]\n",
    "#\n",
    "# engel_1_2_true = true_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] for elem in true_data.index)]\n",
    "# engel_1_2_false = false_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] for elem in false_data.index)]\n",
    "#\n",
    "# engel_3_4_true = true_data.loc[(elem[:4] not in [*ENGEL1, *ENGEL2] for elem in true_data.index)]\n",
    "# engel_3_4_false = false_data.loc[(elem[:4] not in [*ENGEL1, *ENGEL2] for elem in false_data.index)]\n",
    "#\n",
    "# engel_1 = pd.concat([engel_1_true, engel_1_false], axis=0)\n",
    "#\n",
    "# d1, d2 = np.array_split(engel_1.sample(frac=1), 2)\n",
    "#\n",
    "# d1\n",
    "\n",
    "path = f'/home/user//Documents/initial_stats.pkl'\n",
    "stats = pickle.load(open(path, 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eigen_stat = stats[0]\n",
    "perloc_stat = stats[-1]\n",
    "\n",
    "full_true_data_eigen = eigen_stat.datasets['true']['4-8Hz_wpli']\n",
    "full_true_data_perloc = perloc_stat.datasets['true']['4-8Hz_envelope']\n",
    "full_false_data_eigen = eigen_stat.datasets['false_mirror']['4-8Hz_wpli']\n",
    "full_false_data_perloc = perloc_stat.datasets['false_mirror']['4-8Hz_envelope']\n",
    "\n",
    "full_true_data = pd.concat([full_true_data_eigen, full_true_data_perloc], axis=1)\n",
    "\n",
    "full_false_data = pd.concat([full_false_data_eigen, full_false_data_perloc], axis=1)\n",
    "\n",
    "\n",
    "features = ['4-8Hz_envelope', '4-8Hz_wpli']\n",
    "\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "stat = deepcopy(STAT)\n",
    "\n",
    "for i in range(1000):\n",
    "    # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "    # clf = AdaBoostClassifier(n_estimators=10)\n",
    "    clf = svm.SVC(kernel='sigmoid')\n",
    "    # clf = svm.SVC()\n",
    "    # clf = svm.SVC(kernel='linear')\n",
    "    # clf = svm.SVC(kernel='poly')\n",
    "    # clf = SGDClassifier()\n",
    "    # clf = KNeighborsClassifier(n_neighbors=7, metric='chebyshev')\n",
    "    # clf = LogisticRegression(class_weight={True: 1, False: .8})\n",
    "    # clf = LogisticRegression()\n",
    "    # clf = RandomForestClassifier(max_depth=20)\n",
    "    # clf = GaussianNB()\n",
    "    # clf = LinearDiscriminantAnalysis()\n",
    "    # clf = QuadraticDiscriminantAnalysis()\n",
    "    # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "    # clf = MLPClassifier(alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # full_true_data = stat.datasets['true'][features]\n",
    "    # full_false_data = stat.datasets['false_mirror'][features]\n",
    "\n",
    "    ## All data\n",
    "    # true_data = full_true_data.assign(resected=True)\n",
    "    # false_data = full_false_data.assign(resected=False)\n",
    "\n",
    "    ## Engel1 only\n",
    "    # engel_1_true = full_true_data.loc[(elem[:4] in ENGEL1 for elem in full_true_data.index)]\n",
    "    # engel_1_false = full_false_data.loc[(elem[:4] in ENGEL1 for elem in full_false_data.index)]\n",
    "    # true_data = engel_1_true.assign(resected=True)\n",
    "    # false_data = engel_1_false.assign(resected=False)\n",
    "\n",
    "    ## Engel1&2 data\n",
    "    engel_1_2_true = full_true_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_true_data.index)]\n",
    "    engel_1_2_false = full_false_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_false_data.index)]\n",
    "    true_data = engel_1_2_true.assign(resected=True)\n",
    "    false_data = engel_1_2_false.assign(resected=False)\n",
    "\n",
    "    dataset = pd.concat([true_data, false_data], axis=0)\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "\n",
    "    y = dataset['resected'].to_numpy()\n",
    "    dataset = dataset.drop(['resected'], axis=1)\n",
    "    x = scaler.fit_transform(dataset)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    ## Engel1 - train, the rest - test\n",
    "    # engel_1_true = full_true_data.loc[(elem[:4] in ENGEL1 and not elem[:4] in REJECTED for elem in full_true_data.index)].assign(resected=True)\n",
    "    # engel_1_false = full_false_data.loc[(elem[:4] in ENGEL1 and not elem[:4] in REJECTED for elem in full_false_data.index)].assign(resected=False)\n",
    "    # engel_2_3_4_true = full_true_data\\\n",
    "    #     .loc[(elem[:4] not in ENGEL1 and not elem[:4] in REJECTED for elem in full_true_data.index)].assign(resected=True)\n",
    "    # engel_2_3_4_false = full_false_data\\\n",
    "    #     .loc[(elem[:4] not in ENGEL1 and not elem[:4] in REJECTED for elem in full_false_data.index)].assign(resected=False)\n",
    "    # engel_1 = pd.concat([engel_1_true, engel_1_false], axis=0)\n",
    "    # engel_1_train, engel_1_test = np.array_split(engel_1.sample(frac=1), 2)\n",
    "    # engel_2_3_4 = pd.concat([engel_2_3_4_true, engel_2_3_4_false], axis=0)\n",
    "    #\n",
    "    # y_train = engel_1_train['resected'].to_numpy()\n",
    "    # x_train = scaler.fit_transform(engel_1_train.drop(['resected'], axis=1))\n",
    "    #\n",
    "    # engel_test = pd.concat([engel_2_3_4, engel_1_test], axis=0).sample(frac=1)\n",
    "    #\n",
    "    # y_test = engel_test['resected'].to_numpy()\n",
    "    # x_test = scaler.fit_transform(engel_test.drop(['resected'], axis=1))\n",
    "\n",
    "\n",
    "    # # Engel1&2 - train, the rest - test\n",
    "    # engel_1_2_true = full_true_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_true_data.index)].assign(resected=True)\n",
    "    # engel_1_2_false = full_false_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_false_data.index)].assign(resected=False)\n",
    "    # engel_3_4_true = full_true_data\\\n",
    "    #     .loc[(elem[:4] not in [*ENGEL1, *ENGEL2, *REJECTED] for elem in full_true_data.index)].assign(resected=True)\n",
    "    # engel_3_4_false = full_false_data\\\n",
    "    #     .loc[(elem[:4] not in [*ENGEL1, *ENGEL2, *REJECTED] for elem in full_false_data.index)].assign(resected=False)\n",
    "    # engel_1_2 = pd.concat([engel_1_2_true, engel_1_2_false], axis=0)\n",
    "    # engel_1_2_train, engel_1_2_test = np.array_split(engel_1_2.sample(frac=1), 2)\n",
    "    # engel_3_4 = pd.concat([engel_3_4_true, engel_3_4_false], axis=0)\n",
    "    #\n",
    "    # y_train = engel_1_2_train['resected'].to_numpy()\n",
    "    # x_train = scaler.fit_transform(engel_1_2_train.drop(['resected'], axis=1))\n",
    "    #\n",
    "    # engel_test = pd.concat([engel_3_4, engel_1_2_test], axis=0).sample(frac=1)\n",
    "    #\n",
    "    # y_test = engel_test['resected'].to_numpy()\n",
    "    # x_test = scaler.fit_transform(engel_test.drop(['resected'], axis=1))\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    acc.append(accuracy_score(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=[0,1]).ravel()\n",
    "    if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "        spec.append(tn / (tn + fp))\n",
    "        sens.append(tp / (tp + fn))\n",
    "        negpred.append(tn/(tn + fn))\n",
    "        pospred.append(tp/(tp + fp))\n",
    "\n",
    "print('acc: ', np.array(acc).mean())\n",
    "print('spec: ', np.array(spec).mean())\n",
    "print('sens: ', np.array(sens).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(stats[-2])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## check all possible combinations of features (nodes)\n",
    "\n",
    "\n",
    "index = [stat.centrality_metric for stat in stats]\n",
    "\n",
    "for feat in ['wpli', 'coh', 'imcoh', 'plv', 'ciplv', 'ppc', 'pli', 'pli2_unbiased', 'wpli2_debiased']:\n",
    "    series = list()\n",
    "    for stat1 in stats:\n",
    "        curr_series = list()\n",
    "        for stat2 in stats:\n",
    "            full_true_data_1 = stat1.datasets['true'][f'4-8Hz_{feat}']\n",
    "            full_true_data_2 = stat2.datasets['true']['4-8Hz_envelope']\n",
    "            full_false_data_1 = stat1.datasets['false_mirror'][f'4-8Hz_{feat}']\n",
    "            full_false_data_2 = stat2.datasets['false_mirror']['4-8Hz_envelope']\n",
    "\n",
    "            full_true_data = pd.concat([full_true_data_1, full_true_data_2], axis=1)\n",
    "\n",
    "            full_false_data = pd.concat([full_false_data_1, full_false_data_2], axis=1)\n",
    "\n",
    "\n",
    "            features = ['4-8Hz_envelope', f'4-8Hz_{feat}']\n",
    "\n",
    "            acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "            for i in range(1000):\n",
    "                clf = svm.SVC(kernel='sigmoid')\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "\n",
    "                ## Engel1&2 data\n",
    "                engel_1_2_true = full_true_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_true_data.index)]\n",
    "                engel_1_2_false = full_false_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_false_data.index)]\n",
    "                true_data = engel_1_2_true.assign(resected=True)\n",
    "                false_data = engel_1_2_false.assign(resected=False)\n",
    "\n",
    "                dataset = pd.concat([true_data, false_data], axis=0)\n",
    "                dataset = dataset.sample(frac = 1)\n",
    "\n",
    "                y = dataset['resected'].to_numpy()\n",
    "                dataset = dataset.drop(['resected'], axis=1)\n",
    "                x = scaler.fit_transform(dataset)\n",
    "                x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "                clf.fit(x_train, y_train)\n",
    "                pred = clf.predict(x_test)\n",
    "\n",
    "                acc.append(accuracy_score(y_test, pred))\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=[0,1]).ravel()\n",
    "                if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "                    spec.append(tn / (tn + fp))\n",
    "                    sens.append(tp / (tp + fn))\n",
    "                    negpred.append(tn/(tn + fn))\n",
    "                    pospred.append(tp/(tp + fp))\n",
    "\n",
    "            curr_series.append(np.array(acc).mean())\n",
    "            # print(f'{stat1.centrality_metric} for {features[1]},\\n{stat2.centrality_metric} for {features[0]}')\n",
    "            # print('acc: ', np.array(acc).mean())\n",
    "            # print('spec: ', np.array(spec).mean())\n",
    "            # print('sens: ', np.array(sens).mean())\n",
    "        series.append(pd.Series(curr_series))\n",
    "\n",
    "    df = pd.DataFrame(series, index=index).rename(columns={i: col for i, col in enumerate(index)})\n",
    "    df.to_csv(f'/home/user/Documents/metrics_accuracy_{feat}.csv')\n",
    "    print(f'{features[1]}|{features[0]}')\n",
    "    print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "subjects = [subject for subject in SUBJECTS if subject.name in [*ENGEL1, *ENGEL2]]\n",
    "GRAPHS = [\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.cluster.transitivity),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.smetric.s_metric, normalized=False),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.global_efficiency),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.cluster.average_clustering, weight='weight'),\n",
    "\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "# print(GRAPHS[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transitivity_for_wpli_4-8Hz,\n",
      "transitivity_for_envelope_4-8Hz\n",
      "acc:  0.7334444444444445\n",
      "spec:  0.7852042518709186\n",
      "sens:  0.7120656370656371\n",
      "transitivity_for_wpli_4-8Hz,\n",
      "s_metric_for_envelope_4-8Hz\n",
      "acc:  0.7592222222222221\n",
      "spec:  0.7815601566604576\n",
      "sens:  0.7581470602283039\n",
      "transitivity_for_wpli_4-8Hz,\n",
      "global_efficiency_for_envelope_4-8Hz\n",
      "acc:  0.759\n",
      "spec:  0.7878187711521045\n",
      "sens:  0.7568854568854568\n",
      "transitivity_for_wpli_4-8Hz,\n",
      "average_clustering_for_envelope_4-8Hz\n",
      "acc:  0.6862222222222223\n",
      "spec:  0.7661181373958033\n",
      "sens:  0.6344327871993868\n",
      "s_metric_for_wpli_4-8Hz,\n",
      "transitivity_for_envelope_4-8Hz\n",
      "acc:  0.7348888888888889\n",
      "spec:  0.806215601818617\n",
      "sens:  0.6897858339315627\n",
      "s_metric_for_wpli_4-8Hz,\n",
      "s_metric_for_envelope_4-8Hz\n",
      "acc:  0.7515555555555556\n",
      "spec:  0.7938028370826766\n",
      "sens:  0.728167836843865\n",
      "s_metric_for_wpli_4-8Hz,\n",
      "global_efficiency_for_envelope_4-8Hz\n",
      "acc:  0.7507777777777779\n",
      "spec:  0.7902660362038497\n",
      "sens:  0.7411806849118784\n",
      "s_metric_for_wpli_4-8Hz,\n",
      "average_clustering_for_envelope_4-8Hz\n",
      "acc:  0.6828888888888889\n",
      "spec:  0.8146499734645631\n",
      "sens:  0.5903097409176438\n",
      "global_efficiency_for_wpli_4-8Hz,\n",
      "transitivity_for_envelope_4-8Hz\n",
      "acc:  0.7313333333333335\n",
      "spec:  0.7612569324918722\n",
      "sens:  0.7378537961369287\n",
      "global_efficiency_for_wpli_4-8Hz,\n",
      "s_metric_for_envelope_4-8Hz\n",
      "acc:  0.7384444444444445\n",
      "spec:  0.7871490538157204\n",
      "sens:  0.7126114209447542\n",
      "global_efficiency_for_wpli_4-8Hz,\n",
      "global_efficiency_for_envelope_4-8Hz\n",
      "acc:  0.7564444444444445\n",
      "spec:  0.8068906578695736\n",
      "sens:  0.7338329508510232\n",
      "global_efficiency_for_wpli_4-8Hz,\n",
      "average_clustering_for_envelope_4-8Hz\n",
      "acc:  0.6924444444444443\n",
      "spec:  0.7957703927492448\n",
      "sens:  0.6320457488131204\n",
      "average_clustering_for_wpli_4-8Hz,\n",
      "transitivity_for_envelope_4-8Hz\n",
      "acc:  0.6662222222222222\n",
      "spec:  0.7148203375036369\n",
      "sens:  0.6782538066142955\n",
      "average_clustering_for_wpli_4-8Hz,\n",
      "s_metric_for_envelope_4-8Hz\n",
      "acc:  0.7081111111111111\n",
      "spec:  0.6785331803404093\n",
      "sens:  0.768864744693058\n",
      "average_clustering_for_wpli_4-8Hz,\n",
      "global_efficiency_for_envelope_4-8Hz\n",
      "acc:  0.7416666666666667\n",
      "spec:  0.709189661780205\n",
      "sens:  0.8131838650953339\n",
      "average_clustering_for_wpli_4-8Hz,\n",
      "average_clustering_for_envelope_4-8Hz\n",
      "acc:  0.5081111111111111\n",
      "spec:  0.6547095340282035\n",
      "sens:  0.43002120376047415\n",
      "average_clustering_for_wpli_4-8Hz|average_clustering_for_envelope_4-8Hz\n",
      "                    transitivity  s_metric  global_efficiency  \\\n",
      "transitivity            0.733444  0.759222           0.759000   \n",
      "s_metric                0.734889  0.751556           0.750778   \n",
      "global_efficiency       0.731333  0.738444           0.756444   \n",
      "average_clustering      0.666222  0.708111           0.741667   \n",
      "\n",
      "                    average_clustering  \n",
      "transitivity                  0.686222  \n",
      "s_metric                      0.682889  \n",
      "global_efficiency             0.692444  \n",
      "average_clustering            0.508111  \n"
     ]
    }
   ],
   "source": [
    "## check all possible combinations of features (hemispheres)\n",
    "index = ['transitivity', 's_metric', 'global_efficiency', 'average_clustering']\n",
    "features = ['wpli', 'coh', 'imcoh', 'plv', 'ciplv', 'ppc', 'pli', 'pli2_unbiased', 'wpli2_debiased']\n",
    "\n",
    "\n",
    "for feat in [features[0]]:\n",
    "    series = list()\n",
    "    for graph1, kind1 in zip(GRAPHS, index):\n",
    "        curr_series = list()\n",
    "        for graph2, kind2 in zip(GRAPHS, index):\n",
    "            assert all(graph1['resected'] == graph2['resected'])\n",
    "            full_data_1 = graph1[[f'{kind1}_for_{feat}_4-8Hz', 'resected']]\n",
    "            full_data_2 = graph2[[f'{kind2}_for_envelope_4-8Hz']]\n",
    "            full_data = pd.concat([full_data_1, full_data_2], axis=1)\n",
    "            features = [f'{kind2}_for_envelope_4-8Hz', f'{kind1}_for_{feat}_4-8Hz']\n",
    "\n",
    "            acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "            for i in range(1000):\n",
    "                clf = svm.SVC(kernel='sigmoid')\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "\n",
    "                ## Engel1&2 data\n",
    "                engel_1_2 = full_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_data.index)]\n",
    "\n",
    "                dataset = engel_1_2.sample(frac = 1)\n",
    "                y = dataset['resected'].to_numpy()\n",
    "                dataset = dataset.drop(['resected'], axis=1)\n",
    "                x = scaler.fit_transform(dataset)\n",
    "                x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "                clf.fit(x_train, y_train)\n",
    "                pred = clf.predict(x_test)\n",
    "\n",
    "                acc.append(accuracy_score(y_test, pred))\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=[0,1]).ravel()\n",
    "                if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "                    spec.append(tn / (tn + fp))\n",
    "                    sens.append(tp / (tp + fn))\n",
    "                    negpred.append(tn/(tn + fn))\n",
    "                    pospred.append(tp/(tp + fp))\n",
    "\n",
    "            curr_series.append(np.array(acc).mean())\n",
    "            print(f'{features[1]},\\n{features[0]}')\n",
    "            print('acc: ', np.array(acc).mean())\n",
    "            print('spec: ', np.array(spec).mean())\n",
    "            print('sens: ', np.array(sens).mean())\n",
    "        series.append(pd.Series(curr_series))\n",
    "\n",
    "    df = pd.DataFrame(series, index=index).rename(columns={i: col for i, col in enumerate(index)})\n",
    "    df.to_csv(f'/home/user/Documents/hemispheres_metrics_accuracy_{feat}.csv')\n",
    "    print(f'{features[1]}|{features[0]}')\n",
    "    print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# wpli + transitivity & envelope + global efficiency\n",
    "\n",
    "subjects = [subject for subject in SUBJECTS if subject.name not in REJECTED]\n",
    "GRAPHS = [\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.cluster.transitivity),\n",
    "    # metric_for_hemispheres(subjects, nx.algorithms.smetric.s_metric, normalized=False),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.global_efficiency),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wpli = GRAPHS[0]['transitivity_for_wpli_4-8Hz']\n",
    "envelope = GRAPHS[1]['global_efficiency_for_envelope_4-8Hz']\n",
    "assert all(GRAPHS[0]['resected'] == GRAPHS[1]['resected'])\n",
    "labels = GRAPHS[0]['resected']\n",
    "dataset = pd.concat([wpli, envelope, labels], axis=1)\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "for _ in range(1000):\n",
    "    # Engel 1&2\n",
    "    engel_1_2 = dataset.copy().loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in dataset.index)]\n",
    "    engel_1_2 = engel_1_2.sample(frac=1)\n",
    "    y = engel_1_2['resected'].to_numpy()\n",
    "    x = engel_1_2.drop('resected', axis=1).to_numpy()\n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.5)\n",
    "    # Engel 3&4\n",
    "    engel_3_4 = dataset.copy().loc[(elem[:4] in [*ENGEL34] and not elem[:4] in REJECTED for elem in dataset.index)].sample(frac=1)\n",
    "    y_engel_3_4 = engel_3_4['resected'].to_numpy()\n",
    "    x_engel_3_4 = engel_3_4.drop('resected', axis=1).to_numpy()\n",
    "    x_test = np.append(x_test, x_engel_3_4, axis=0)\n",
    "    y_test = np.append(y_test, y_engel_3_4, axis=0)\n",
    "\n",
    "\n",
    "    clf = svm.SVC(kernel='sigmoid')\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    # print(pred)\n",
    "\n",
    "    acc.append(accuracy_score(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=[0,1]).ravel()\n",
    "    if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "        spec.append(tn / (tn + fp))\n",
    "        sens.append(tp / (tp + fn))\n",
    "        negpred.append(tn/(tn + fn))\n",
    "        pospred.append(tp/(tp + fp))\n",
    "spec = [s for s in spec if not np.isnan(s)]\n",
    "sens = [s for s in sens if not np.isnan(s)]\n",
    "print('acc: ', np.array(acc).mean())\n",
    "print('spec: ', np.array(spec).mean())\n",
    "print('sens: ', np.array(sens).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "# regions wpli+eigen & envelope+percolation\n",
    "\n",
    "path = f'/home/user//Documents/initial_stats.pkl'\n",
    "stats = pickle.load(open(path, 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.5545774647887324\n",
      "spec:  0.5759884235299025\n",
      "sens:  0.5501672975761028\n"
     ]
    }
   ],
   "source": [
    "stat1 = stats[0]\n",
    "stat2 = stats[-1]\n",
    "\n",
    "full_true_data_1 = stat1.datasets['true']['4-8Hz_wpli']\n",
    "full_true_data_2 = stat2.datasets['true']['4-8Hz_envelope']\n",
    "full_false_data_1 = stat1.datasets['false_mirror']['4-8Hz_wpli']\n",
    "full_false_data_2 = stat2.datasets['false_mirror']['4-8Hz_envelope']\n",
    "\n",
    "full_true_data = pd.concat([full_true_data_1, full_true_data_2], axis=1)\n",
    "\n",
    "full_false_data = pd.concat([full_false_data_1, full_false_data_2], axis=1)\n",
    "\n",
    "\n",
    "features = ['4-8Hz_envelope', '4-8Hz_wpli']\n",
    "\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    clf = svm.SVC(kernel='sigmoid')\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    ## All data\n",
    "    # true_data = full_true_data.assign(resected=True)\n",
    "    # false_data = full_false_data.assign(resected=False)\n",
    "\n",
    "    ## Engel1 only\n",
    "    # engel_1_true = full_true_data.loc[(elem[:4] in ENGEL1 for elem in full_true_data.index)]\n",
    "    # engel_1_false = full_false_data.loc[(elem[:4] in ENGEL1 for elem in full_false_data.index)]\n",
    "    # true_data = engel_1_true.assign(resected=True)\n",
    "    # false_data = engel_1_false.assign(resected=False)\n",
    "\n",
    "    ## Engel1&2 data\n",
    "    # engel_1_2_true = full_true_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_true_data.index)]\n",
    "    # engel_1_2_false = full_false_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_false_data.index)]\n",
    "    # true_data = engel_1_2_true.assign(resected=True)\n",
    "    # false_data = engel_1_2_false.assign(resected=False)\n",
    "    #\n",
    "    # dataset = pd.concat([true_data, false_data], axis=0)\n",
    "    # dataset = dataset.sample(frac = 1)\n",
    "    #\n",
    "    # y = dataset['resected'].to_numpy()\n",
    "    # dataset = dataset.drop(['resected'], axis=1)\n",
    "    # x = scaler.fit_transform(dataset)\n",
    "    # x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    # Engel1 - train, the rest - test\n",
    "    engel_1_true = full_true_data.loc[(elem[:4] in ENGEL1 and not elem[:4] in REJECTED for elem in full_true_data.index)].assign(resected=True)\n",
    "    engel_1_false = full_false_data.loc[(elem[:4] in ENGEL1 and not elem[:4] in REJECTED for elem in full_false_data.index)].assign(resected=False)\n",
    "    engel_2_3_4_true = full_true_data\\\n",
    "        .loc[(elem[:4] not in ENGEL1 and not elem[:4] in REJECTED for elem in full_true_data.index)].assign(resected=True)\n",
    "    engel_2_3_4_false = full_false_data\\\n",
    "        .loc[(elem[:4] not in ENGEL1 and not elem[:4] in REJECTED for elem in full_false_data.index)].assign(resected=False)\n",
    "    engel_1 = pd.concat([engel_1_true, engel_1_false], axis=0)\n",
    "    engel_1_train, engel_1_test = np.array_split(engel_1.sample(frac=1), 2)\n",
    "    engel_2_3_4 = pd.concat([engel_2_3_4_true, engel_2_3_4_false], axis=0)\n",
    "\n",
    "    y_train = engel_1_train['resected'].to_numpy()\n",
    "    x_train = scaler.fit_transform(engel_1_train.drop(['resected'], axis=1))\n",
    "\n",
    "    engel_test = pd.concat([engel_2_3_4, engel_1_test], axis=0).sample(frac=1)\n",
    "\n",
    "    y_test = engel_test['resected'].to_numpy()\n",
    "    x_test = scaler.fit_transform(engel_test.drop(['resected'], axis=1))\n",
    "\n",
    "\n",
    "    # # Engel1&2 - train, the rest - test\n",
    "    # engel_1_2_true = full_true_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_true_data.index)].assign(resected=True)\n",
    "    # engel_1_2_false = full_false_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_false_data.index)].assign(resected=False)\n",
    "    # engel_3_4_true = full_true_data\\\n",
    "    #     .loc[(elem[:4] not in [*ENGEL1, *ENGEL2, *REJECTED] for elem in full_true_data.index)].assign(resected=True)\n",
    "    # engel_3_4_false = full_false_data\\\n",
    "    #     .loc[(elem[:4] not in [*ENGEL1, *ENGEL2, *REJECTED] for elem in full_false_data.index)].assign(resected=False)\n",
    "    # engel_1_2 = pd.concat([engel_1_2_true, engel_1_2_false], axis=0)\n",
    "    # engel_1_2_train, engel_1_2_test = np.array_split(engel_1_2.sample(frac=1), 2)\n",
    "    # engel_3_4 = pd.concat([engel_3_4_true, engel_3_4_false], axis=0)\n",
    "    #\n",
    "    # y_train = engel_1_2_train['resected'].to_numpy()\n",
    "    # x_train = scaler.fit_transform(engel_1_2_train.drop(['resected'], axis=1))\n",
    "    #\n",
    "    # engel_test = pd.concat([engel_3_4, engel_1_2_test], axis=0).sample(frac=1)\n",
    "    #\n",
    "    # y_test = engel_test['resected'].to_numpy()\n",
    "    # x_test = scaler.fit_transform(engel_test.drop(['resected'], axis=1))\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    acc.append(accuracy_score(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=[0,1]).ravel()\n",
    "    if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "        spec.append(tn / (tn + fp))\n",
    "        sens.append(tp / (tp + fn))\n",
    "        negpred.append(tn/(tn + fn))\n",
    "        pospred.append(tp/(tp + fp))\n",
    "\n",
    "print('acc: ', np.array(acc).mean())\n",
    "print('spec: ', np.array(spec).mean())\n",
    "print('sens: ', np.array(sens).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rois = [50, 77, 74, 72, 50, 57, 57, 62, 64, 54, 56, 17, 50, 88, 55, 57, 40,]# 39, 63, 41]\n",
    "hemis = [59, 95, 98, 50, 48, 48, 97, 73, 93, 95, 96, 36, 72, 45, 64, 68, 60,]# 3, 71, 41]\n",
    "\n",
    "# plt.plot(rois, hemis, 'x')\n",
    "# plt.show()\n",
    "plt.plot(hemis, rois, 'x')\n",
    "plt.xlabel('Hemispheres accuracy, %')\n",
    "plt.ylabel('ROIs accuracy, %')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.29839908228635526, pvalue=0.2446825909683375)\n",
      "(0.31864598766929964, 0.21256350182108505)\n"
     ]
    }
   ],
   "source": [
    "print(sp.stats.spearmanr(rois, hemis))\n",
    "print(sp.stats.pearsonr(rois, hemis))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}