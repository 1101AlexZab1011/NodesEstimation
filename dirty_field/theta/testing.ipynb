{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All computation has been already done, loading of the existing file with the solution...\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import pickle\n",
    "import re\n",
    "from abc import *\n",
    "from copy import deepcopy\n",
    "from operator import itemgetter\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import mne\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors._dist_metrics import DistanceMetric\n",
    "from sklearn.utils import shuffle\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nodestimation.learning.connectoming import make_connectome\n",
    "from nodestimation.learning.estimation import collect_statistic, \\\n",
    "    compute_importance, collect_cross_statistic, make_selection_map, \\\n",
    "    select, separate_datasets, selected_statistic, choose_best, selected_data, make_feature_selection\n",
    "from nodestimation.learning.informativeness import CrossInformativeness, Informativeness, SubjectsInformativeness, \\\n",
    "    NodesInformativeness\n",
    "from nodestimation.learning.networking import sparse_graph, graph_to_hemispheres, hemispheres_division_modularity, \\\n",
    "    metric_for_hemispheres\n",
    "from nodestimation.processing.features import prepare_features\n",
    "from nodestimation.project import find_subject_dir, conditions_unique_code\n",
    "from nodestimation.pipeline import pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nibabel\n",
    "import nilearn.plotting as nplt\n",
    "from nodestimation.project.actions import read\n",
    "import nodestimation as nd\n",
    "from nodestimation.learning.modification import append_series, promote\n",
    "import nodestimation.learning.modification as lmd\n",
    "from nodestimation.project.subject import Subject\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib as mpl\n",
    "from nodestimation.learning.selection import SubjectsStatistic, Wilcoxon, Mannwhitneyu, Test\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "\n",
    "ENGEL1 = [\n",
    "    'B1C2',\n",
    "    'B1R1',\n",
    "    'G1R1',\n",
    "    'G1V2',\n",
    "    'J1T2',\n",
    "    'K1V1',\n",
    "    'L1P1',\n",
    "    'M1G2',\n",
    "    'M1N2',\n",
    "    'O1O2',\n",
    "    'R1D2',\n",
    "    'S1A2',\n",
    "    'S1B1',\n",
    "    'S1H1',\n",
    "    'S1U3'\n",
    "]\n",
    "ENGEL2 = [\n",
    "    'L2M1',\n",
    "    'M2S2',\n",
    "    'N2K2',\n",
    "    'P1H2'\n",
    "]\n",
    "ENGEL3 = [\n",
    "    'N3S2',\n",
    "    'S3R1'\n",
    "]\n",
    "ENGEL4 = [\n",
    "    'K4L2'\n",
    "]\n",
    "REJECTED = [\n",
    "    'S1U3',\n",
    "    'P1H2'\n",
    "]\n",
    "\n",
    "AGE = {\n",
    "    'B1C2': 28.0,\n",
    "    'B1R1': 16.0,\n",
    "    'G1R1': 23.0,\n",
    "    'G1V2': 5.0,\n",
    "    'J1T2': 8.0,\n",
    "    'K1V1': 10.0,\n",
    "    'K4L2': 14.0,\n",
    "    'L1P1': 16.0,\n",
    "    'L2M1': 20.0,\n",
    "    'M1G2': 8.0,\n",
    "    'M1N2': 7.0,\n",
    "    'M2S2': 18.0,\n",
    "    'N2K2': 30.0,\n",
    "    'N3S2': 10.0,\n",
    "    'O1O2': 18.0,\n",
    "    'R1D2': 6.5,\n",
    "    'P1H2': 7.0,\n",
    "    'S1A2': 12.0,\n",
    "    'S1B1': 17.0,\n",
    "    'S1H1': 28.0,\n",
    "    'S3R1': 19.0,\n",
    "    'S1U3': 15.0,\n",
    "}\n",
    "\n",
    "SEX = {\n",
    "    'B1C2': 'f',\n",
    "    'B1R1': 'm',\n",
    "    'G1R1': 'f',\n",
    "    'G1V2': 'm',\n",
    "    'J1T2': 'f',\n",
    "    'K1V1': 'f',\n",
    "    'K4L2': 'f',\n",
    "    'L1P1': 'f',\n",
    "    'L2M1': 'f',\n",
    "    'M1G2': 'm',\n",
    "    'M1N2': 'm',\n",
    "    'M2S2': 'm',\n",
    "    'N2K2': 'm',\n",
    "    'N3S2': 'm',\n",
    "    'O1O2': 'f',\n",
    "    'R1D2': 'f',\n",
    "    'P1H2': 'm',\n",
    "    'S1A2': 'm',\n",
    "    'S1B1': 'm',\n",
    "    'S1H1': 'm',\n",
    "    'S3R1': 'm',\n",
    "    'S1U3': 'f',\n",
    "}\n",
    "\n",
    "SUBJECTS = pipeline(\n",
    "    methods=['wpli', 'envelope', 'coh', 'imcoh', 'plv', 'ciplv', 'ppc', 'pli', 'pli2_unbiased', 'wpli2_debiased'],\n",
    "    freq_bands=(4, 8),\n",
    "    centrality_metrics=['eigen', 'between', 'degree', 'info']\n",
    "    )\n",
    "\n",
    "CONNECTOMES_KIND = 'initial'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connectomes are prepared\n"
     ]
    }
   ],
   "source": [
    "subjects = SUBJECTS.copy()\n",
    "\n",
    "DATASETS = {\n",
    "    subject.name: {\n",
    "        freq: {\n",
    "            method: make_connectome(subject, freq, method, CONNECTOMES_KIND, threshold=1)\n",
    "           for method in subject.connectomes[freq]\n",
    "        }\n",
    "        for freq in subject.connectomes\n",
    "    }\n",
    "    for subject in subjects if subject.name in [*ENGEL1, *ENGEL2]\n",
    "}\n",
    "print('Connectomes are prepared')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GRAPHS = [\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.cluster.transitivity),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.smetric.s_metric, normalized=False),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.global_efficiency),\n",
    "]\n",
    "print('Graphs are prepared')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing centrality...\n",
      "P1H2 4-8Hz wpli\n",
      "P1H2 4-8Hz envelope\n",
      "P1H2 4-8Hz coh\n",
      "P1H2 4-8Hz imcoh\n",
      "P1H2 4-8Hz plv\n",
      "P1H2 4-8Hz ciplv\n",
      "P1H2 4-8Hz ppc\n",
      "P1H2 4-8Hz pli\n",
      "P1H2 4-8Hz pli2_unbiased\n",
      "P1H2 4-8Hz wpli2_debiased\n",
      "M2S2 4-8Hz wpli\n",
      "M2S2 4-8Hz envelope\n",
      "M2S2 4-8Hz coh\n",
      "M2S2 4-8Hz imcoh\n",
      "M2S2 4-8Hz plv\n",
      "M2S2 4-8Hz ciplv\n",
      "M2S2 4-8Hz ppc\n",
      "M2S2 4-8Hz pli\n",
      "M2S2 4-8Hz pli2_unbiased\n",
      "M2S2 4-8Hz wpli2_debiased\n",
      "R1D2 4-8Hz wpli\n",
      "R1D2 4-8Hz envelope\n",
      "R1D2 4-8Hz coh\n",
      "R1D2 4-8Hz imcoh\n",
      "R1D2 4-8Hz plv\n",
      "R1D2 4-8Hz ciplv\n",
      "R1D2 4-8Hz ppc\n",
      "R1D2 4-8Hz pli\n",
      "R1D2 4-8Hz pli2_unbiased\n",
      "R1D2 4-8Hz wpli2_debiased\n",
      "S1A2 4-8Hz wpli\n",
      "S1A2 4-8Hz envelope\n",
      "S1A2 4-8Hz coh\n",
      "S1A2 4-8Hz imcoh\n",
      "S1A2 4-8Hz plv\n",
      "S1A2 4-8Hz ciplv\n",
      "S1A2 4-8Hz ppc\n",
      "S1A2 4-8Hz pli\n",
      "S1A2 4-8Hz pli2_unbiased\n",
      "S1A2 4-8Hz wpli2_debiased\n",
      "S1H1 4-8Hz wpli\n",
      "S1H1 4-8Hz envelope\n",
      "S1H1 4-8Hz coh\n",
      "S1H1 4-8Hz imcoh\n",
      "S1H1 4-8Hz plv\n",
      "S1H1 4-8Hz ciplv\n",
      "S1H1 4-8Hz ppc\n",
      "S1H1 4-8Hz pli\n",
      "S1H1 4-8Hz pli2_unbiased\n",
      "S1H1 4-8Hz wpli2_debiased\n",
      "K1V1 4-8Hz wpli\n",
      "K1V1 4-8Hz envelope\n",
      "K1V1 4-8Hz coh\n",
      "K1V1 4-8Hz imcoh\n",
      "K1V1 4-8Hz plv\n",
      "K1V1 4-8Hz ciplv\n",
      "K1V1 4-8Hz ppc\n",
      "K1V1 4-8Hz pli\n",
      "K1V1 4-8Hz pli2_unbiased\n",
      "K1V1 4-8Hz wpli2_debiased\n",
      "L1P1 4-8Hz wpli\n",
      "L1P1 4-8Hz envelope\n",
      "L1P1 4-8Hz coh\n",
      "L1P1 4-8Hz imcoh\n",
      "L1P1 4-8Hz plv\n",
      "L1P1 4-8Hz ciplv\n",
      "L1P1 4-8Hz ppc\n",
      "L1P1 4-8Hz pli\n",
      "L1P1 4-8Hz pli2_unbiased\n",
      "L1P1 4-8Hz wpli2_debiased\n",
      "M1G2 4-8Hz wpli\n",
      "M1G2 4-8Hz envelope\n",
      "M1G2 4-8Hz coh\n",
      "M1G2 4-8Hz imcoh\n",
      "M1G2 4-8Hz plv\n",
      "M1G2 4-8Hz ciplv\n",
      "M1G2 4-8Hz ppc\n",
      "M1G2 4-8Hz pli\n",
      "M1G2 4-8Hz pli2_unbiased\n",
      "M1G2 4-8Hz wpli2_debiased\n",
      "G1V2 4-8Hz wpli\n",
      "G1V2 4-8Hz envelope\n",
      "G1V2 4-8Hz coh\n",
      "G1V2 4-8Hz imcoh\n",
      "G1V2 4-8Hz plv\n",
      "G1V2 4-8Hz ciplv\n",
      "G1V2 4-8Hz ppc\n",
      "G1V2 4-8Hz pli\n",
      "G1V2 4-8Hz pli2_unbiased\n",
      "G1V2 4-8Hz wpli2_debiased\n",
      "G1R1 4-8Hz wpli\n",
      "G1R1 4-8Hz envelope\n",
      "G1R1 4-8Hz coh\n",
      "G1R1 4-8Hz imcoh\n",
      "G1R1 4-8Hz plv\n",
      "G1R1 4-8Hz ciplv\n",
      "G1R1 4-8Hz ppc\n",
      "G1R1 4-8Hz pli\n",
      "G1R1 4-8Hz pli2_unbiased\n",
      "G1R1 4-8Hz wpli2_debiased\n",
      "M1N2 4-8Hz wpli\n",
      "M1N2 4-8Hz envelope\n",
      "M1N2 4-8Hz coh\n",
      "M1N2 4-8Hz imcoh\n",
      "M1N2 4-8Hz plv\n",
      "M1N2 4-8Hz ciplv\n",
      "M1N2 4-8Hz ppc\n",
      "M1N2 4-8Hz pli\n",
      "M1N2 4-8Hz pli2_unbiased\n",
      "M1N2 4-8Hz wpli2_debiased\n",
      "S1B1 4-8Hz wpli\n",
      "S1B1 4-8Hz envelope\n",
      "S1B1 4-8Hz coh\n",
      "S1B1 4-8Hz imcoh\n",
      "S1B1 4-8Hz plv\n",
      "S1B1 4-8Hz ciplv\n",
      "S1B1 4-8Hz ppc\n",
      "S1B1 4-8Hz pli\n",
      "S1B1 4-8Hz pli2_unbiased\n",
      "S1B1 4-8Hz wpli2_debiased\n",
      "S1U3 4-8Hz wpli\n",
      "S1U3 4-8Hz envelope\n",
      "S1U3 4-8Hz coh\n",
      "S1U3 4-8Hz imcoh\n",
      "S1U3 4-8Hz plv\n",
      "S1U3 4-8Hz ciplv\n",
      "S1U3 4-8Hz ppc\n",
      "S1U3 4-8Hz pli\n",
      "S1U3 4-8Hz pli2_unbiased\n",
      "S1U3 4-8Hz wpli2_debiased\n",
      "B1R1 4-8Hz wpli\n",
      "B1R1 4-8Hz envelope\n",
      "B1R1 4-8Hz coh\n",
      "B1R1 4-8Hz imcoh\n",
      "B1R1 4-8Hz plv\n",
      "B1R1 4-8Hz ciplv\n",
      "B1R1 4-8Hz ppc\n",
      "B1R1 4-8Hz pli\n",
      "B1R1 4-8Hz pli2_unbiased\n",
      "B1R1 4-8Hz wpli2_debiased\n",
      "N2K2 4-8Hz wpli\n",
      "N2K2 4-8Hz envelope\n",
      "N2K2 4-8Hz coh\n",
      "N2K2 4-8Hz imcoh\n",
      "N2K2 4-8Hz plv\n",
      "N2K2 4-8Hz ciplv\n",
      "N2K2 4-8Hz ppc\n",
      "N2K2 4-8Hz pli\n",
      "N2K2 4-8Hz pli2_unbiased\n",
      "N2K2 4-8Hz wpli2_debiased\n",
      "B1C2 4-8Hz wpli\n",
      "B1C2 4-8Hz envelope\n",
      "B1C2 4-8Hz coh\n",
      "B1C2 4-8Hz imcoh\n",
      "B1C2 4-8Hz plv\n",
      "B1C2 4-8Hz ciplv\n",
      "B1C2 4-8Hz ppc\n",
      "B1C2 4-8Hz pli\n",
      "B1C2 4-8Hz pli2_unbiased\n",
      "B1C2 4-8Hz wpli2_debiased\n",
      "J1T2 4-8Hz wpli\n",
      "J1T2 4-8Hz envelope\n",
      "J1T2 4-8Hz coh\n",
      "J1T2 4-8Hz imcoh\n",
      "J1T2 4-8Hz plv\n",
      "J1T2 4-8Hz ciplv\n",
      "J1T2 4-8Hz ppc\n",
      "J1T2 4-8Hz pli\n",
      "J1T2 4-8Hz pli2_unbiased\n",
      "J1T2 4-8Hz wpli2_debiased\n",
      "O1O2 4-8Hz wpli\n",
      "O1O2 4-8Hz envelope\n",
      "O1O2 4-8Hz coh\n",
      "O1O2 4-8Hz imcoh\n",
      "O1O2 4-8Hz plv\n",
      "O1O2 4-8Hz ciplv\n",
      "O1O2 4-8Hz ppc\n",
      "O1O2 4-8Hz pli\n",
      "O1O2 4-8Hz pli2_unbiased\n",
      "O1O2 4-8Hz wpli2_debiased\n",
      "L2M1 4-8Hz wpli\n",
      "L2M1 4-8Hz envelope\n",
      "L2M1 4-8Hz coh\n",
      "L2M1 4-8Hz imcoh\n",
      "L2M1 4-8Hz plv\n",
      "L2M1 4-8Hz ciplv\n",
      "L2M1 4-8Hz ppc\n",
      "L2M1 4-8Hz pli\n",
      "L2M1 4-8Hz pli2_unbiased\n",
      "L2M1 4-8Hz wpli2_debiased\n",
      "Centrality computations are done\n"
     ]
    }
   ],
   "source": [
    "print('Processing centrality...')\n",
    "\n",
    "datasets = DATASETS.copy()\n",
    "\n",
    "ignored_methods = [\n",
    "#     'wpli',\n",
    "#     'envelope',\n",
    "#     'coh',\n",
    "#     'imcoh',\n",
    "#     'plv',\n",
    "#     'ciplv',\n",
    "#     'ppc',\n",
    "#     'pli',\n",
    "#     'pli2_unbiased',\n",
    "#     'wpli2_debiased'\n",
    "]\n",
    "\n",
    "close = dict()\n",
    "between = dict()\n",
    "eigen = dict()\n",
    "degree = dict()\n",
    "info = dict()\n",
    "harmony = dict()\n",
    "katz = dict()\n",
    "percolation = dict()\n",
    "\n",
    "total_ignored_subjects = 0\n",
    "\n",
    "for subject_name in datasets:\n",
    "    is_corrupted = False\n",
    "    close.update({subject_name: dict()})\n",
    "    between.update({subject_name: dict()})\n",
    "    eigen.update({subject_name: dict()})\n",
    "    degree.update({subject_name: dict()})\n",
    "    info.update({subject_name: dict()})\n",
    "    harmony.update({subject_name: dict()})\n",
    "    katz.update({subject_name: dict()})\n",
    "    percolation.update({subject_name: dict()})\n",
    "\n",
    "    for freq in datasets[subject_name]:\n",
    "\n",
    "        if is_corrupted:\n",
    "            break\n",
    "\n",
    "        for method in datasets[subject_name][freq]:\n",
    "\n",
    "            if method in ignored_methods:\n",
    "                continue\n",
    "\n",
    "            print(subject_name, freq, method)\n",
    "            label_names = datasets[subject_name][freq][method].columns\n",
    "\n",
    "            if nx.is_connected(\n",
    "                    nx.convert_matrix.from_numpy_array(\n",
    "                        datasets[subject_name][freq][method].to_numpy()\n",
    "                    )\n",
    "            ):\n",
    "                arr  = datasets[subject_name][freq][method].to_numpy()\n",
    "            else:\n",
    "                try:\n",
    "                    corrupted_subject = [subject for subject in subjects if subject.name == subject_name][0]\n",
    "                    subjects.remove(corrupted_subject)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                total_ignored_subjects += 1\n",
    "                print(f'Graph is not connected: {subject_name}, {freq}, {method}.\\n'\n",
    "                      f'This subject will be ignored.\\n'\n",
    "                      f'Total of ignored subjects: {total_ignored_subjects}\\n'\n",
    "                      f'Total of spared subjects: {len(subjects)}\\n')\n",
    "                is_corrupted = True\n",
    "                break\n",
    "                # raise ValueError(f'Graph is not connected: {subject_name}, {freq}, {method}')\n",
    "            # if matrix has negative values, shift it to make minimal value at least 0\n",
    "            if arr.min().min() < 0:\n",
    "                print(f'\\tShifting connectome for {method} at {freq}')\n",
    "                for i in range(arr.shape[0]):\n",
    "                    for j in range(arr.shape[1]):\n",
    "                        if i != j: arr[i, j] -= arr.min().min()\n",
    "            G = nx.convert_matrix.from_numpy_array(arr)\n",
    "            mapping = {node: label_name for node, label_name in zip(G, label_names)}\n",
    "            max = np.max(\n",
    "                np.array([\n",
    "                    np.sum(row)\n",
    "                    for row in arr\n",
    "                ])\n",
    "            )\n",
    "            min = np.min(\n",
    "                np.array([\n",
    "                    np.sum(row)\n",
    "                    for row in arr\n",
    "                ])\n",
    "            )\n",
    "            states = {node: (np.sum(row) - min)/(max - min) for node, row in zip(label_names, arr)}\n",
    "            G_num = G.copy()\n",
    "            G = nx.relabel_nodes(G, mapping)\n",
    "            if CONNECTOMES_KIND == 'initial' or CONNECTOMES_KIND == 'inverse' or CONNECTOMES_KIND == 'spatial':\n",
    "                G_sup = nx.convert_matrix.from_numpy_array(\n",
    "                        lmd.suppress(\n",
    "                            datasets[subject_name][freq][method],\n",
    "                            trigger= arr.mean().mean(),\n",
    "                            optimal=0\n",
    "                        ).to_numpy()\n",
    "                    )\n",
    "                G_sup = nx.relabel_nodes(G_sup, mapping)\n",
    "            else:\n",
    "                G_sup = G\n",
    "            for place, data in zip(\n",
    "                [\n",
    "                    close[subject_name],\n",
    "                    between[subject_name],\n",
    "                    eigen[subject_name],\n",
    "                    info[subject_name],\n",
    "                    degree[subject_name],\n",
    "                    harmony[subject_name],\n",
    "                    katz[subject_name],\n",
    "                    percolation[subject_name]\n",
    "                ],[\n",
    "                        nx.closeness_centrality(G, distance='weight'),\n",
    "                        nx.betweenness_centrality(G_sup, weight='weight'),\n",
    "                        nx.eigenvector_centrality_numpy(G, weight='weight'),\n",
    "                        nx.information_centrality(G, weight='weight'),\n",
    "                        dict(G.degree(weight='weight')),\n",
    "                        nx.harmonic_centrality(G, distance='weight'),\n",
    "                        nx.katz_centrality_numpy(G, weight='weight'),\n",
    "                        nx.algorithms.centrality.percolation_centrality(G_sup, weight='weight', states=states)\n",
    "                    ]\n",
    "            ):\n",
    "                place.update({\n",
    "                    freq + '_' + method: pd.Series(data)\n",
    "                })\n",
    "\n",
    "print('Centrality computations are done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating connectomes...\n"
     ]
    }
   ],
   "source": [
    "print('Updating connectomes...')\n",
    "\n",
    "datasets_centrality = dict()\n",
    "\n",
    "for subject in subjects:\n",
    "\n",
    "    if subject.name not in [*ENGEL1, *ENGEL2]:\n",
    "        continue\n",
    "\n",
    "    datasets_centrality.update({subject.name: dict()})\n",
    "    datasets_centrality[subject.name].update({\n",
    "        'close': pd.DataFrame(close[subject.name]),\n",
    "        'between': pd.DataFrame(between[subject.name]),\n",
    "        'eigen': pd.DataFrame(eigen[subject.name]),\n",
    "        'info': pd.DataFrame(info[subject.name]),\n",
    "        'degree': pd.DataFrame(degree[subject.name]),\n",
    "        'harmony': pd.DataFrame(harmony[subject.name]),\n",
    "        'katz': pd.DataFrame(katz[subject.name]),\n",
    "        'percolation': pd.DataFrame(percolation[subject.name])\n",
    "    })\n",
    "    true = subject.datasets['eigen']['resected']\n",
    "    datasets_centrality[subject.name]['close'] =\\\n",
    "        datasets_centrality[subject.name]['close'].assign(resected=true)\n",
    "    datasets_centrality[subject.name]['between'] =\\\n",
    "        datasets_centrality[subject.name]['between'].assign(resected=true)\n",
    "    datasets_centrality[subject.name]['eigen'] =\\\n",
    "        datasets_centrality[subject.name]['eigen'].assign(resected=true)\n",
    "    datasets_centrality[subject.name]['degree'] =\\\n",
    "        datasets_centrality[subject.name]['degree'].assign(resected=true)\n",
    "    datasets_centrality[subject.name]['info'] =\\\n",
    "        datasets_centrality[subject.name]['info'].assign(resected=true)\n",
    "    datasets_centrality[subject.name]['harmony'] =\\\n",
    "        datasets_centrality[subject.name]['harmony'].assign(resected=true)\n",
    "    datasets_centrality[subject.name]['katz'] =\\\n",
    "        datasets_centrality[subject.name]['katz'].assign(resected=true)\n",
    "    datasets_centrality[subject.name]['percolation'] =\\\n",
    "        datasets_centrality[subject.name]['percolation'].assign(resected=true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets_centrality' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-d0ed7e5f32ae>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf'/home/user//Documents/{CONNECTOMES_KIND}_centrality_en1&2.pkl'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m pickle.dump(\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mdatasets_centrality\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     open(\n\u001B[1;32m      5\u001B[0m         \u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'datasets_centrality' is not defined"
     ]
    }
   ],
   "source": [
    "path = f'/home/user/Documents/{CONNECTOMES_KIND}_centrality_en1&2.pkl'\n",
    "pickle.dump(\n",
    "    datasets_centrality,\n",
    "    open(\n",
    "        path,\n",
    "        'wb'\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path = f'/home/user//Documents/{CONNECTOMES_KIND}_centrality_en1&2.pkl'\n",
    "\n",
    "datasets_centrality = pickle.load(open(path, 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connectomes successfully updated. Now each subject has new initial connectomes\n",
      "Collecting statistics...\n",
      "Eigencentrality statistics are collected\n",
      "Betweenness centrality statistics are collected\n",
      "Closeness centrality statistics are collected\n",
      "Degree centrality statistics are collected\n",
      "Info centrality statistics are collected\n",
      "Harmony centrality statistics are collected\n",
      "Katz centrality statistics are collected\n",
      "Percolation centrality statistics are collected\n",
      "All statistics for initial connectomes are collected\n",
      "Saving statistics\n"
     ]
    }
   ],
   "source": [
    "subjects_list = [*ENGEL1, *ENGEL2, *ENGEL3, *ENGEL4]\n",
    "\n",
    "for subject in subjects:\n",
    "    if subject.name not in subjects_list:\n",
    "        continue\n",
    "    subject.datasets = datasets_centrality[subject.name]\n",
    "\n",
    "all_subjects = subjects.copy()\n",
    "\n",
    "subjects = [subject for subject in subjects if subject.name in subjects_list]\n",
    "\n",
    "print(f'Connectomes successfully updated. Now each subject has new {CONNECTOMES_KIND} connectomes')\n",
    "\n",
    "print('Collecting statistics...')\n",
    "\n",
    "stat1 = SubjectsStatistic(subjects, 'resected', centrality_metric='eigen')\n",
    "print('Eigencentrality statistics are collected')\n",
    "stat2 = SubjectsStatistic(subjects, 'resected', centrality_metric='between')\n",
    "print('Betweenness centrality statistics are collected')\n",
    "stat3 = SubjectsStatistic(subjects, 'resected', centrality_metric='close')\n",
    "print('Closeness centrality statistics are collected')\n",
    "stat4 = SubjectsStatistic(subjects, 'resected', centrality_metric='degree')\n",
    "print('Degree centrality statistics are collected')\n",
    "stat5 = SubjectsStatistic(subjects, 'resected', centrality_metric='info')\n",
    "print('Info centrality statistics are collected')\n",
    "stat6 = SubjectsStatistic(subjects, 'resected', centrality_metric='harmony')\n",
    "print('Harmony centrality statistics are collected')\n",
    "stat7 = SubjectsStatistic(subjects, 'resected', centrality_metric='katz')\n",
    "print('Katz centrality statistics are collected')\n",
    "stat8 = SubjectsStatistic(subjects, 'resected', centrality_metric='percolation')\n",
    "print('Percolation centrality statistics are collected')\n",
    "print(f'All statistics for {CONNECTOMES_KIND} connectomes are collected')\n",
    "print('Saving statistics')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "stats = (\n",
    "        stat1,\n",
    "        stat2,\n",
    "        stat3,\n",
    "        stat4,\n",
    "        stat5,\n",
    "        stat6,\n",
    "        stat7,\n",
    "        stat8,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = f'/home/user//Documents/{CONNECTOMES_KIND}_stats_en1&2.pkl'\n",
    "pickle.dump(\n",
    "    (\n",
    "        stat1,\n",
    "        stat2,\n",
    "        stat3,\n",
    "        stat4,\n",
    "        stat5,\n",
    "        stat6,\n",
    "        stat7,\n",
    "        stat8,\n",
    "    ),\n",
    "    open(\n",
    "        path,\n",
    "        'wb'\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f'All statistics are successfully saved at {path = }')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "path = f'/home/user//Documents/{CONNECTOMES_KIND}_stats_en1&2.pkl'\n",
    "stats = pickle.load(open(path, 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             eigen   between     close    degree      info  \\\n",
      "4-8Hz_wpli            6.128071e-01  0.515587  0.568135  0.654712  0.623172   \n",
      "4-8Hz_envelope        2.935385e-01  0.708642  0.264799  0.275017  0.284175   \n",
      "4-8Hz_coh             1.553784e-07  0.077248  0.308666  0.001659  0.000857   \n",
      "4-8Hz_imcoh           7.240341e-01  0.297239  0.013678  0.855252  0.811630   \n",
      "4-8Hz_plv             4.961603e-06  0.346741  0.502324  0.001578  0.001327   \n",
      "4-8Hz_ciplv           6.825575e-01  0.921600  0.160479  0.739529  0.708651   \n",
      "4-8Hz_ppc             1.668446e-08  0.151427  0.301727  0.000238  0.000146   \n",
      "4-8Hz_pli             6.825575e-01  0.304230  0.995305  0.802515  0.779849   \n",
      "4-8Hz_pli2_unbiased   5.385979e-01  0.662161  0.312879  0.741752  0.710842   \n",
      "4-8Hz_wpli2_debiased  9.320023e-01  0.890292  0.000069  0.823059  0.818483   \n",
      "\n",
      "                       harmony          katz  percolation  \n",
      "4-8Hz_wpli            0.544443  6.483526e-01     0.375820  \n",
      "4-8Hz_envelope        0.232258  3.114705e-01     0.988262  \n",
      "4-8Hz_coh             0.391887  1.786418e-08     0.204756  \n",
      "4-8Hz_imcoh           0.022418  4.673847e-01     0.318556  \n",
      "4-8Hz_plv             0.507964  6.421437e-02     0.558204  \n",
      "4-8Hz_ciplv           0.141254  7.086510e-01     0.804792  \n",
      "4-8Hz_ppc             0.432110  2.802252e-01     0.327241  \n",
      "4-8Hz_pli             0.953075  6.107432e-01     0.293538  \n",
      "4-8Hz_pli2_unbiased   0.249968  6.378097e-01     0.869127  \n",
      "4-8Hz_wpli2_debiased  0.000082  6.589664e-01     0.934342  \n"
     ]
    }
   ],
   "source": [
    "test1 = stats[0].test(state='reflected')\n",
    "test2 = stats[1].test(state='reflected')\n",
    "test3 = stats[2].test(state='reflected')\n",
    "test4 = stats[3].test(state='reflected')\n",
    "test5 = stats[4].test(state='reflected')\n",
    "test6 = stats[5].test(state='reflected')\n",
    "test7 = stats[6].test(state='reflected')\n",
    "test8 = stats[7].test(state='reflected')\n",
    "test1_samples, test2_samples, test3_samples, test4_samples, test5_samples, test6_samples, test7_samples, test8_samples = list(), list(), list(), list(), list(), list(), list(), list()\n",
    "for feature in test1.result:\n",
    "    test1_samples.append(test1.result[feature][1])\n",
    "    test2_samples.append(test2.result[feature][1])\n",
    "    test3_samples.append(test3.result[feature][1])\n",
    "    test4_samples.append(test4.result[feature][1])\n",
    "    test5_samples.append(test5.result[feature][1])\n",
    "    test6_samples.append(test6.result[feature][1])\n",
    "    test7_samples.append(test7.result[feature][1])\n",
    "    test8_samples.append(test8.result[feature][1])\n",
    "\n",
    "test_samples = np.array([\n",
    "    np.array(test1_samples),\n",
    "    np.array(test2_samples),\n",
    "    np.array(test3_samples),\n",
    "    np.array(test4_samples),\n",
    "    np.array(test5_samples),\n",
    "    np.array(test6_samples),\n",
    "    np.array(test7_samples),\n",
    "    np.array(test8_samples)\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(test_samples, columns=list(test1.result.keys()), index=[\n",
    "    'eigen', 'between', 'close', 'degree', 'info', 'harmony', 'katz', 'percolation'\n",
    "]).T\n",
    "print(df)\n",
    "df.to_csv('/home/user/Documents/Wilcoxon_ENG_1&2&3&4.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         eigen   between     close    degree      info  \\\n",
      "4-8Hz_wpli            0.347972  0.356870  0.260572  0.357286  0.356506   \n",
      "4-8Hz_envelope        0.272239  0.419249  0.450934  0.447626  0.463368   \n",
      "4-8Hz_coh             0.000010  0.124518  0.445148  0.005077  0.006110   \n",
      "4-8Hz_imcoh           0.394542  0.120871  0.067556  0.282038  0.341046   \n",
      "4-8Hz_plv             0.000350  0.294859  0.339514  0.025104  0.024377   \n",
      "4-8Hz_ciplv           0.494998  0.475000  0.445974  0.424585  0.347200   \n",
      "4-8Hz_ppc             0.000002  0.196611  0.285578  0.012400  0.011873   \n",
      "4-8Hz_pli             0.500000  0.162734  0.368653  0.479999  0.500000   \n",
      "4-8Hz_pli2_unbiased   0.383325  0.365107  0.153405  0.450521  0.496665   \n",
      "4-8Hz_wpli2_debiased  0.434433  0.420078  0.001188  0.186659  0.138580   \n",
      "\n",
      "                       harmony          katz  percolation  \n",
      "4-8Hz_wpli            0.248505  3.311359e-01     0.249831  \n",
      "4-8Hz_envelope        0.475837  2.612507e-01     0.456731  \n",
      "4-8Hz_coh             0.477501  1.965050e-09     0.245531  \n",
      "4-8Hz_imcoh           0.049799  4.139700e-01     0.120937  \n",
      "4-8Hz_plv             0.282744  2.039540e-01     0.452175  \n",
      "4-8Hz_ciplv           0.440197  4.700140e-01     0.442671  \n",
      "4-8Hz_ppc             0.266030  2.920036e-01     0.308721  \n",
      "4-8Hz_pli             0.411529  4.608776e-01     0.142309  \n",
      "4-8Hz_pli2_unbiased   0.150457  4.633675e-01     0.424585  \n",
      "4-8Hz_wpli2_debiased  0.000885  4.262237e-01     0.458389  \n"
     ]
    }
   ],
   "source": [
    "test1 = stats[0].test(state='reflected', test='mannwhitneyu')\n",
    "test2 = stats[1].test(state='reflected', test='mannwhitneyu')\n",
    "test3 = stats[2].test(state='reflected', test='mannwhitneyu')\n",
    "test4 = stats[3].test(state='reflected', test='mannwhitneyu')\n",
    "test5 = stats[4].test(state='reflected', test='mannwhitneyu')\n",
    "test6 = stats[5].test(state='reflected', test='mannwhitneyu')\n",
    "test7 = stats[6].test(state='reflected', test='mannwhitneyu')\n",
    "test8 = stats[7].test(state='reflected', test='mannwhitneyu')\n",
    "test1_samples, test2_samples, test3_samples, test4_samples, test5_samples, test6_samples, test7_samples, test8_samples = list(), list(), list(), list(), list(), list(), list(), list()\n",
    "for feature in test1.result:\n",
    "    test1_samples.append(test1.result[feature][1])\n",
    "    test2_samples.append(test2.result[feature][1])\n",
    "    test3_samples.append(test3.result[feature][1])\n",
    "    test4_samples.append(test4.result[feature][1])\n",
    "    test5_samples.append(test5.result[feature][1])\n",
    "    test6_samples.append(test6.result[feature][1])\n",
    "    test7_samples.append(test7.result[feature][1])\n",
    "    test8_samples.append(test8.result[feature][1])\n",
    "\n",
    "test_samples = np.array([\n",
    "    np.array(test1_samples),\n",
    "    np.array(test2_samples),\n",
    "    np.array(test3_samples),\n",
    "    np.array(test4_samples),\n",
    "    np.array(test5_samples),\n",
    "    np.array(test6_samples),\n",
    "    np.array(test7_samples),\n",
    "    np.array(test8_samples)\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(test_samples, columns=list(test1.result.keys()), index=[\n",
    "    'eigen', 'between', 'close', 'degree', 'info', 'harmony', 'katz', 'percolation'\n",
    "]).T\n",
    "print(df)\n",
    "df.to_csv('/home/user/Documents/MannWitneyu_ENG_1&2&3&4.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen\n",
      "wpli 0.0008117911888701784\n",
      "envelope 0.34944988965725554\n",
      "coh 0.07040544183835014\n",
      "imcoh 2.535107137548402e-06\n",
      "plv 0.3148843146982729\n",
      "ciplv 0.04072622824960368\n",
      "ppc 0.23778742919111537\n",
      "pli 0.4007241200601771\n",
      "pli2_unbiased 1.2199289786234054e-05\n",
      "wpli2_debiased 9.457825168762198e-24\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "true = stats[i].datasets['true']\n",
    "false = stats[i].datasets['false_mirror']\n",
    "scaler = MaxAbsScaler()\n",
    "print(stats[i].centrality_metric)\n",
    "\n",
    "\n",
    "true = pd.DataFrame(scaler.fit_transform(true), columns=true.columns)\n",
    "false = pd.DataFrame(scaler.fit_transform(false), columns=false.columns)\n",
    "\n",
    "for feat in true.columns:\n",
    "    w, p = sp.stats.ttest_ind(true[feat], false[feat])\n",
    "    print(feat[6:], p)\n",
    "\n",
    "\n",
    "feat = 'wpli'\n",
    "# for val1, val2 in zip(stats[0].datasets['true']['4-8Hz_coh'], stats[0].datasets['false_res']['4-8Hz_coh']):\n",
    "#     print(val1, val2)\n",
    "\n",
    "# print(\n",
    "#     np.mean(\n",
    "#         np.array([\n",
    "#             np.abs(val1 - val2)\n",
    "#             for val1, val2 in zip(stats[i].datasets['true'][f'4-8Hz_{feat}'],\n",
    "#                                   stats[i].datasets['false_res'][f'4-8Hz_{feat}'])\n",
    "#         ])\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# x = np.arange(stats[i].datasets['true'][f'4-8Hz_{feat}'].to_numpy().shape[0])\n",
    "#\n",
    "# plt.plot(\n",
    "#     x, stats[i].datasets['true'][f'4-8Hz_{feat}'].to_numpy(), 'gx',\n",
    "#     x, stats[i].datasets['false_mirror'][f'4-8Hz_{feat}'].to_numpy(), 'ro'\n",
    "# )\n",
    "# plt.show()\n",
    "#\n",
    "# feat = 'envelope'\n",
    "#\n",
    "# plt.plot(\n",
    "#     x, stats[i].datasets['true'][f'4-8Hz_{feat}'].to_numpy(), 'gx',\n",
    "#     x, stats[i].datasets['false_mirror'][f'4-8Hz_{feat}'].to_numpy(), 'ro'\n",
    "# )\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "LinearRegression importance\n",
      "Feature: 4-8Hz_wpli, Score: -0.03004\n",
      "Feature: 4-8Hz_envelope, Score: -0.01351\n",
      "Feature: 4-8Hz_coh, Score: -0.10160\n",
      "Feature: 4-8Hz_imcoh, Score: 0.01274\n",
      "Feature: 4-8Hz_plv, Score: 0.01002\n",
      "Feature: 4-8Hz_ciplv, Score: 0.03342\n",
      "Feature: 4-8Hz_ppc, Score: 0.04246\n",
      "Feature: 4-8Hz_pli, Score: 0.04595\n",
      "Feature: 4-8Hz_pli2_unbiased, Score: -0.02892\n",
      "Feature: 4-8Hz_wpli2_debiased, Score: 0.01127\n",
      "--------------\n",
      "--------------\n",
      "LogisticRegression importance\n",
      "Feature: 4-8Hz_wpli, Score: -0.12050\n",
      "Feature: 4-8Hz_envelope, Score: -0.05405\n",
      "Feature: 4-8Hz_coh, Score: -0.40104\n",
      "Feature: 4-8Hz_imcoh, Score: 0.05214\n",
      "Feature: 4-8Hz_plv, Score: 0.02765\n",
      "Feature: 4-8Hz_ciplv, Score: 0.13471\n",
      "Feature: 4-8Hz_ppc, Score: 0.16557\n",
      "Feature: 4-8Hz_pli, Score: 0.18766\n",
      "Feature: 4-8Hz_pli2_unbiased, Score: -0.11541\n",
      "Feature: 4-8Hz_wpli2_debiased, Score: 0.04577\n",
      "--------------\n",
      "--------------\n",
      "RandomForestClassifier importance\n",
      "Feature: 4-8Hz_wpli, Score: 0.10561\n",
      "Feature: 4-8Hz_envelope, Score: 0.09563\n",
      "Feature: 4-8Hz_coh, Score: 0.08832\n",
      "Feature: 4-8Hz_imcoh, Score: 0.11182\n",
      "Feature: 4-8Hz_plv, Score: 0.09861\n",
      "Feature: 4-8Hz_ciplv, Score: 0.10376\n",
      "Feature: 4-8Hz_ppc, Score: 0.08478\n",
      "Feature: 4-8Hz_pli, Score: 0.12140\n",
      "Feature: 4-8Hz_pli2_unbiased, Score: 0.10087\n",
      "Feature: 4-8Hz_wpli2_debiased, Score: 0.08919\n",
      "--------------\n",
      "--------------\n",
      "permutation importance\n",
      "Feature: 4-8Hz_wpli, Score: 0.05890\n",
      "Feature: 4-8Hz_envelope, Score: 0.03082\n",
      "Feature: 4-8Hz_coh, Score: 0.01507\n",
      "Feature: 4-8Hz_imcoh, Score: 0.02466\n",
      "Feature: 4-8Hz_plv, Score: 0.02740\n",
      "Feature: 4-8Hz_ciplv, Score: 0.01781\n",
      "Feature: 4-8Hz_ppc, Score: 0.00479\n",
      "Feature: 4-8Hz_pli, Score: 0.02671\n",
      "Feature: 4-8Hz_pli2_unbiased, Score: 0.02808\n",
      "Feature: 4-8Hz_wpli2_debiased, Score: 0.04315\n",
      "--------------\n",
      "--------------\n",
      "Linear SVM importance\n",
      "Feature: 4-8Hz_wpli, Score: -0.16989\n",
      "Feature: 4-8Hz_envelope, Score: -0.20526\n",
      "Feature: 4-8Hz_coh, Score: -0.66107\n",
      "Feature: 4-8Hz_imcoh, Score: 0.02916\n",
      "Feature: 4-8Hz_plv, Score: -0.01126\n",
      "Feature: 4-8Hz_ciplv, Score: 0.35631\n",
      "Feature: 4-8Hz_ppc, Score: 0.35006\n",
      "Feature: 4-8Hz_pli, Score: 0.37550\n",
      "Feature: 4-8Hz_pli2_unbiased, Score: -0.26907\n",
      "Feature: 4-8Hz_wpli2_debiased, Score: 0.07413\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "i = 7\n",
    "true = stats[i].datasets['true'].assign(resected=True)\n",
    "false = stats[i].datasets['false_mirror'].assign(resected=False)\n",
    "dataset = pd.concat([true, false], axis=0).sample(frac=1)\n",
    "resected = dataset['resected']\n",
    "dataset = dataset.drop(columns='resected')\n",
    "model = LinearRegression()\n",
    "scaler = StandardScaler()\n",
    "# dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
    "# dataset = dataset.assign(resected=resected.to_list())\n",
    "X = scaler.fit_transform(dataset)\n",
    "y = resected.to_numpy()\n",
    "model.fit(X, y)\n",
    "importance = model.coef_\n",
    "print('--------------')\n",
    "print('LinearRegression importance')\n",
    "for i, v in zip(dataset.columns, importance):\n",
    "\tprint(f'Feature: {i}, Score: {v:.5f}')\n",
    "print('--------------')\n",
    "model = LogisticRegression()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "print('--------------')\n",
    "print('LogisticRegression importance')\n",
    "for i, v in zip(dataset.columns, importance):\n",
    "\tprint(f'Feature: {i}, Score: {v:.5f}')\n",
    "print('--------------')\n",
    "model = RandomForestClassifier()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "print('--------------')\n",
    "print('RandomForestClassifier importance')\n",
    "for i, v in zip(dataset.columns, importance):\n",
    "\tprint(f'Feature: {i}, Score: {v:.5f}')\n",
    "print('--------------')\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# perform permutation importance\n",
    "results = permutation_importance(model, X, y, scoring='accuracy')\n",
    "# get importance\n",
    "importance = results.importances_mean\n",
    "print('--------------')\n",
    "print('permutation importance')\n",
    "for i, v in zip(dataset.columns, importance):\n",
    "\tprint(f'Feature: {i}, Score: {v:.5f}')\n",
    "print('--------------')\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X, y)\n",
    "importance = model.coef_\n",
    "print('--------------')\n",
    "print('Linear SVM importance')\n",
    "for i, v in zip(dataset.columns, *importance):\n",
    "\tprint(f'Feature: {i}, Score: {v:.5f}')\n",
    "print('--------------')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}