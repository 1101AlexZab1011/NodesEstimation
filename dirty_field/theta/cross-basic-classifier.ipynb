{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/nilearn/datasets/__init__.py:86: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All computation has been already done, loading of the existing file with the solution...\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import pickle\n",
    "import re\n",
    "from abc import *\n",
    "from copy import deepcopy\n",
    "from operator import itemgetter\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import mne\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors._dist_metrics import DistanceMetric\n",
    "from sklearn.utils import shuffle\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nodestimation.learning.connectoming import make_connectome\n",
    "from nodestimation.learning.estimation import collect_statistic, \\\n",
    "    compute_importance, collect_cross_statistic, make_selection_map, \\\n",
    "    select, separate_datasets, selected_statistic, choose_best, selected_data, make_feature_selection\n",
    "from nodestimation.learning.informativeness import CrossInformativeness, Informativeness, SubjectsInformativeness, \\\n",
    "    NodesInformativeness\n",
    "from nodestimation.learning.networking import sparse_graph, graph_to_hemispheres, hemispheres_division_modularity, \\\n",
    "    metric_for_hemispheres\n",
    "from nodestimation.processing.features import prepare_features\n",
    "from nodestimation.project import find_subject_dir, conditions_unique_code\n",
    "from nodestimation.pipeline import pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nibabel\n",
    "import nilearn.plotting as nplt\n",
    "from nodestimation.project.actions import read\n",
    "import nodestimation as nd\n",
    "from nodestimation.learning.modification import append_series, promote\n",
    "import nodestimation.learning.modification as lmd\n",
    "from nodestimation.project.subject import Subject\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib as mpl\n",
    "from nodestimation.learning.selection import SubjectsStatistic, Wilcoxon, Mannwhitneyu, Test\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "\n",
    "ENGEL1 = [\n",
    "    'B1C2',\n",
    "    'B1R1',\n",
    "    'G1R1',\n",
    "    'G1V2',\n",
    "    'J1T2',\n",
    "    'K1V1',\n",
    "    'L1P1',\n",
    "    'M1G2',\n",
    "    'M1N2',\n",
    "    'O1O2',\n",
    "    'R1D2',\n",
    "    'S1A2',\n",
    "    'S1B1',\n",
    "    'S1H1',\n",
    "    'S1U3'\n",
    "]\n",
    "ENGEL2 = [\n",
    "    'L2M1',\n",
    "    'M2S2',\n",
    "    'N2K2',\n",
    "    'P1H2'\n",
    "]\n",
    "ENGEL3 = [\n",
    "    'N3S2',\n",
    "    'S3R1'\n",
    "]\n",
    "ENGEL4 = [\n",
    "    'K4L2'\n",
    "]\n",
    "REJECTED = [\n",
    "    'S1U3',\n",
    "    'P1H2'\n",
    "]\n",
    "\n",
    "AGE = {\n",
    "    'B1C2': 28.0,\n",
    "    'B1R1': 16.0,\n",
    "    'G1R1': 23.0,\n",
    "    'G1V2': 5.0,\n",
    "    'J1T2': 8.0,\n",
    "    'K1V1': 10.0,\n",
    "    'K4L2': 14.0,\n",
    "    'L1P1': 16.0,\n",
    "    'L2M1': 20.0,\n",
    "    'M1G2': 8.0,\n",
    "    'M1N2': 7.0,\n",
    "    'M2S2': 18.0,\n",
    "    'N2K2': 30.0,\n",
    "    'N3S2': 10.0,\n",
    "    'O1O2': 18.0,\n",
    "    'R1D2': 6.5,\n",
    "    'P1H2': 7.0,\n",
    "    'S1A2': 12.0,\n",
    "    'S1B1': 17.0,\n",
    "    'S1H1': 28.0,\n",
    "    'S3R1': 19.0,\n",
    "    'S1U3': 15.0,\n",
    "}\n",
    "\n",
    "SEX = {\n",
    "    'B1C2': 'f',\n",
    "    'B1R1': 'm',\n",
    "    'G1R1': 'f',\n",
    "    'G1V2': 'm',\n",
    "    'J1T2': 'f',\n",
    "    'K1V1': 'f',\n",
    "    'K4L2': 'f',\n",
    "    'L1P1': 'f',\n",
    "    'L2M1': 'f',\n",
    "    'M1G2': 'm',\n",
    "    'M1N2': 'm',\n",
    "    'M2S2': 'm',\n",
    "    'N2K2': 'm',\n",
    "    'N3S2': 'm',\n",
    "    'O1O2': 'f',\n",
    "    'R1D2': 'f',\n",
    "    'P1H2': 'm',\n",
    "    'S1A2': 'm',\n",
    "    'S1B1': 'm',\n",
    "    'S1H1': 'm',\n",
    "    'S3R1': 'm',\n",
    "    'S1U3': 'f',\n",
    "}\n",
    "\n",
    "SUBJECTS = pipeline(\n",
    "    methods=['wpli', 'envelope', 'coh', 'imcoh', 'plv', 'ciplv', 'ppc', 'pli', 'pli2_unbiased', 'wpli2_debiased'],\n",
    "    freq_bands=(4, 8),\n",
    "    centrality_metrics=['eigen', 'between', 'degree', 'info']\n",
    "    )\n",
    "\n",
    "CONNECTOMES_KIND = 'initial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs are prepared\n"
     ]
    }
   ],
   "source": [
    "subjects = SUBJECTS.copy()\n",
    "\n",
    "DATASETS = {\n",
    "    subject.name: {\n",
    "        freq: {\n",
    "            method: make_connectome(subject, freq, method, CONNECTOMES_KIND, threshold=1)\n",
    "           for method in subject.connectomes[freq]\n",
    "        }\n",
    "        for freq in subject.connectomes\n",
    "    }\n",
    "    for subject in subjects\n",
    "}\n",
    "print('Connectomes are prepared')\n",
    "\n",
    "GRAPHS = [\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.cluster.transitivity),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.smetric.s_metric, normalized=False),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.global_efficiency),\n",
    "]\n",
    "print('Graphs are prepared')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "path = f'/home/user//Documents/{CONNECTOMES_KIND}_stats.pkl'\n",
    "stats = pickle.load(open(path, 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Engel 1 and 2, global efficiency\n",
    "\n",
    "datasets = GRAPHS.copy()\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    for sample in datasets[i].index:\n",
    "        subject = sample[:4]\n",
    "        if subject in REJECTED:\n",
    "            datasets[i] = datasets[i].drop(index=sample)\n",
    "        # if subject not in ENGEL1 and subject not in ENGEL2 or subject in REJECTED:\n",
    "        #     datasets[i] = datasets[i].drop(index=sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# hemispheres\n",
    "\n",
    "names = ['transitivity', 's_metric', 'global_efficiency']\n",
    "cross_hemispheres_informativeness_arr = list()\n",
    "cross_subjects_informativeness_arr = list()\n",
    "\n",
    "confusions = list()\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "#     confusions.append((tn, fp, fn, tp))\n",
    "\n",
    "for dataset, name in zip(datasets, names):\n",
    "    cross_hemispheres_informativeness = CrossInformativeness()\n",
    "    cross_subjects_informativeness = CrossInformativeness()\n",
    "\n",
    "    for _ in range(100):\n",
    "        hemispheres_informatoveness = Informativeness()\n",
    "        subjects_informativeness = SubjectsInformativeness()\n",
    "        acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "        for i in range(100):\n",
    "\n",
    "            y = dataset['resected'].to_numpy()\n",
    "            x = dataset[[f'{name}_for_wpli_4-8Hz', f'{name}_for_envelope_4-8Hz']].to_numpy()\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            x = scaler.fit_transform(x)\n",
    "\n",
    "            samples = [[sample] for sample in dataset.index.tolist()]\n",
    "\n",
    "            x = np.append(x, samples, axis=1)\n",
    "            engel_1_2_set_x, engel_1_2_set_y = list(), list()\n",
    "            test_set_x, test_set_y = list(), list()\n",
    "            for sample_x, sample_y in zip(x, y):\n",
    "                if any([subject in sample_x[-1] for subject in [*ENGEL1, *ENGEL2]]):\n",
    "                    engel_1_2_set_x.append(sample_x)\n",
    "                    engel_1_2_set_y.append(sample_y)\n",
    "                else:\n",
    "                    test_set_x.append(sample_x)\n",
    "                    test_set_y.append(sample_y)\n",
    "\n",
    "            x_train, x_test_add, y_train, y_test_add = train_test_split(\n",
    "                engel_1_2_set_x,\n",
    "                engel_1_2_set_y,\n",
    "                train_size=0.5\n",
    "            )\n",
    "            x_test = test_set_x + x_test_add\n",
    "            y_test = test_set_y + y_test_add\n",
    "            # train_samples, test_samples = x_train[:][2], x_test[:][2]\n",
    "            train_samples = np.array([sample[2] for sample in x_train])\n",
    "            test_samples = np.array([sample[2] for sample in x_test])\n",
    "            x_train = np.array([sample[0:2] for sample in x_train])\n",
    "            x_test = np.array([sample[0:2] for sample in x_test])\n",
    "\n",
    "            clf = svm.SVC()\n",
    "            clf.fit(x_train, y_train)\n",
    "            pred = clf.predict(x_test)\n",
    "\n",
    "            # if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "            #     spec.append(tn / (tn + fp))\n",
    "            #     sens.append(tp / (tp + fn))\n",
    "            #     negpred.append(tn/(tn + fn))\n",
    "            #     pospred.append(tp/(tp + fp))\n",
    "\n",
    "            for predicted, actual, sample, value in zip(pred, y_test, test_samples, x_test):\n",
    "                hemispheres_informatoveness.informativeness = sample, actual, 'correct' \\\n",
    "                if predicted == actual else 'wrong'\n",
    "                subjects_informativeness.informativeness = sample, actual, 'correct' \\\n",
    "                if predicted == actual else 'wrong'\n",
    "\n",
    "        cross_subjects_informativeness.informativeness = subjects_informativeness\n",
    "        cross_hemispheres_informativeness.informativeness = hemispheres_informatoveness\n",
    "\n",
    "    cross_hemispheres_informativeness_arr.append(cross_hemispheres_informativeness)\n",
    "    cross_subjects_informativeness_arr.append(cross_subjects_informativeness)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Transitivity  S metric  Global Efficiency  Engel\n",
      "B1C2      0.273291  0.355502           0.390818    1.0\n",
      "B1R1      0.875153  0.877188           0.958836    1.0\n",
      "G1R1      0.962443  0.968370           0.978824    1.0\n",
      "G1V2      0.479753  0.490202           0.460029    1.0\n",
      "J1T2      0.288805  0.584870           0.662457    1.0\n",
      "K1V1      0.214108  0.527049           0.525609    1.0\n",
      "K4L2      0.566000  0.558700           0.490300    4.0\n",
      "L1P1      0.853683  0.950030           0.976848    1.0\n",
      "L2M1      0.736296  0.887759           0.641966    2.0\n",
      "M1G2      0.631346  0.727425           0.763141    1.0\n",
      "M1N2      0.864098  0.832760           0.928898    1.0\n",
      "M2S2      0.647733  0.695212           0.779264    2.0\n",
      "N2K2      0.486773  0.523013           0.864838    2.0\n",
      "N3S2      0.051224  0.040018           0.051564    3.0\n",
      "O1O2      0.849875  0.918361           0.970726    1.0\n",
      "R1D2      0.944319  0.860090           0.955945    1.0\n",
      "S1A2      0.324196  0.392767           0.460512    1.0\n",
      "S1B1      0.612949  0.598702           0.722740    1.0\n",
      "S1H1      0.435475  0.439541           0.434426    1.0\n",
      "S3R1      0.430900  0.606850           0.605447    3.0\n"
     ]
    }
   ],
   "source": [
    "series = list()\n",
    "index = [\n",
    "    'Transitivity',\n",
    "    'S metric',\n",
    "    'Global Efficiency',\n",
    "    'Engel'\n",
    "]\n",
    "\n",
    "eng = dict()\n",
    "for subject_name in ENGEL1 + ENGEL2 + ENGEL3 + ENGEL4:\n",
    "    if subject_name in REJECTED:\n",
    "        continue\n",
    "    else:\n",
    "        if subject_name in ENGEL1:\n",
    "            eng.update({\n",
    "                subject_name: 1\n",
    "            })\n",
    "        if subject_name in ENGEL2:\n",
    "            eng.update({\n",
    "                subject_name: 2\n",
    "            })\n",
    "        if subject_name in ENGEL3:\n",
    "            eng.update({\n",
    "                subject_name: 3\n",
    "            })\n",
    "        if subject_name in ENGEL4:\n",
    "            eng.update({\n",
    "                subject_name: 4\n",
    "            })\n",
    "\n",
    "for info in cross_subjects_informativeness_arr:\n",
    "    series.append(\n",
    "        pd.Series(\n",
    "                dict(\n",
    "                sorted(\n",
    "                    info.acc().items(),\n",
    "                    key=lambda item: item[0]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "series.append(\n",
    "    pd.Series(\n",
    "                dict(\n",
    "                sorted(\n",
    "                    eng.items(),\n",
    "                    key=lambda item: item[0]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    series,\n",
    "    index=index\n",
    ")\n",
    "df = df.T\n",
    "print(df)\n",
    "df.to_csv('~/Documents/Subjects_informativeness-hemispheres-level.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# regions\n",
    "\n",
    "for stat in stats:\n",
    "    print(stat)\n",
    "    start = time.time()\n",
    "    cross_subjects_informativeness = CrossInformativeness()\n",
    "\n",
    "    for _ in range(100):\n",
    "        features = ['4-8Hz_wpli', '4-8Hz_envelope']\n",
    "        acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "        subjects_informativeness = SubjectsInformativeness()\n",
    "\n",
    "        for _ in range(100):\n",
    "            clf = svm.SVC()\n",
    "            true_data = stat.datasets['true'][features]\n",
    "            false_data = stat.datasets['false_mirror'][features]\n",
    "            true_data = true_data.assign(resected=True)\n",
    "            false_data = false_data.assign(resected=False)\n",
    "            for sample in true_data.index:\n",
    "                subject = sample[:4]\n",
    "                # if subject in REJECTED:\n",
    "                #     true_data = true_data.drop(index=sample)\n",
    "                if subject not in ENGEL1 and subject not in ENGEL2 or subject in REJECTED:\n",
    "                    true_data = true_data.drop(index=sample)\n",
    "            for sample in false_data.index:\n",
    "                subject = sample[:4]\n",
    "                # if subject in REJECTED:\n",
    "                #     false_data = false_data.drop(index=sample)\n",
    "                if subject not in ENGEL1 and subject not in ENGEL2 or subject in REJECTED:\n",
    "                    false_data = false_data.drop(index=sample)\n",
    "            dataset = pd.concat([true_data, false_data], axis=0)\n",
    "            dataset = dataset.sample(frac = 1)\n",
    "\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "            y = dataset['resected'].to_numpy()\n",
    "            dataset = dataset.drop(['resected'], axis=1)\n",
    "            samples = [[sample] for sample in dataset.index.tolist()]\n",
    "\n",
    "            x = scaler.fit_transform(dataset)\n",
    "            x = np.append(x, samples, axis=1)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "            train_samples, test_samples = x_train[:, 2], x_test[:, 2]\n",
    "            x_train, x_test = x_train[:, 0:2], x_test[:, 0:2]\n",
    "\n",
    "            clf.fit(x_train, y_train)\n",
    "            pred = clf.predict(x_test)\n",
    "\n",
    "            for predicted, actual, sample, value in zip(pred, y_test, test_samples, x_test):\n",
    "                subjects_informativeness.informativeness = sample, actual, 'correct'\\\n",
    "                    if predicted == actual else 'wrong'\n",
    "            # acc.append(accuracy_score(y_test, pred))\n",
    "\n",
    "            # if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "            #     spec.append(tn / (tn + fp))\n",
    "            #     sens.append(tp / (tp + fn))\n",
    "            #     negpred.append(tn/(tn + fn))\n",
    "            #     pospred.append(tp/(tp + fp))\n",
    "        cross_subjects_informativeness.informativeness = subjects_informativeness\n",
    "\n",
    "    print(f'RUNTIME: {time.time() - start}')\n",
    "    cross_subjects_informativeness_arr.append(cross_subjects_informativeness)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "series = list()\n",
    "index = [\n",
    "    'Transitivity',\n",
    "    'S metric',\n",
    "    'Global Efficiency',\n",
    "    'Eigencentrality',\n",
    "    'Betweenness',\n",
    "    'Closeness',\n",
    "    'Degree',\n",
    "    'Info',\n",
    "    'Harmony',\n",
    "    'Katz',\n",
    "    'Percolation',\n",
    "    'Engel'\n",
    "]\n",
    "\n",
    "eng = dict()\n",
    "for subject_name in ENGEL1 + ENGEL2:\n",
    "    if subject_name in REJECTED:\n",
    "        continue\n",
    "    else:\n",
    "        eng.update({\n",
    "            subject_name: 1 if subject_name in ENGEL1 else 2\n",
    "        })\n",
    "\n",
    "for info in cross_subjects_informativeness_arr:\n",
    "    series.append(\n",
    "        pd.Series(\n",
    "                dict(\n",
    "                sorted(\n",
    "                    info.acc().items(),\n",
    "                    key=lambda item: item[0]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "series.append(\n",
    "    pd.Series(\n",
    "                dict(\n",
    "                sorted(\n",
    "                    eng.items(),\n",
    "                    key=lambda item: item[0]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    series,\n",
    "    index=index\n",
    ")\n",
    "df = df.T\n",
    "print(df)\n",
    "df.to_csv('~/Documents/Subjects_informativeness-Engel1&2.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hemispheres\n",
    "\n",
    "names = ['transitivity', 's_metric', 'global_efficiency']\n",
    "n_iter = 1000\n",
    "confusions = list()\n",
    "#     confusions.append((tn, fp, fn, tp))\n",
    "\n",
    "for dataset, name in zip(datasets, names):\n",
    "\n",
    "    tn_c, tp_c, fn_c, fp_c = 0, 0, 0, 0\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        y = dataset['resected'].to_numpy()\n",
    "        x = dataset[[f'{name}_for_wpli_4-8Hz', f'{name}_for_envelope_4-8Hz']].to_numpy()\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x = scaler.fit_transform(x)\n",
    "\n",
    "        samples = [[sample] for sample in dataset.index.tolist()]\n",
    "\n",
    "        x = np.append(x, samples, axis=1)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "        train_samples, test_samples = x_train[:, 2], x_test[:, 2]\n",
    "        x_train, x_test = x_train[:, 0:2], x_test[:, 0:2]\n",
    "\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=[0,1]).ravel()\n",
    "        tn_c += tn\n",
    "        fp_c += fp\n",
    "        fn_c += fn\n",
    "        tp_c += tp\n",
    "\n",
    "    confusions.append((tn_c/n_iter, fp_c/n_iter, fn_c/n_iter, tp_c/n_iter))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# regions\n",
    "\n",
    "n_iter = 1000\n",
    "\n",
    "for stat in stats:\n",
    "\n",
    "    features = ['4-8Hz_wpli', '4-8Hz_envelope']\n",
    "    tn_c, tp_c, fn_c, fp_c = 0, 0, 0, 0\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        clf = svm.SVC()\n",
    "        true_data = stat.datasets['true'][features]\n",
    "        false_data = stat.datasets['false_mirror'][features]\n",
    "        true_data = true_data.assign(resected=True)\n",
    "        false_data = false_data.assign(resected=False)\n",
    "        for sample in true_data.index:\n",
    "            subject = sample[:4]\n",
    "            if subject in REJECTED:\n",
    "                true_data = true_data.drop(index=sample)\n",
    "        for sample in false_data.index:\n",
    "            subject = sample[:4]\n",
    "            if subject in REJECTED:\n",
    "                false_data = false_data.drop(index=sample)\n",
    "        dataset = pd.concat([true_data, false_data], axis=0)\n",
    "        dataset = dataset.sample(frac = 1)\n",
    "\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        y = dataset['resected'].to_numpy()\n",
    "        dataset = dataset.drop(['resected'], axis=1)\n",
    "        samples = [[sample] for sample in dataset.index.tolist()]\n",
    "\n",
    "        x = scaler.fit_transform(dataset)\n",
    "        x = np.append(x, samples, axis=1)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "        train_samples, test_samples = x_train[:, 2], x_test[:, 2]\n",
    "        x_train, x_test = x_train[:, 0:2], x_test[:, 0:2]\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=[0,1]).ravel()\n",
    "        tn_c += tn\n",
    "        fp_c += fp\n",
    "        fn_c += fn\n",
    "        tp_c += tp\n",
    "\n",
    "    confusions.append((tn_c/n_iter, fp_c/n_iter, fn_c/n_iter, tp_c/n_iter))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = [\n",
    "    'Transitivity',\n",
    "    'S metric',\n",
    "    'Global Efficiency',\n",
    "    'Eigencentrality',\n",
    "    'Betweenness',\n",
    "    'Closeness',\n",
    "    'Degree',\n",
    "    'Info',\n",
    "    'Harmony',\n",
    "    'Katz',\n",
    "    'Percolation'\n",
    "]\n",
    "\n",
    "columns = [\n",
    "    'accuracy',\n",
    "    'specificity',\n",
    "    'sensitivity',\n",
    "    'Matthews',\n",
    "    'f1',\n",
    "    'Fowlkesâ€“Mallows'\n",
    "]\n",
    "\n",
    "series = list()\n",
    "\n",
    "for tn, fp, fn, tp in confusions:\n",
    "\n",
    "    series.append(\n",
    "        [\n",
    "            (tp + tn) / (tp + tn + fp + fn),\n",
    "            tn / (tn + fp),\n",
    "            tp / (tp + fn),\n",
    "            (tp * tn - fp * fn) /\n",
    "            np.sqrt(\n",
    "                (tp + fp) *\n",
    "                (tp + fn) *\n",
    "                (tn + fp) *\n",
    "                (tn + fn)\n",
    "            ),\n",
    "            2 * tp / (2 * tp + fp + fn),\n",
    "            np.sqrt(tp / (tp + fn) * tp / (tp + fp))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    series,\n",
    "    columns=columns,\n",
    "    index=index\n",
    ")\n",
    "df = df.T\n",
    "# print(df)\n",
    "df.to_csv('~/Documents/Metrics_informativeness.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, info in zip(names, cross_subjects_informativeness_arr):\n",
    "\n",
    "    acc = dict(\n",
    "        sorted(\n",
    "            info.acc().items(),\n",
    "            key=lambda item: item[0]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plt.bar(\n",
    "        acc.keys(),\n",
    "        acc.values()\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    # plt.xticks(range(len(info.acc().keys())))\n",
    "    plt.title(f'Subjects-level prediction accuracy, {name}')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "series = list()\n",
    "names = ['Transitivity, acc, %', 'S metric, acc, %', 'Global Efficiency, acc, %', 'Eigencentrality, acc, %']\n",
    "for info in cross_subjects_informativeness_arr:\n",
    "    series.append(\n",
    "        pd.Series(\n",
    "            dict(\n",
    "                sorted(\n",
    "                    info.acc().items(),\n",
    "                    key=lambda item: item[0]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "df = pd.DataFrame(series, index=names)\n",
    "\n",
    "df = df.T\n",
    "print(df)\n",
    "df.to_csv('/home/user/Documents/Engel1&2_Subject_informativeness.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# wpli + transitivity & envelope + global efficiency\n",
    "subjects = [subject for subject in SUBJECTS if subject.name not in REJECTED]\n",
    "GRAPHS = [\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.cluster.transitivity),\n",
    "    metric_for_hemispheres(subjects, nx.algorithms.global_efficiency),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "#     confusions.append((tn, fp, fn, tp))\n",
    "\n",
    "cross_hemispheres_informativeness = CrossInformativeness()\n",
    "cross_subjects_informativeness = CrossInformativeness()\n",
    "wpli = GRAPHS[0]['transitivity_for_wpli_4-8Hz']\n",
    "envelope = GRAPHS[1]['global_efficiency_for_envelope_4-8Hz']\n",
    "assert all(GRAPHS[0]['resected'] == GRAPHS[1]['resected'])\n",
    "labels = GRAPHS[0]['resected']\n",
    "dataset = pd.concat([wpli, envelope, labels], axis=1)\n",
    "\n",
    "for _ in range(100):\n",
    "    hemispheres_informatoveness = Informativeness()\n",
    "    subjects_informativeness = SubjectsInformativeness()\n",
    "    acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        y = dataset['resected'].to_numpy()\n",
    "        x = dataset[['transitivity_for_wpli_4-8Hz', 'global_efficiency_for_envelope_4-8Hz']].to_numpy()\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x = scaler.fit_transform(x)\n",
    "\n",
    "        samples = [[sample] for sample in dataset.index.tolist()]\n",
    "\n",
    "        x = np.append(x, samples, axis=1)\n",
    "        engel_1_2_set_x, engel_1_2_set_y = list(), list()\n",
    "        test_set_x, test_set_y = list(), list()\n",
    "        for sample_x, sample_y in zip(x, y):\n",
    "            if any([subject in sample_x[-1] for subject in [*ENGEL1, *ENGEL2]]):\n",
    "                engel_1_2_set_x.append(sample_x)\n",
    "                engel_1_2_set_y.append(sample_y)\n",
    "            else:\n",
    "                test_set_x.append(sample_x)\n",
    "                test_set_y.append(sample_y)\n",
    "\n",
    "        x_train, x_test_add, y_train, y_test_add = train_test_split(\n",
    "            engel_1_2_set_x,\n",
    "            engel_1_2_set_y,\n",
    "            train_size=0.5\n",
    "        )\n",
    "        # x_test = test_set_x + x_test_add\n",
    "        # y_test = test_set_y + y_test_add\n",
    "        x_test = x_test_add\n",
    "        y_test = y_test_add\n",
    "        # train_samples, test_samples = x_train[:][2], x_test[:][2]\n",
    "        train_samples = np.array([sample[2] for sample in x_train])\n",
    "        test_samples = np.array([sample[2] for sample in x_test])\n",
    "        x_train = np.array([sample[0:2] for sample in x_train])\n",
    "        x_test = np.array([sample[0:2] for sample in x_test])\n",
    "\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "        acc.append(accuracy_score(y_test, pred))\n",
    "        # if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "        #     spec.append(tn / (tn + fp))\n",
    "        #     sens.append(tp / (tp + fn))\n",
    "        #     negpred.append(tn/(tn + fn))\n",
    "        #     pospred.append(tp/(tp + fp))\n",
    "\n",
    "        for predicted, actual, sample, value in zip(pred, y_test, test_samples, x_test):\n",
    "            hemispheres_informatoveness.informativeness = sample, actual, 'correct' \\\n",
    "            if predicted == actual else 'wrong'\n",
    "            subjects_informativeness.informativeness = sample, actual, 'correct' \\\n",
    "            if predicted == actual else 'wrong'\n",
    "\n",
    "    # print('acc: ', np.array(acc).mean())\n",
    "    cross_subjects_informativeness.informativeness = subjects_informativeness\n",
    "    cross_hemispheres_informativeness.informativeness = hemispheres_informatoveness\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           acc      spec      sens\n",
      "B1C2  0.593741  0.566960  0.661268\n",
      "B1R1  0.943664  0.918529  0.971559\n",
      "G1R1  0.971040  0.967070  0.975110\n",
      "G1V2  0.491887  0.493411  0.458599\n",
      "J1T2  0.472808  0.477791  0.465513\n",
      "K1V1  0.479073  0.300293  0.488148\n",
      "L1P1  0.968103  0.960690  0.975657\n",
      "L2M1  0.646032  0.679241  0.623245\n",
      "M1G2  0.733508  0.945288  0.660555\n",
      "M1N2  0.928267  0.889090  0.975835\n",
      "M2S2  0.683802  0.625087  0.833835\n",
      "N2K2  0.593690  0.879329  0.555618\n",
      "O1O2  0.942102  0.919358  0.968397\n",
      "R1D2  0.957813  0.966650  0.949505\n",
      "S1A2  0.355623  0.408578  0.163627\n",
      "S1B1  0.713685  0.913161  0.643823\n",
      "S1H1  0.466303  0.479497  0.435388\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "    pd.Series(\n",
    "        dict(\n",
    "            sorted(\n",
    "                cross_subjects_informativeness.acc().items(),\n",
    "                key=lambda item: item[0]\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    pd.Series(\n",
    "        dict(\n",
    "            sorted(\n",
    "                cross_subjects_informativeness.tnr().items(),\n",
    "                key=lambda item: item[0]\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    pd.Series(\n",
    "        dict(\n",
    "            sorted(\n",
    "                cross_subjects_informativeness.tpr().items(),\n",
    "                key=lambda item: item[0]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "])\\\n",
    "    .T\\\n",
    "    .rename(\n",
    "    columns={\n",
    "        0: 'acc',\n",
    "        1: 'spec',\n",
    "        2: 'sens'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('/home/user/Documents/cross_hemispheres_analysis_Eng1&2.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# regions wpli+eigen & envelope+percolation\n",
    "\n",
    "path = f'/home/user//Documents/initial_stats.pkl'\n",
    "stats = pickle.load(open(path, 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "stat1 = stats[0]\n",
    "stat2 = stats[-1]\n",
    "\n",
    "cross_subjects_informativeness = CrossInformativeness()\n",
    "\n",
    "for _ in range(100):\n",
    "    features = ['4-8Hz_wpli', '4-8Hz_envelope']\n",
    "\n",
    "    full_true_data_1 = stat1.datasets['true']['4-8Hz_wpli']\n",
    "    full_true_data_2 = stat2.datasets['true']['4-8Hz_envelope']\n",
    "    full_false_data_1 = stat1.datasets['false_mirror']['4-8Hz_wpli']\n",
    "    full_false_data_2 = stat2.datasets['false_mirror']['4-8Hz_envelope']\n",
    "\n",
    "    full_true_data = pd.concat([full_true_data_1, full_true_data_2], axis=1)\n",
    "\n",
    "    full_false_data = pd.concat([full_false_data_1, full_false_data_2], axis=1)\n",
    "\n",
    "    acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "    subjects_informativeness = SubjectsInformativeness()\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        # Engel1&2 - train, the rest - test\n",
    "        scaler = StandardScaler()\n",
    "        clf = svm.SVC(kernel='sigmoid')\n",
    "        engel_1_2_true = full_true_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_true_data.index)].assign(resected=True)\n",
    "        engel_1_2_false = full_false_data.loc[(elem[:4] in [*ENGEL1, *ENGEL2] and not elem[:4] in REJECTED for elem in full_false_data.index)].assign(resected=False)\n",
    "        engel_3_4_true = full_true_data\\\n",
    "            .loc[(elem[:4] not in [*ENGEL1, *ENGEL2, *REJECTED] for elem in full_true_data.index)].assign(resected=True)\n",
    "        engel_3_4_false = full_false_data\\\n",
    "            .loc[(elem[:4] not in [*ENGEL1, *ENGEL2, *REJECTED] for elem in full_false_data.index)].assign(resected=False)\n",
    "        engel_1_2 = pd.concat([engel_1_2_true, engel_1_2_false], axis=0)\n",
    "        engel_1_2_train, engel_1_2_test = np.array_split(engel_1_2.sample(frac=1), 2)\n",
    "        engel_3_4 = pd.concat([engel_3_4_true, engel_3_4_false], axis=0)\n",
    "\n",
    "        y_train = engel_1_2_train['resected'].to_numpy()\n",
    "        x_train = scaler.fit_transform(engel_1_2_train.drop(['resected'], axis=1))\n",
    "\n",
    "        # engel_test = pd.concat([engel_3_4, engel_1_2_test], axis=0).sample(frac=1)\n",
    "        engel_test = engel_1_2_test\n",
    "        test_samples = engel_test.index.to_list()\n",
    "        y_test = engel_test['resected'].to_numpy()\n",
    "        x_test = scaler.fit_transform(engel_test.drop(['resected'], axis=1))\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "\n",
    "        for predicted, actual, sample, value in zip(pred, y_test, test_samples, x_test):\n",
    "            subjects_informativeness.informativeness = sample, actual, 'correct'\\\n",
    "                if predicted == actual else 'wrong'\n",
    "        acc.append(accuracy_score(y_test, pred))\n",
    "\n",
    "        # if not any([tn + fp == 0, tp + fn == 0, tn + fn == 0, tp + fp == 0]):\n",
    "        #     spec.append(tn / (tn + fp))\n",
    "        #     sens.append(tp / (tp + fn))\n",
    "        #     negpred.append(tn/(tn + fn))\n",
    "        #     pospred.append(tp/(tp + fp))\n",
    "    # print('acc: ', np.array(acc).mean())\n",
    "    cross_subjects_informativeness.informativeness = subjects_informativeness"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           acc      spec      sens\n",
      "B1C2  0.506243  0.506624  0.506012\n",
      "B1R1  0.734763  0.735956  0.733580\n",
      "G1R1  0.826107  0.821641  0.830825\n",
      "G1V2  0.683769  0.622493  0.867873\n",
      "J1T2  0.491037  0.441282  0.493418\n",
      "K1V1  0.594397  0.591699  0.597210\n",
      "L1P1  0.599588  0.577812  0.640597\n",
      "L2M1  0.592070  0.571948  0.626103\n",
      "M1G2  0.646031  0.658354  0.635776\n",
      "M1N2  0.652498  0.798278  0.602839\n",
      "M2S2  0.518425  0.509299  0.637586\n",
      "N2K2  0.396261  0.293487  0.431090\n",
      "O1O2  0.584784  0.697479  0.552091\n",
      "R1D2  0.511443  0.503658  0.617442\n",
      "S1A2  0.120297  0.083647  0.151037\n",
      "S1B1  0.536596  0.524226  0.575695\n",
      "S1H1  0.864598  0.810340  0.942361\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame([\n",
    "    pd.Series(\n",
    "        dict(\n",
    "            sorted(\n",
    "                cross_subjects_informativeness.acc().items(),\n",
    "                key=lambda item: item[0]\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    pd.Series(\n",
    "        dict(\n",
    "            sorted(\n",
    "                cross_subjects_informativeness.tnr().items(),\n",
    "                key=lambda item: item[0]\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    pd.Series(\n",
    "        dict(\n",
    "            sorted(\n",
    "                cross_subjects_informativeness.tpr().items(),\n",
    "                key=lambda item: item[0]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "])\\\n",
    "    .T\\\n",
    "    .rename(\n",
    "    columns={\n",
    "        0: 'acc',\n",
    "        1: 'spec',\n",
    "        2: 'sens'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)\n",
    "df.to_csv('/home/user/Documents/cross_regions_analysis_Eng1&2.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}