{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/nilearn/datasets/__init__.py:86: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import re\n",
    "from abc import *\n",
    "from copy import deepcopy\n",
    "from operator import itemgetter\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import mne\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors._dist_metrics import DistanceMetric\n",
    "from sklearn.utils import shuffle\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nodestimation.learning.estimation import collect_statistic, \\\n",
    "    compute_importance, collect_cross_statistic, make_selection_map, \\\n",
    "    select, separate_datasets, selected_statistic, choose_best, selected_data, make_feature_selection\n",
    "from nodestimation.learning.informativeness import CrossInformativeness, Informativeness, SubjectsInformativeness, \\\n",
    "    NodesInformativeness\n",
    "from nodestimation.learning.networking import sparse_graph, graph_to_hemispheres, hemispheres_division_modularity, \\\n",
    "    metric_for_hemispheres\n",
    "from nodestimation.processing.features import prepare_features\n",
    "from nodestimation.project import find_subject_dir, conditions_unique_code\n",
    "from nodestimation.pipeline import pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nibabel\n",
    "import nilearn.plotting as nplt\n",
    "from nodestimation.project.actions import read\n",
    "import nodestimation as nd\n",
    "from nodestimation.learning.modification import append_series, promote\n",
    "import nodestimation.learning.modification as lmd\n",
    "from nodestimation.project.subject import Subject\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib as mpl\n",
    "from nodestimation.learning.selection import SubjectsStatistic, Wilcoxon, Mannwhitneyu, Test\n",
    "from scipy.stats import wilcoxon, spearmanr, pearsonr\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ENGEL1 = [\n",
    "    'B1C2',\n",
    "    'B1R1',\n",
    "    'G1R1',\n",
    "    'G1V2',\n",
    "    'J1T2',\n",
    "    'K1V1',\n",
    "    'L1P1',\n",
    "    'M1G2',\n",
    "    'M1N2',\n",
    "    'O1O2',\n",
    "    'R1D2',\n",
    "    'S1A2',\n",
    "    'S1B1',\n",
    "    'S1H1',\n",
    "    'S1U3'\n",
    "]\n",
    "ENGEL2 = [\n",
    "    'L2M1',\n",
    "    'M2S2',\n",
    "    'N2K2',\n",
    "    'P1H2'\n",
    "]\n",
    "ENGEL3 = [\n",
    "    'N3S2',\n",
    "    'S3R1'\n",
    "]\n",
    "ENGEL4 = [\n",
    "    'K4L2'\n",
    "]\n",
    "REJECTED = [\n",
    "    'S1U3',\n",
    "    'P1H2'\n",
    "]\n",
    "\n",
    "AGE = {\n",
    "    'B1C2': 28.0,\n",
    "    'B1R1': 16.0,\n",
    "    'G1R1': 23.0,\n",
    "    'G1V2': 5.0,\n",
    "    'J1T2': 8.0,\n",
    "    'K1V1': 10.0,\n",
    "    'K4L2': 14.0,\n",
    "    'L1P1': 16.0,\n",
    "    'L2M1': 20.0,\n",
    "    'M1G2': 8.0,\n",
    "    'M1N2': 7.0,\n",
    "    'M2S2': 18.0,\n",
    "    'N2K2': 30.0,\n",
    "    'N3S2': 10.0,\n",
    "    'O1O2': 18.0,\n",
    "    'R1D2': 6.5,\n",
    "    'P1H2': 7.0,\n",
    "    'S1A2': 12.0,\n",
    "    'S1B1': 17.0,\n",
    "    'S1H1': 28.0,\n",
    "    'S3R1': 19.0,\n",
    "    'S1U3': 15.0,\n",
    "}\n",
    "\n",
    "SEX = {\n",
    "    'B1C2': 'f',\n",
    "    'B1R1': 'm',\n",
    "    'G1R1': 'f',\n",
    "    'G1V2': 'm',\n",
    "    'J1T2': 'f',\n",
    "    'K1V1': 'f',\n",
    "    'K4L2': 'f',\n",
    "    'L1P1': 'f',\n",
    "    'L2M1': 'f',\n",
    "    'M1G2': 'm',\n",
    "    'M1N2': 'm',\n",
    "    'M2S2': 'm',\n",
    "    'N2K2': 'm',\n",
    "    'N3S2': 'm',\n",
    "    'O1O2': 'f',\n",
    "    'R1D2': 'f',\n",
    "    'P1H2': 'm',\n",
    "    'S1A2': 'm',\n",
    "    'S1B1': 'm',\n",
    "    'S1H1': 'm',\n",
    "    'S3R1': 'm',\n",
    "    'S1U3': 'f',\n",
    "}\n",
    "\n",
    "ENGEL = dict()\n",
    "for group, i in zip([ENGEL1, ENGEL2, ENGEL3, ENGEL4], range(4)):\n",
    "    ENGEL.update({\n",
    "        subject_name: i+1\n",
    "        for subject_name in group\n",
    "    })\n",
    "\n",
    "\n",
    "def distance(point1: np.ndarray, point2: np.ndarray = np.array([0, 0, 0])) -> float:\n",
    "    return np.sqrt(\n",
    "        np.sum(\n",
    "            np.array([\n",
    "                (coords1 - coords2) ** 2\n",
    "                for coords1, coords2 in zip(point1, point2)\n",
    "            ])\n",
    "        )\n",
    "    )\n",
    "\n",
    "def angle(point1: np.ndarray, point2: np.ndarray, center: np.ndarray = np.array([0, 0, 0])) -> np.ndarray:\n",
    "    a = point1 - center\n",
    "    b = point2 - center\n",
    "    return np.degrees(\n",
    "        np.arccos(\n",
    "            np.around(\n",
    "                np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)),\n",
    "                decimals=8\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def spheric_angles(point: np.ndarray, center: np.ndarray = np.array([0, 0, 0])) -> Union[\n",
    "    Tuple[np.ndarray, np.ndarray], Tuple[float, float]]:\n",
    "    if all(point != center):\n",
    "        proj = point.copy()\n",
    "        proj[2] = center[2]\n",
    "        axis1 = center.copy()\n",
    "        axis1[0] = center[0] + 1\n",
    "        axis2 = center.copy()\n",
    "        axis2[2] = center[2] + 1\n",
    "        return angle(proj, axis1, center), angle(point, axis2, center)\n",
    "    else:\n",
    "        return 0.0, 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All computation has been already done, loading of the existing file with the solution...\n"
     ]
    }
   ],
   "source": [
    "subjects = pipeline(\n",
    "    methods=['wpli', 'envelope', 'coh', 'imcoh', 'plv', 'ciplv', 'ppc', 'pli', 'pli2_unbiased', 'wpli2_debiased'],\n",
    "    freq_bands=(4, 8),\n",
    "    centrality_metrics=['eigen', 'between', 'degree', 'info']\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph done\n"
     ]
    }
   ],
   "source": [
    "DATASET = metric_for_hemispheres(subjects, nx.algorithms.global_efficiency)\n",
    "print('graph done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "HEMISPHERE = {\n",
    "    sample[:4]: sample[5:]\n",
    "    for sample in DATASET.index\n",
    "    if DATASET.loc[sample]['resected']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "modularity_env, modularity_wpli = dict(), dict()\n",
    "freq = '4-8Hz'\n",
    "\n",
    "for subject in subjects:\n",
    "    for method in ['wpli', 'envelope']:\n",
    "        label_names = list(subject.connectomes[freq][method].index)\n",
    "        mapping = {\n",
    "            i: label_name\n",
    "            for i, label_name in zip(\n",
    "                range(len(label_names)),\n",
    "                label_names\n",
    "            )\n",
    "        }\n",
    "        G = sparse_graph(\n",
    "            nx.convert_matrix.from_numpy_matrix(\n",
    "                subject.connectomes[freq][method].to_numpy()\n",
    "            )\n",
    "        )\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        modularity = {\n",
    "            'wpli': modularity_wpli,\n",
    "            'envelope': modularity_env\n",
    "        }[method]\n",
    "        modularity.update({\n",
    "            # subject.name: hemispheres_division_modularity(G)\n",
    "            subject.name: nx.algorithms.smetric.s_metric(G, normalized=False)\n",
    "        })\n",
    "\n",
    "# print(lmd.dict_to_str(modularity_env))\n",
    "# print(lmd.dict_to_str(modularity_wpli))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataset = DATASET.copy()\n",
    "\n",
    "for sample in dataset.index:\n",
    "    subject = sample[:4]\n",
    "    if subject in REJECTED:\n",
    "        dataset = dataset.drop(index=sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cross_hemispheres_informativeness = CrossInformativeness()\n",
    "cross_subjects_informativeness = CrossInformativeness()\n",
    "\n",
    "for _ in range(100):\n",
    "    hemispheres_informatoveness = Informativeness()\n",
    "    subjects_informativeness = SubjectsInformativeness()\n",
    "    acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        y = dataset['resected'].to_numpy()\n",
    "        x = dataset[[f'global_efficiency_for_wpli_4-8Hz', f'global_efficiency_for_envelope_4-8Hz']].to_numpy()\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x = scaler.fit_transform(x)\n",
    "\n",
    "        samples = [[sample] for sample in dataset.index.tolist()]\n",
    "\n",
    "        x = np.append(x, samples, axis=1)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "        train_samples, test_samples = x_train[:, 2], x_test[:, 2]\n",
    "        x_train, x_test = x_train[:, 0:2], x_test[:, 0:2]\n",
    "\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "\n",
    "        for predicted, actual, sample, value in zip(pred, y_test, test_samples, x_test):\n",
    "            hemispheres_informatoveness.informativeness = sample, actual, 'correct' if predicted == actual else 'wrong'\n",
    "            subjects_informativeness.informativeness = sample, actual, 'correct' if predicted == actual else 'wrong'\n",
    "\n",
    "    cross_subjects_informativeness.informativeness = subjects_informativeness\n",
    "    cross_hemispheres_informativeness.informativeness = hemispheres_informatoveness"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "deepest_regions = dict()\n",
    "n_regions = dict()\n",
    "weight = dict()\n",
    "height = dict()\n",
    "omega_row = dict()\n",
    "phi_row = dict()\n",
    "theta_row = dict()\n",
    "vol = dict()\n",
    "density = dict()\n",
    "\n",
    "dists2coords = dict()\n",
    "\n",
    "for subject in subjects:\n",
    "    dists2coords = dict()\n",
    "    if subject.name in REJECTED:\n",
    "        continue\n",
    "    else:\n",
    "        for node in subject.nodes:\n",
    "            if node.type == 'resected':\n",
    "                dists2coords.update({\n",
    "                    distance(node.center_coordinates): node.center_coordinates\n",
    "                })\n",
    "        dists2coords = dict(\n",
    "            sorted(\n",
    "                dists2coords.items(),\n",
    "                key=lambda item: item[0]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        deepest_region = list(dists2coords.values())[-1]\n",
    "        shallowest_region = list(dists2coords.values())[0]\n",
    "        phi, theta = spheric_angles(shallowest_region, deepest_region)\n",
    "        phi_row.update({\n",
    "            subject.name: phi\n",
    "        })\n",
    "        theta_row.update({\n",
    "            subject.name: theta\n",
    "        })\n",
    "        omega = angle(deepest_region, shallowest_region)\n",
    "        omega_row.update({\n",
    "            subject.name: omega\n",
    "        })\n",
    "        deepest_regions.update({\n",
    "            subject.name: list(dists2coords.keys())[-1]\n",
    "        })\n",
    "        height.update({\n",
    "            subject.name: distance(shallowest_region, deepest_region)\n",
    "        })\n",
    "        size = 0\n",
    "        weight_all = 0\n",
    "        weight_ra = 0\n",
    "\n",
    "        for node in subject.nodes:\n",
    "\n",
    "            weight_all += 1/distance(node.center_coordinates)\n",
    "\n",
    "            if node.type == 'resected':\n",
    "                weight_ra += 1/distance(node.center_coordinates)\n",
    "                size += 1\n",
    "\n",
    "        n_regions.update({\n",
    "            subject.name: size\n",
    "        })\n",
    "        weight.update({\n",
    "            subject.name: weight_ra/weight_all\n",
    "        })\n",
    "        vol.update({\n",
    "            subject.name: size*distance(shallowest_region, deepest_region)\n",
    "        })\n",
    "        density.update({\n",
    "            subject.name: weight_ra/weight_all*distance(shallowest_region, deepest_region)\n",
    "        })\n",
    "\n",
    "max = np.max(np.array(list(deepest_regions.values())))\n",
    "min = np.min(np.array(list(deepest_regions.values())))\n",
    "\n",
    "deepest_regions_norm = {\n",
    "    item[0]: 1 - (item[1] - min)/(max - min)\n",
    "    for item in deepest_regions.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      accuracy     depth size    weight     height      volume   density  \\\n",
      "B1C2  0.449247  0.089017    5  0.021657  56.739396   283.69698  1.228791   \n",
      "B1R1  0.980828  0.578577    2  0.011369  22.200947   44.401893  0.252402   \n",
      "G1R1       1.0  0.477518    2  0.011622  52.021366  104.042732  0.604582   \n",
      "G1V2  0.495675  0.667041    2  0.012261  33.316376   66.632752  0.408482   \n",
      "J1T2  0.721876  0.766211    1   0.00627        0.0         0.0       0.0   \n",
      "K1V1  0.505606  0.464549    6  0.033831  52.019901  312.119406  1.759896   \n",
      "K4L2  0.382894  0.371184    4  0.021262  36.040868   144.16347  0.766299   \n",
      "L1P1  0.961744  0.710195    4  0.026613  20.567457   82.269827  0.547355   \n",
      "L2M1  0.435907       1.0    1  0.007899        0.0         0.0       0.0   \n",
      "M1G2  0.774668       0.0    4  0.016583  49.103955  196.415821  0.814299   \n",
      "M1N2  0.958092   0.74731    2  0.012591  17.943396   35.886791   0.22593   \n",
      "M2S2  0.909667  0.794608    1  0.006377        0.0         0.0       0.0   \n",
      "N2K2  0.921997  0.696135    1  0.005954        0.0         0.0       0.0   \n",
      "N3S2  0.024211  0.318136    4  0.022414  62.232727  248.930907  1.394894   \n",
      "O1O2  0.980084  0.386362    1  0.004829        0.0         0.0       0.0   \n",
      "R1D2  0.961165  0.809041    1  0.006643        0.0         0.0       0.0   \n",
      "S1A2  0.464835  0.708157    1  0.005913        0.0         0.0       0.0   \n",
      "S1B1  0.710506   0.47775    4  0.022533  44.447704  177.790814  1.001553   \n",
      "S1H1  0.464806  0.972713    2  0.016488  15.339247   30.678495  0.252921   \n",
      "S3R1  0.521168  0.539719    6  0.037028  85.707276  514.243657  3.173562   \n",
      "\n",
      "             phi       theta       omega   age  sex  hemisphere engel  \n",
      "B1C2   69.003081   37.151389   39.535291  28.0    1           0     1  \n",
      "B1R1   75.509835   99.062515   19.769994  16.0    0           0     1  \n",
      "G1R1    61.45909   128.34409   47.523235  23.0    1           1     1  \n",
      "G1V2   51.579635  123.605846   32.972962   5.0    0           0     1  \n",
      "J1T2         0.0         0.0         0.0   8.0    1           1     1  \n",
      "K1V1  116.794847  121.764251   47.518648  10.0    1           0     1  \n",
      "K4L2  151.835236  129.755916   28.366793  14.0    1           1     4  \n",
      "L1P1  138.458536  131.704665   15.590978  16.0    1           0     1  \n",
      "L2M1         0.0         0.0         0.0  20.0    1           1     2  \n",
      "M1G2   65.525325  119.377476   30.862382   8.0    0           0     1  \n",
      "M1N2  152.439031   59.760913   18.392163   7.0    0           0     1  \n",
      "M2S2         0.0         0.0         0.0  18.0    0           0     2  \n",
      "N2K2         0.0         0.0         0.0  30.0    0           1     2  \n",
      "N3S2   78.457684  122.571326   53.908287  10.0    0           0     3  \n",
      "O1O2         0.0         0.0         0.0  18.0    1           0     1  \n",
      "R1D2         0.0         0.0         0.0   6.5    1           0     1  \n",
      "S1A2         0.0         0.0         0.0  12.0    0           1     1  \n",
      "S1B1  109.902875  102.528309   39.793557  17.0    0           0     1  \n",
      "S1H1   75.023009   55.852122   18.366888  28.0    0           0     1  \n",
      "S3R1  124.939303   65.686772  105.816814  19.0    0           0     3  \n",
      "\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between engel and accuracy\n",
      "SpearmannCorrCoef: -0.44622694435662114\n",
      "Spearmann p-val: 0.048592596323917485\n",
      "PearsonCorrCoef: -0.49349264087899714\n",
      "Pearson p-val: 0.02702116246060935\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between hemisphere and accuracy\n",
      "SpearmannCorrCoef: -0.13245323570650436\n",
      "Spearmann p-val: 0.5777527094497387\n",
      "PearsonCorrCoef: -0.06471626838296056\n",
      "Pearson p-val: 0.7863385498299382\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between sex and accuracy\n",
      "SpearmannCorrCoef: 0.07843304784240031\n",
      "Spearmann p-val: 0.742394077693133\n",
      "PearsonCorrCoef: 0.09959493388873236\n",
      "Pearson p-val: 0.6761194693998642\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between age and accuracy\n",
      "SpearmannCorrCoef: -0.010546158061163444\n",
      "Spearmann p-val: 0.9648024027889406\n",
      "PearsonCorrCoef: 0.0535292734459691\n",
      "Pearson p-val: 0.8226514144818211\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between omega and accuracy\n",
      "SpearmannCorrCoef: -0.2273951389939709\n",
      "Spearmann p-val: 0.33495906844673196\n",
      "PearsonCorrCoef: -0.38425032059022846\n",
      "Pearson p-val: 0.09438602674073458\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between phi and accuracy\n",
      "SpearmannCorrCoef: -0.13059855955734817\n",
      "Spearmann p-val: 0.5831377109252506\n",
      "PearsonCorrCoef: -0.15902717498936605\n",
      "Pearson p-val: 0.50306192455137\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between theta and accuracy\n",
      "SpearmannCorrCoef: -0.05531233110664158\n",
      "Spearmann p-val: 0.8168383245947751\n",
      "PearsonCorrCoef: -0.19370920910373002\n",
      "Pearson p-val: 0.41318146196343003\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between volume and accuracy\n",
      "SpearmannCorrCoef: -0.2827074701006125\n",
      "Spearmann p-val: 0.22715207949067712\n",
      "PearsonCorrCoef: -0.4434211461044387\n",
      "Pearson p-val: 0.050197968827804994\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between density and accuracy\n",
      "SpearmannCorrCoef: -0.327264625714296\n",
      "Spearmann p-val: 0.15899115574812644\n",
      "PearsonCorrCoef: -0.4250681434500597\n",
      "Pearson p-val: 0.06172030750202818\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between height and accuracy\n",
      "SpearmannCorrCoef: -0.2427596754124825\n",
      "Spearmann p-val: 0.3024093510721686\n",
      "PearsonCorrCoef: -0.41475682422324134\n",
      "Pearson p-val: 0.06901449912693178\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between weight and accuracy\n",
      "SpearmannCorrCoef: -0.31879699248120297\n",
      "Spearmann p-val: 0.1706978721400242\n",
      "PearsonCorrCoef: -0.402938157419217\n",
      "Pearson p-val: 0.07814957280918289\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between size and accuracy\n",
      "SpearmannCorrCoef: -0.2928356244127347\n",
      "Spearmann p-val: 0.21021839152879873\n",
      "PearsonCorrCoef: -0.4096949216466871\n",
      "Pearson p-val: 0.07282335929037416\n",
      "\n",
      "*****************\n",
      "\n",
      "Correlation between depth and accuracy\n",
      "SpearmannCorrCoef: 0.12180451127819547\n",
      "Spearmann p-val: 0.608956622164901\n",
      "PearsonCorrCoef: 0.1640479432105097\n",
      "Pearson p-val: 0.48949604387212214\n",
      "\n",
      "*****************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "series = list()\n",
    "names = [\n",
    "    'accuracy',\n",
    "    'depth',\n",
    "    'size',\n",
    "    'weight',\n",
    "    'height',\n",
    "    'volume',\n",
    "    'density',\n",
    "    'phi',\n",
    "    'theta',\n",
    "    'omega',\n",
    "    'age',\n",
    "    'sex',\n",
    "    'hemisphere',\n",
    "    'engel',\n",
    "]\n",
    "\n",
    "age = AGE.copy()\n",
    "engel = ENGEL.copy()\n",
    "sex = SEX.copy()\n",
    "hemisphere = HEMISPHERE.copy()\n",
    "\n",
    "for subject_name in REJECTED:\n",
    "    age.pop(subject_name)\n",
    "    engel.pop(subject_name)\n",
    "    sex.pop(subject_name)\n",
    "    hemisphere.pop(subject_name)\n",
    "\n",
    "for data in [\n",
    "    cross_subjects_informativeness.acc(),\n",
    "    deepest_regions_norm,\n",
    "    n_regions,\n",
    "    weight,\n",
    "    height,\n",
    "    vol,\n",
    "    density,\n",
    "    phi_row,\n",
    "    theta_row,\n",
    "    omega_row,\n",
    "    age,\n",
    "    sex,\n",
    "    hemisphere,\n",
    "    engel\n",
    "]:\n",
    "    series.append(\n",
    "        dict(\n",
    "            sorted(\n",
    "                data.items(),\n",
    "                key=lambda item: item[0]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "df = pd.DataFrame(\n",
    "    series,\n",
    "    index=names\n",
    ")\n",
    "df = df.T\n",
    "df['sex'] = [int(sample == 'f') for sample in df['sex']]\n",
    "df['hemisphere'] = [int(sample == 'lh') for sample in df['hemisphere']]\n",
    "print(df)\n",
    "df.to_csv('~/Documents/Global_efficiency_subjects_informativeness_all_data.csv')\n",
    "\n",
    "sep = '\\n\\n*****************\\n'\n",
    "print(sep)\n",
    "for param in [\n",
    "    'engel',\n",
    "    'hemisphere',\n",
    "    'sex',\n",
    "    'age',\n",
    "    'omega',\n",
    "    'phi',\n",
    "    'theta',\n",
    "    'volume',\n",
    "    'density',\n",
    "    'height',\n",
    "    'weight',\n",
    "    'size',\n",
    "    'depth'\n",
    "]:\n",
    "\n",
    "    s_corr, s_p = spearmanr(df[param].to_numpy(), df['accuracy'].to_numpy())\n",
    "    p_corr, p_p = pearsonr(df[param].to_numpy(), df['accuracy'].to_numpy())\n",
    "    print(f'Correlation between {param} and accuracy\\n'\n",
    "          f'SpearmannCorrCoef: {s_corr}\\nSpearmann p-val: {s_p}\\n'\n",
    "          f'PearsonCorrCoef: {p_corr}\\nPearson p-val: {p_p}{sep}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for param in ['age', 'size', 'depth', 'weight']:\n",
    "    s_corr, s_p = spearmanr(df[param].to_numpy(), df['engel'].to_numpy())\n",
    "    p_corr, p_p = pearsonr(df[param].to_numpy(), df['engel'].to_numpy())\n",
    "    print(f'Correlation between {param} and engel\\n'\n",
    "          f'SpearmannCorrCoef: {s_corr}\\nSpearmann p-val: {s_p}\\n'\n",
    "          f'PearsonCorrCoef: {p_corr}\\nPearson p-val: {p_p}{sep}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [d, a]\n",
    "    for d, a in zip(\n",
    "        df['depth'].to_numpy(),\n",
    "        df['age'].to_numpy()\n",
    "    )\n",
    "])\n",
    "y = df[['accuracy']].to_numpy()\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "\n",
    "print('Linear model for depth and age to accuracy')\n",
    "print(f'score: {reg.score(X, y)}')\n",
    "print(f'coef: {reg.coef_}')\n",
    "# intercept is the expected mean value when X=0\n",
    "print(f'intercept: {reg.intercept_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model for accuracy\n",
      "score: 0.7704063414905848\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [\n",
    "        d,\n",
    "        s,\n",
    "        w,\n",
    "        a,\n",
    "        e,\n",
    "        g,\n",
    "        p,\n",
    "        t,\n",
    "        o,\n",
    "        h,\n",
    "        r,\n",
    "        v,\n",
    "        hm\n",
    "    ]\n",
    "    for d,\n",
    "        s,\n",
    "        w,\n",
    "        a,\n",
    "        e,\n",
    "        g,\n",
    "        p,\n",
    "        t,\n",
    "        o,\n",
    "        h,\n",
    "        r,\n",
    "        v,\n",
    "        hm in zip(\n",
    "        df['depth'].to_numpy(),\n",
    "        df['size'].to_numpy(),\n",
    "        df['weight'].to_numpy(),\n",
    "        df['age'].to_numpy(),\n",
    "        df['engel'].to_numpy(),\n",
    "        df['sex'].to_numpy(),\n",
    "        df['phi'].to_numpy(),\n",
    "        df['theta'].to_numpy(),\n",
    "        df['omega'].to_numpy(),\n",
    "        df['height'].to_numpy(),\n",
    "        df['density'].to_numpy(),\n",
    "        df['volume'].to_numpy(),\n",
    "        df['hemisphere'].to_numpy(),\n",
    "    )\n",
    "])\n",
    "y = df[['accuracy']].to_numpy()\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "print('Linear model for accuracy')\n",
    "print(f'score: {reg.score(X, y)}')\n",
    "# print(f'coef: {reg.coef_}')\n",
    "# print(f'intercept: {reg.intercept_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model for engel\n",
      "score: 0.7878567357054084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-13ebee5f5847>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array([\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [\n",
    "        d,\n",
    "        s,\n",
    "        w,\n",
    "        a,\n",
    "        g,\n",
    "        p,\n",
    "        t,\n",
    "        o,\n",
    "        h,\n",
    "        r,\n",
    "        ac,\n",
    "        v,\n",
    "        # hm\n",
    "    ]\n",
    "    for d,\n",
    "        s,\n",
    "        w,\n",
    "        a,\n",
    "        g,\n",
    "        p,\n",
    "        t,\n",
    "        o,\n",
    "        h,\n",
    "        r,\n",
    "        ac,\n",
    "        v,\n",
    "        hm in zip(\n",
    "        df['depth'].to_numpy(),\n",
    "        df['size'].to_numpy(),\n",
    "        df['weight'].to_numpy(),\n",
    "        df['age'].to_numpy(),\n",
    "        df['sex'].to_numpy(),\n",
    "        df['phi'].to_numpy(),\n",
    "        df['theta'].to_numpy(),\n",
    "        df['omega'].to_numpy(),\n",
    "        df['height'].to_numpy(),\n",
    "        df['density'].to_numpy(),\n",
    "        df[['accuracy']].to_numpy(),\n",
    "        df['volume'].to_numpy(),\n",
    "        df['hemisphere'].to_numpy(),\n",
    "    )\n",
    "])\n",
    "y = df[['engel']].to_numpy()\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "print('Linear model for engel')\n",
    "print(f'score: {reg.score(X, y)}')\n",
    "# print(f'coef: {reg.coef_}')\n",
    "# print(f'intercept: {reg.intercept_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "names = [\n",
    "    # 'depth',\n",
    "    # 'size',\n",
    "    'age',\n",
    "    'weight',\n",
    "    'engel',\n",
    "    'sex',\n",
    "    'accuracy'\n",
    "]\n",
    "\n",
    "for name in names:\n",
    "    y = df[name].to_numpy()\n",
    "    parameters = [p for p in names if p != name]\n",
    "    X = np.array([\n",
    "        [\n",
    "            p1,\n",
    "            p2,\n",
    "            p3,\n",
    "            p4,\n",
    "            # p5,\n",
    "            # p6\n",
    "        ]\n",
    "        for p1,\n",
    "            p2,\n",
    "            p3,\n",
    "            p4,\n",
    "            # p5,\n",
    "            # p6\n",
    "        in zip(\n",
    "            df[parameters[0]].to_numpy(),\n",
    "            df[parameters[1]].to_numpy(),\n",
    "            df[parameters[2]].to_numpy(),\n",
    "            df[parameters[3]].to_numpy(),\n",
    "            # df[parameters[4]].to_numpy(),\n",
    "            # df[parameters[5]].to_numpy()\n",
    "        )\n",
    "    ])\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "\n",
    "    print(name, ': ', reg.score(X, y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [s, e]\n",
    "    for s, e in zip(\n",
    "        df['size'].to_numpy(),\n",
    "        df['engel'].to_numpy()\n",
    "    )\n",
    "])\n",
    "y = df[['accuracy']].to_numpy()\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "print('Linear model for size and engel to accuracy')\n",
    "print(f'score: {reg.score(X, y)}')\n",
    "print(f'coef: {reg.coef_}')\n",
    "print(f'intercept: {reg.intercept_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [s, d, a]\n",
    "    for s, d, a, g in zip(\n",
    "        df['size'].to_numpy(),\n",
    "        df['depth'].to_numpy(),\n",
    "        df['age'].to_numpy(),\n",
    "        df['sex'].to_numpy(),\n",
    "    )\n",
    "])\n",
    "y = df[['engel']].to_numpy()\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "\n",
    "print('Linear model for size and depth to engel')\n",
    "print(f'score: {reg.score(X, y)}')\n",
    "print(f'coef: {reg.coef_}')\n",
    "print(f'intercept: {reg.intercept_}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}