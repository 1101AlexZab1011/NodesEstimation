{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import mne\n",
    "import nilearn.plotting as nplt\n",
    "import nilearn.image as image\n",
    "import pickle\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs, corrmap)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nodestimation.node_estimate import Node\n",
    "from nodestimation.timewindow import TimeWindow, sliding_window\n",
    "import nibabel as nib\n",
    "from nodestimation.parcellation import freesurf_dict\n",
    "import matplotlib.pyplot as plt\n",
    "import nodestimation.project.path as path\n",
    "from nodestimation.project.actions import save, read, save_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing project structure...\n",
      "\tSubject:  B1C2\n",
      "\t\tTrans file: ok\n",
      "\t\tFwd file: ok\n",
      "\t\tSrc file: ok\n",
      "\t\tBem file: ok\n",
      "\t\tRaw file: ok\n",
      "\t\tResec file: ok\n",
      "\tFiles structure for B1C2 has been analysed. Files tree is built\n",
      "./Source/Subjects/B1C2/B1C2_ii_run1_raw_tsss_mc_art_corr_raw.fif\n"
     ]
    }
   ],
   "source": [
    "subjects_dir, subjects = path.found_subject_dir()\n",
    "tree = path.build_resources_tree(subjects)\n",
    "print(tree['B1C2'][1]['raw'])\n",
    "\n",
    "\n",
    "# print(path.build_resources_tree(subjects))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for original raw file in files tree...\n",
      "Original raw file has been found. trying to read...\n",
      "Opening raw data file ./Source/Subjects/B1C2/B1C2_ii_run1_raw_tsss_mc_art_corr_raw.fif...\n",
      "    Range : 39000 ... 1257999 =     39.000 ...  1257.999 secs\n",
      "Ready.\n",
      "Successfully read\n",
      "original:\n",
      "<Info | 24 non-empty values\n",
      " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
      " acq_stim: 7 800.000000 2000.000000\n",
      " bads: []\n",
      " ch_names: MEG0113, MEG0112, MEG0111, MEG0122, MEG0123, MEG0121, MEG0132, ...\n",
      " chs: 204 GRAD, 102 MAG, 7 STIM, 60 EEG, 2 EOG, 1 ECG, 1 EMG, 18 MISC, 9 CHPI\n",
      " custom_ref_applied: False\n",
      " description: Vectorview system at moscow\n",
      " dev_head_t: MEG device -> head transform\n",
      " dig: 151 items (3 Cardinal, 4 HPI, 61 EEG, 83 Extra)\n",
      " events: 1 item (list)\n",
      " experimenter: meg\n",
      " file_id: 4 items (dict)\n",
      " highpass: 0.0 Hz\n",
      " hpi_meas: 1 item (list)\n",
      " hpi_results: 1 item (list)\n",
      " hpi_subsystem: 2 items (dict)\n",
      " line_freq: 50.0\n",
      " lowpass: 330.0 Hz\n",
      " meas_date: 2011-10-11 10:36:23 UTC\n",
      " meas_id: 4 items (dict)\n",
      " nchan: 404\n",
      " proc_history: 1 item (list)\n",
      " proj_id: 1 item (ndarray)\n",
      " proj_name: epilepsy\n",
      " projs: []\n",
      " sfreq: 1000.0 Hz\n",
      " subject_info: 3 items (dict)\n",
      ">\n",
      "Looking for nepf raw file in files tree...\n",
      "The nepf raw file has not been found\n",
      "Creating a new nepf raw file\n",
      "4 events found\n",
      "Event IDs: [64]\n",
      "4 events found\n",
      "Event IDs: [64]\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1321 samples (6.605 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 70 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 70.00 Hz\n",
      "- Upper transition bandwidth: 17.50 Hz (-6 dB cutoff frequency: 78.75 Hz)\n",
      "- Filter length: 661 samples (3.305 sec)\n",
      "\n",
      "Writing /home/ubuntu/PycharmProjects/NodesEstimation/Source/Subjects/B1C2/B1C2_node_estimation_pipeline_file_first_processing_output_raw.fif\n",
      "Closing /home/ubuntu/PycharmProjects/NodesEstimation/Source/Subjects/B1C2/B1C2_node_estimation_pipeline_file_first_processing_output_raw.fif\n",
      "[done]\n",
      "Done. Path to new file: ./Source/Subjects/B1C2/B1C2_node_estimation_pipeline_file_first_processing_output_raw.fif\n",
      "processed:\n",
      "<Info | 24 non-empty values\n",
      " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
      " acq_stim: 7 800.000000 2000.000000\n",
      " bads: []\n",
      " ch_names: MEG0113, MEG0112, MEG0111, MEG0122, MEG0123, MEG0121, MEG0132, ...\n",
      " chs: 204 GRAD, 102 MAG, 60 EEG\n",
      " custom_ref_applied: False\n",
      " description: Vectorview system at moscow\n",
      " dev_head_t: MEG device -> head transform\n",
      " dig: 151 items (3 Cardinal, 4 HPI, 61 EEG, 83 Extra)\n",
      " events: 1 item (list)\n",
      " experimenter: meg\n",
      " file_id: 4 items (dict)\n",
      " highpass: 1.0 Hz\n",
      " hpi_meas: 1 item (list)\n",
      " hpi_results: 1 item (list)\n",
      " hpi_subsystem: 2 items (dict)\n",
      " line_freq: 50.0\n",
      " lowpass: 70.0 Hz\n",
      " meas_date: 2011-10-11 10:36:23 UTC\n",
      " meas_id: 4 items (dict)\n",
      " nchan: 366\n",
      " proc_history: 1 item (list)\n",
      " proj_id: 1 item (ndarray)\n",
      " proj_name: epilepsy\n",
      " projs: []\n",
      " sfreq: 200.0 Hz\n",
      " subject_info: 3 items (dict)\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "from nodestimation.mneraw import read_original_raw, first_processing\n",
    "\n",
    "conductivity = (0.3,)  # for single layer\n",
    "# conductivity = (0.3, 0.006, 0.3)  # for three layers\n",
    "epochs_tmin, epochs_tmax = -15, 15\n",
    "crop_time = 120\n",
    "snr = 0.5  # use SNR smaller than 1 for raw data\n",
    "lambda2 = 1.0 / snr ** 2\n",
    "method = \"sLORETA\"\n",
    "rfreq = 200\n",
    "nfreq = 50\n",
    "lfreq = 1\n",
    "hfreq = 70\n",
    "\n",
    "raw = read_original_raw('./', _subject_tree=tree['B1C2'])\n",
    "print('original:')\n",
    "print(raw.info)\n",
    "fp_raw = first_processing(raw, lfreq, nfreq, hfreq, rfreq=rfreq, crop=crop_time, _subject_tree=tree['B1C2'])\n",
    "print('processed:')\n",
    "print(fp_raw.info)\n",
    "\n",
    "        # if not 'raw' in subject_tree:\n",
    "        #     raise OSError(\"No one of raw files are found. Raw file must have extension \"\n",
    "        #                   \"\\'.fif\\' and contain \\'raw\\' in its name\")\n",
    "        # if not 'resec' in subject_tree and not 'mni-resec' in subject_tree:\n",
    "        #     raise OSError(\"No one of resection files are found. Resection file must have extension \"\n",
    "        #                   \"\\'.nii\\' or  \\'.pkl\\' and contain \\'resec\\' in its name\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root= './'\n",
    "\n",
    "tree = os.walk(os.path.join(root, 'Source'))\n",
    "\n",
    "raw_files = []\n",
    "src_files = []\n",
    "inv_files = []\n",
    "bem_files = []\n",
    "fwd_files = []\n",
    "trans_files = []\n",
    "epochs_files = []\n",
    "ave_files = []\n",
    "stc_files = []\n",
    "\n",
    "subjects_found = False\n",
    "\n",
    "for walk in tree:\n",
    "    for file in walk[2]:\n",
    "        if re.search(r'.*raw\\.fif', file):\n",
    "            raw_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*src.*\\.fif', file) or re.search(r'.*source.*space.*\\.fif', file):\n",
    "            src_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*inv.*\\.fif', file) or re.search(r'.*inverse.*\\.fif', file):\n",
    "            inv_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*bem.*\\.fif', file):\n",
    "            bem_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*fwd.*\\.fif', file) or re.search(r'.*forward.*\\.fif', file):\n",
    "            fwd_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*trans.*\\.fif', file):\n",
    "            trans_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*epo.*\\.fif', file):\n",
    "            epochs_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*ave.*\\.fif', file):\n",
    "            ave_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*stc.*\\.fif.*', file):\n",
    "            stc_files.append(os.path.join(walk[0], file))\n",
    "\n",
    "    for subdir in walk[1]:\n",
    "        if subdir == 'Subjects' or subdir == 'subjects' and not subjects_found:\n",
    "            subjects_found = True\n",
    "            subjects_dir = os.path.join(walk[0], subdir)\n",
    "        elif subdir == 'Subjects' or subdir == 'subjects' and subjects_found:\n",
    "            raise OSError(\"There are two subjects directories: {}, {}; Only one must be\".format(\n",
    "                subjects_dir, os.path.join(walk[0], subdir)\n",
    "            ))\n",
    "\n",
    "if not raw_files:\n",
    "    raise OSError(\"No one of raw files are found. Raw file must have extension \\'.fif\\' and ends with \\'raw\\'\")\n",
    "\n",
    "if not subjects_found:\n",
    "    raise OSError(\"Subjects directory not found!\")\n",
    "subjects = os.listdir(subjects_dir)\n",
    "\n",
    "subject_dirs = []\n",
    "\n",
    "for subject in subjects:\n",
    "    subject_dirs.append(os.path.join(subjects_dir, subject))\n",
    "\n",
    "raw_file = raw_files[0]\n",
    "bem_file = bem_files[0]\n",
    "src_file = src_files[0]\n",
    "fwd_file = fwd_files[0]\n",
    "trans_file = trans_files[0]\n",
    "\n",
    "res_folder = os.path.join(root, 'Pipeline', subjects[0])\n",
    "\n",
    "res_raw_folder = os.path.join(res_folder, 'Raw')\n",
    "res_bem_folder = os.path.join(res_folder, 'Bem')\n",
    "res_src_folder = os.path.join(res_folder, 'Src')\n",
    "res_fwd_folder = os.path.join(res_folder, 'Fwd')\n",
    "res_events_folder = os.path.join(res_folder, 'Events')\n",
    "res_epochs_folder = os.path.join(res_folder, 'Epochs')\n",
    "res_evoked_folder = os.path.join(res_folder, 'Evoked')\n",
    "res_cov_folder = os.path.join(res_folder, 'Cov')\n",
    "res_inv_folder = os.path.join(res_folder, 'Inv')\n",
    "res_sLORETA_folder = os.path.join(res_folder, 'sLORETA')\n",
    "res_nodes_folder = os.path.join(res_folder, 'NodesEstimate')\n",
    "res_resec_folder = os.path.join(res_folder, 'Resection')\n",
    "\n",
    "res_raw_file = os.path.join(res_raw_folder, 'raw.fif')\n",
    "res_bem_file = os.path.join(res_bem_folder, 'raw_bem.fif')\n",
    "res_src_file = os.path.join(res_src_folder, 'raw_src_ico5.fif')\n",
    "res_fwd_file = os.path.join(res_fwd_folder, 'raw_fwd_ico5.fif')\n",
    "res_events_file = os.path.join(res_events_folder, 'raw_eve.fif')\n",
    "res_epochs_file = os.path.join(res_epochs_folder, 'raw_epo.fif')\n",
    "res_evoked_file = os.path.join(res_evoked_folder, 'raw_ave.fif')\n",
    "res_cov_file = os.path.join(res_cov_folder, 'noise_cov.fif')\n",
    "res_inv_file = os.path.join(res_inv_folder, 'raw_inv.fif')\n",
    "res_sLORETA_file = os.path.join(res_sLORETA_folder, 'sLORETA_raw_ave_inv.pkl')\n",
    "res_nodes_strength_file = os.path.join(res_nodes_folder, 'nodes_strength_auc.dat')\n",
    "res_pearson_nodes_file = os.path.join(res_nodes_folder, 'pearson_nodes.pkl')\n",
    "res_plv_nodes_file = os.path.join(res_nodes_folder, 'plv_nodes.pkl')\n",
    "res_resec_file = os.path.join(res_resec_folder, 'resection.pkl')\n",
    "\n",
    "subject_dir = subject_dirs[0]\n",
    "subject = subjects[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "conductivity = (0.3,)  # for single layer\n",
    "# conductivity = (0.3, 0.006, 0.3)  # for three layers\n",
    "epochs_tmin, epochs_tmax = -15, 15\n",
    "crop_time = 120\n",
    "snr = 0.5  # use SNR smaller than 1 for raw data\n",
    "lambda2 = 1.0 / snr ** 2\n",
    "method = \"sLORETA\"\n",
    "rfreq = 200\n",
    "nfreq = 50\n",
    "lfreq = 1\n",
    "hfreq = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from os import mkdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./Pipeline'):\n",
    "    mkdir('./Pipeline')\n",
    "\n",
    "if not os.path.exists(res_folder):\n",
    "    mkdir(res_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_raw_file):\n",
    "    raw = mne.io.read_raw_fif(res_raw_file)\n",
    "\n",
    "elif os.path.isfile(raw_file):\n",
    "    raw = mne.io.read_raw_fif(raw_file)\n",
    "    raw.resample(rfreq, npad='auto')\n",
    "    raw = first_processing(raw)\n",
    "    path = res_raw_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    raw.save(res_raw_file)\n",
    "\n",
    "else:\n",
    "    raise OSError('PIPELINE: Raw-file not found')\n",
    "\n",
    "\n",
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_src_file):\n",
    "    src = mne.read_source_spaces(res_src_file)\n",
    "\n",
    "elif os.path.isfile(src_file):\n",
    "    src = mne.read_source_spaces(src_file)\n",
    "    path = res_src_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    src.save(res_src_file)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Source spaces not found, creating a new one...')\n",
    "    src = mne.setup_source_space(subject, spacing='ico5', add_dist='patch', subjects_dir=subjects_dir)\n",
    "    path = res_src_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    src.save(res_src_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_bem_file):\n",
    "    bem = mne.read_bem_solution(res_bem_file)\n",
    "\n",
    "elif os.path.isfile(bem_file):\n",
    "    bem = mne.read_bem_solution(bem_file)\n",
    "    path = res_bem_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_bem_solution(res_bem_file, bem)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: BEM-surface not found, creating a new one...')\n",
    "    model = mne.make_bem_model(subject=subject, ico=4, conductivity=conductivity, subjects_dir=subject_dir)\n",
    "    bem = mne.make_bem_solution(model)\n",
    "    path = res_bem_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_bem_solution(res_bem_file, bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_fwd_file):\n",
    "    fwd = mne.read_forward_solution(res_fwd_file)\n",
    "\n",
    "elif os.path.isfile(fwd_file):\n",
    "    fwd = mne.read_forward_solution(fwd_file)\n",
    "    path = res_fwd_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_forward_solution(res_fwd_file, fwd)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Forward solution not found, creating a new one...')\n",
    "    fwd = mne.make_forward_solution(res_raw_file, trans=trans_file, src=src, bem=bem, meg=True, eeg=False,\n",
    "                                    mindist=5.0, n_jobs=1, verbose=True)\n",
    "    path = res_fwd_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_forward_solution(res_fwd_file, fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "events = np.array([[\n",
    "        raw.first_samp + raw.time_as_index(i)[0],\n",
    "        0,\n",
    "        1\n",
    "    ] for i in range(1, 59)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_epochs_file):\n",
    "    epochs = mne.read_epochs(res_epochs_file)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Epochs not found, creating a new one...')\n",
    "    epochs = mne.Epochs(raw, events, tmin=-1, tmax=1,\n",
    "                        preload=True)\n",
    "    path = res_epochs_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    epochs.save(res_epochs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_evoked_file):\n",
    "    evoked = mne.read_evokeds(res_evoked_file)\n",
    "else:\n",
    "    print('PIPELINE: Evokeds not found, creating a new one...')\n",
    "    evoked = epochs.average()\n",
    "    path = res_evoked_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_evokeds(res_evoked_file, evoked)\n",
    "\n",
    "    evoked = [evoked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# evoked[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_cov_file):\n",
    "    noise_cov = mne.read_cov(res_cov_file)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Noise covariance not found, creating a new one...')\n",
    "    noise_cov = mne.compute_covariance(epochs.copy().pick_types(meg=True, eeg=False, eog=False), tmin=-1, tmax=0,\n",
    "                                       method='empirical')\n",
    "    path = res_cov_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_cov(res_cov_file, noise_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_inv_file):\n",
    "    inv = mne.minimum_norm.read_inverse_operator(res_inv_file)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Inverse operator not found, creating a new one...')\n",
    "    inv = mne.minimum_norm.make_inverse_operator(epochs.info, fwd, noise_cov, depth=None, fixed=False)\n",
    "    path = res_inv_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.minimum_norm.write_inverse_operator(res_inv_file, inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if os.path.isfile(res_sLORETA_file):\n",
    "    print('Reading sLORETA solution...')\n",
    "    stc = pickle.load(open(res_sLORETA_file, 'rb'))\n",
    "    print('sLORETA has been read')\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: sLORETA not found, creating a new one...')\n",
    "    stc = mne.minimum_norm.apply_inverse_epochs(epochs,\n",
    "                                         inv,\n",
    "                                         lambda2,\n",
    "                                         'sLORETA',\n",
    "                                         pick_ori=None\n",
    "                                         )\n",
    "    path = res_sLORETA_folder\n",
    "\n",
    "    mkdir(path)\n",
    "    pickle.dump(stc, open(res_sLORETA_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "labels_parc = mne.read_labels_from_annot(subject, parc='aparc', subjects_dir=subjects_dir)\n",
    "\n",
    "# label_tc = stc.extract_label_time_course(labels_parc, src, mode='mean_flip')\n",
    "\n",
    "label_ts = mne.extract_label_time_course(stc, labels_parc, src, mode='mean_flip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(label_ts[0].shape)\n",
    "\n",
    "plt.plot(np.arange(401), label_ts[0][10].T, np.arange(401), label_ts[0][36].T)\n",
    "plt.show()\n",
    "plt.plot(np.arange(401), label_ts[1][10].T, np.arange(401), label_ts[1][36].T)\n",
    "plt.show()\n",
    "plt.plot(np.arange(401), label_ts[2][10].T, np.arange(401), label_ts[2][36].T)\n",
    "plt.show()\n",
    "plt.plot(np.arange(401), label_ts[3][10].T, np.arange(401), label_ts[3][36].T)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels_aseg = mne.get_volume_labels_from_src(src, subject, subjects_dir)\n",
    "\n",
    "labels = labels_parc + labels_aseg\n",
    "\n",
    "label_names = [label.name for label in labels]\n",
    "\n",
    "lh_labels = [name for name in label_names if name.endswith('lh')]\n",
    "\n",
    "rh_labels = [name for name in label_names if name.endswith('rh')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fmin = 30\n",
    "fmax = 70\n",
    "sfreq = 200\n",
    "\n",
    "con, freqs, times, n_epochs, n_tapers = mne.connectivity.spectral_connectivity(\n",
    "    label_ts, method='plv', mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
    "    fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "label_ypos_lh = list()\n",
    "\n",
    "for name in lh_labels:\n",
    "    idx = label_names.index(name)\n",
    "    ypos = np.mean(labels[idx].pos[:, 1])\n",
    "    label_ypos_lh.append(ypos)\n",
    "\n",
    "try:\n",
    "    idx = label_names.index('Brain-Stem')\n",
    "\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    ypos = np.mean(labels[idx].pos[:, 1])\n",
    "    lh_labels.append('Brain-Stem')\n",
    "    label_ypos_lh.append(ypos)\n",
    "\n",
    "\n",
    "lh_labels = [label for (yp, label) in sorted(zip(label_ypos_lh, lh_labels))]\n",
    "\n",
    "rh_labels = [label[:-2] + 'rh' for label in lh_labels\n",
    "             if label != 'Brain-Stem' and label[:-2] + 'rh' in rh_labels]\n",
    "\n",
    "\n",
    "node_colors = [label.color for label in labels]\n",
    "\n",
    "node_order = lh_labels[::-1] + rh_labels\n",
    "\n",
    "node_angles = mne.viz.circular_layout(label_names, node_order, start_pos=90,\n",
    "                              group_boundaries=[0, len(label_names) // 2])\n",
    "conmat = con[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(67):\n",
    "    print((conmat[:, i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(8, 8), facecolor='black')\n",
    "mne.viz.plot_connectivity_circle(conmat, label_names, n_lines=300,\n",
    "                         node_angles=node_angles, node_colors=node_colors,\n",
    "                         title='All-to-All Connectivity Epilepsy '\n",
    "                         'Condition (PLV)', fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# fmin = 30.\n",
    "# fmax = 50.\n",
    "# sfreq = 200\n",
    "#\n",
    "# con, freqs, times, n_epochs, n_tapers = mne.connectivity.spectral_connectivity(\n",
    "#     label_ts, method='plv', mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
    "#     fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(num=None, figsize=(8, 8), facecolor='black')\n",
    "# mne.viz.plot_connectivity_circle(conmat, label_names, n_lines=300,\n",
    "#                          node_angles=node_angles, node_colors=node_colors,\n",
    "#                          title='All-to-All Connectivity Epilepsy '\n",
    "#                          'Condition (PLV)', fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# nodes strength\n",
    "\n",
    "# plt.plot(n_strength, 'o')\n",
    "# plt.title('Node Strength')\n",
    "# plt.xlabel('node: number')\n",
    "# plt.ylabel('node: strength')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## compute roc curve\n",
    "# resected_nodes = 15\n",
    "#\n",
    "# label_ind = np.zeros(len(n_strength))\n",
    "# label_ind[0:resected_nodes] = True\n",
    "# label_ind[resected_nodes+1:] = False\n",
    "# Drs = roc_auc_score(label_ind, n_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# if os.path.isfile(res_pearson_nodes_file):\n",
    "#     print('Reading nodes...')\n",
    "#     nodes = pickle.load(open(res_pearson_nodes_file, 'rb'))\n",
    "#\n",
    "# else:\n",
    "#     print('PIPELINE: Pearson\\'s Nodes file not found, create a new one')\n",
    "#\n",
    "#     if not os.path.exists(res_nodes_folder):\n",
    "#         mkdir(res_nodes_folder)\n",
    "#\n",
    "#     nodes = []\n",
    "#     n_strength, pearson_connectome = nodes_strength(label_ts, 'pearson')\n",
    "#\n",
    "#     for i in range(len(n_strength)):\n",
    "#         nodes.append(Node(label_ts[i, :], n_strength[i], labels[i], 'Pearson', pearson_connectome[i, :]))\n",
    "#\n",
    "#     pickle.dump(nodes, open(res_pearson_nodes_file, 'wb'))\n",
    "#\n",
    "# coordinates = []\n",
    "# n_strength = []\n",
    "# for node in nodes:\n",
    "#     coordinates.append(node.nilearn_coordinates)\n",
    "#     n_strength.append(node.strength)\n",
    "#\n",
    "# nplt.plot_markers(n_strength, coordinates, node_cmap='black_red_r')\n",
    "# nplt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# if os.path.isfile(res_plv_nodes_file):\n",
    "#     print('Reading nodes...')\n",
    "#     nodes = pickle.load(open(res_plv_nodes_file, 'rb'))\n",
    "#\n",
    "# else:\n",
    "#     print('PIPELINE: PLV Nodes file not found, create a new one')\n",
    "#\n",
    "#     if not os.path.exists(res_nodes_folder):\n",
    "#         mkdir(res_nodes_folder)\n",
    "#\n",
    "#     nodes = []\n",
    "#     n_strength, plv_connectome = nodes_strength(label_ts, 'plv')\n",
    "#\n",
    "#     for i in range(len(n_strength)):\n",
    "#         nodes.append(Node(label_ts[i, :], n_strength[i], labels[i], 'PLV', plv_connectome[i, :, :]))\n",
    "#\n",
    "#     pickle.dump(nodes, open(res_plv_nodes_file, 'wb'))\n",
    "#\n",
    "# coordinates = []\n",
    "# n_strength = []\n",
    "# for node in nodes:\n",
    "#     coordinates.append(node.nilearn_coordinates)\n",
    "#     n_strength.append(node.strength)\n",
    "#\n",
    "# nplt.plot_markers(n_strength, coordinates, node_cmap='black_red_r')\n",
    "# nplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## example how to get freesurf_dict\n",
    "\n",
    "# vertexes = [mne.vertex_to_mni(\n",
    "#     label.vertices,\n",
    "#     hemis=0 if label.hemi == 'lh' else 1,\n",
    "#     subject=subject, subjects_dir=subjects_dir\n",
    "# )for label in labels]\n",
    "# freesurf_dict_sample = {l[0].name: np.mean(l[1], axis=0) for l in zip(labels, vertexes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # show one label\n",
    "# nplt.plot_markers(np.zeros(vertexes[0].shape[0]), vertexes[0])\n",
    "# nplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # show one node\n",
    "#\n",
    "# nplt.plot_markers(np.array([0, 0]), np.array([\n",
    "#     np.mean(vertexes[0], axis=0),\n",
    "#     np.array([1000, 1000, 1000]) ## plot markers does not work with one node\n",
    "# ]))\n",
    "# nplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "vertexes = [mne.vertex_to_mni(\n",
    "    label.vertices,\n",
    "    hemis=0 if label.hemi == 'lh' else 1,\n",
    "    subject=subject, subjects_dir=subjects_dir\n",
    ")for label in labels]\n",
    "\n",
    "freesurf_dict_sample = {l[0].name: np.mean(l[1], axis=0) for l in zip(labels, vertexes)}\n",
    "node_coordinates = np.array(list(freesurf_dict_sample.values()))\n",
    "\n",
    "# print(node_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(res_resec_file):\n",
    "    print('Reading resection coordinates...')\n",
    "    resec_coordinates = pickle.load(open(res_resec_file, 'rb'))\n",
    "    print('Resection coordinates has been read')\n",
    "else:\n",
    "    print('PIPELINE: Resection file not found, create a new one')\n",
    "    if not os.path.exists(res_resec_folder):\n",
    "        mkdir(res_resec_folder)\n",
    "\n",
    "    img = nib.load('Source/Subjects/B1C2/resection/resection.nii')\n",
    "    res = np.array(img.get_data().tolist())\n",
    "    img_coordinates = list()\n",
    "    for i in range(res.shape[0]):\n",
    "        for j in range(res.shape[1]):\n",
    "            for k in range(res.shape[2]):\n",
    "                if res[i,j,k] != 0:\n",
    "                    img_coordinates.append(np.array([i, j, k]))\n",
    "    img_coordinates = np.array(img_coordinates)\n",
    "    mni_coordinates = []\n",
    "    for coordinate in img_coordinates:\n",
    "        mni_coordinates.append(\n",
    "            np.array(\n",
    "                image.coord_transform(\n",
    "                    coordinate[0],\n",
    "                    coordinate[1],\n",
    "                    coordinate[2],\n",
    "                    img.affine\n",
    "                    )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    resec_coordinates = np.array(mni_coordinates)\n",
    "    pickle.dump(resec_coordinates, open(res_resec_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "display = nplt.plot_glass_brain(None, display_mode='lyrz', figure=fig, axes=ax)\n",
    "\n",
    "display.add_markers(resec_coordinates, marker_color=\"violet\", marker_size=1)\n",
    "\n",
    "display.add_markers(node_coordinates, marker_color=\"yellow\", marker_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "spared = list()\n",
    "resected = list()\n",
    "\n",
    "for node_coordinate in node_coordinates:\n",
    "    for resec_coordinate in resec_coordinates:\n",
    "        diff = node_coordinate - resec_coordinate\n",
    "        dist = np.sqrt(diff[0]**2 + diff[1]**2 + diff[2]**2)\n",
    "        if dist <= 1 and not node_coordinate in np.array(resected):\n",
    "            resected.append(node_coordinate)\n",
    "        else:\n",
    "            spared.append(node_coordinate)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "\n",
    "display = nplt.plot_glass_brain(\n",
    "    None, display_mode='lyrz', figure=fig, axes=ax)\n",
    "display.add_markers(resec_coordinates, marker_color=\"violet\", marker_size=1)\n",
    "display.add_markers(np.array(spared), marker_color=\"yellow\", marker_size=100)\n",
    "display.add_markers(np.array(resected), marker_color=\"red\", marker_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "del stc, src, raw, fwd,\\\n",
    "    bem, labels, label_ts, inv, noise_cov\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}