{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "from abc import *\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import mne\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors._dist_metrics import DistanceMetric\n",
    "from sklearn.utils import shuffle\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nodestimation.learning.estimation import collect_statistic, \\\n",
    "    compute_importance, collect_cross_statistic, make_selection_map, \\\n",
    "    select, separate_datasets, selected_statistic, choose_best, selected_data, make_feature_selection\n",
    "from nodestimation.processing.features import prepare_features\n",
    "from nodestimation.project import find_subject_dir, conditions_unique_code\n",
    "from nodestimation.pipeline import pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nilearn.plotting as nplt\n",
    "from nodestimation.project.actions import read\n",
    "import nodestimation as nd\n",
    "from nodestimation.learning.modification import append_series, promote\n",
    "import nodestimation.learning.modification as lmd\n",
    "from nodestimation.project.subject import Subject\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from nodestimation.learning.selection import SubjectsStatistic\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "import numpy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All computation has been already done, loading of the existing file with the solution...\n"
     ]
    }
   ],
   "source": [
    "subjects = pipeline(\n",
    "    methods=['wpli', 'envelope'],\n",
    "    freq_bands=(7.5, 12),\n",
    "    centrality_metrics=['eigen', 'close', 'between', 'degree', ],# 'katz', 'info', 'harmonic']\n",
    "    subjects_specificity={\n",
    "        'M2S2': {\n",
    "            'freq_bands': (7.5, 12.5)\n",
    "        },\n",
    "        'R1D2': {\n",
    "            'freq_bands': (7.5, 11)\n",
    "        },\n",
    "        'S1A2': {\n",
    "            'freq_bands': (5, 10)\n",
    "        },\n",
    "        'S1H1': {\n",
    "            'freq_bands': (8, 13)\n",
    "        },\n",
    "        'K1V1': {\n",
    "            'freq_bands': (7.5, 11)\n",
    "        },\n",
    "        'L1P1': {\n",
    "            'freq_bands': (5, 10)\n",
    "        },\n",
    "        'M1G2': {\n",
    "            'freq_bands': (7, 11)\n",
    "        },\n",
    "        'G1V2': {\n",
    "            'freq_bands': (7, 11)\n",
    "        },\n",
    "        'G1R1': {\n",
    "            'freq_bands': (12.5, 16.5)\n",
    "        },\n",
    "        'M1N2': {\n",
    "            'freq_bands': (10, 15)\n",
    "        },\n",
    "        'B1R1': {\n",
    "            'freq_bands': (6, 11)\n",
    "        },\n",
    "        'B1C2': {\n",
    "            'freq_bands': (7.5, 12.5)\n",
    "        },\n",
    "        'J1T2': {\n",
    "            'freq_bands': (11, 15)\n",
    "        },\n",
    "        'O1O2': {\n",
    "            'freq_bands': (5.5, 9.5)\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "for subject in subjects:\n",
    "    for dataset in subject.dataset:\n",
    "        columns = subject.dataset[dataset].columns.to_list()\n",
    "        rule = dict()\n",
    "        for column in columns:\n",
    "            if 'wpli' in column:\n",
    "                rule.update({column: 'wpli'})\n",
    "            if 'envelope' in column:\n",
    "                rule.update({column: 'envelope'})\n",
    "        subject.dataset[dataset] = subject.dataset[dataset].rename(columns=rule, copy=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(list(subjects[0].graph.values())[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stat1 = SubjectsStatistic(subjects, 'resected', centrality_metric='eigen')\n",
    "stat2 = SubjectsStatistic(subjects, 'resected', centrality_metric='close')\n",
    "# stat3 = SubjectsStatistic(subjects, 'resected', centrality_metric='between')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subjects_brains = dict()\n",
    "c = 'eigen'\n",
    "for subject in subjects:\n",
    "    subjects_brains.update({subject: dict()})\n",
    "    lh, rh = pd.DataFrame(), pd.DataFrame()\n",
    "    resected = None\n",
    "    for i in range(len(subject.dataset[c].index)):\n",
    "        if 'lh' in subject.dataset[c].iloc[i].name:\n",
    "            if subject.dataset[c].iloc[i]['resected'] and resected is None:\n",
    "                resected = 'left'\n",
    "            lh = append_series(lh, subject.dataset[c].iloc[i][['4-7Hz_envelope', '4-7Hz_wpli']], index=subject.dataset[c].iloc[i].name)\n",
    "        else:\n",
    "            rh = append_series(rh, subject.dataset[c].iloc[i][['4-7Hz_envelope', '4-7Hz_wpli']], index=subject.dataset[c].iloc[i].name)\n",
    "            if subject.dataset[c].iloc[i]['resected'] and resected is None:\n",
    "                resected = 'right'\n",
    "    subjects_brains[subject].update({'lh': lh, 'rh': rh, 'resected': resected})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = list()\n",
    "for brain in subjects_brains:\n",
    "    if subjects_brains[brain]['resected'] == 'left':\n",
    "        y.append(True)\n",
    "        y.append(False)\n",
    "    else:\n",
    "        y.append(False)\n",
    "        y.append(True)\n",
    "y = np.array(y)\n",
    "x = list()\n",
    "for brain in subjects_brains:\n",
    "    x.append(subjects_brains[brain]['lh'].to_numpy().T)\n",
    "    x.append(subjects_brains[brain]['rh'].to_numpy().T)\n",
    "\n",
    "x = np.array(x)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    x[i] = scaler.fit_transform(x[i].T).T\n",
    "nsamples, nx, ny = x.shape\n",
    "x = x.reshape((nsamples, nx*ny))\n",
    "print(x[0, :].shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "# clf = AdaBoostClassifier(n_estimators=10)\n",
    "# clf = svm.SVC(kernel='linear')\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "# clf = svm.SVC(class_weight={True: 1, False: .8}, probability=True)\n",
    "# clf = SGDClassifier()\n",
    "# clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# clf = LogisticRegression(class_weight={True: 1, False: .8})\n",
    "# clf = RandomForestClassifier(max_depth=20)\n",
    "# clf = GaussianNB()\n",
    "# clf = LinearDiscriminantAnalysis()\n",
    "# clf = KMeans(n_clusters=2, algorithm='full')\n",
    "# clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#     s2 = subject.dataset['4-7Hz_imcoh']\n",
    "#     print(s1.corr(s2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(stat1.datasets['true'].shape)\n",
    "print(stat1.datasets['false'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          resampled, eigen  reflected, eigen  resampled, close  \\\n",
      "wpli              0.065466          0.069655          0.078691   \n",
      "envelope          0.769480          0.099622          0.567217   \n",
      "\n",
      "          reflected, close  \n",
      "wpli              0.834195  \n",
      "envelope          0.124772  \n"
     ]
    }
   ],
   "source": [
    "test11 = stat1.test(state='resampled')\n",
    "test12 = stat1.test(state='reflected')\n",
    "test21 = stat2.test(state='resampled')\n",
    "test22 = stat2.test(state='reflected')\n",
    "test11_samples, test12_samples, test21_samples, test22_samples = list(), list(), list(), list()\n",
    "for feature in test11.result:\n",
    "    test11_samples.append(test11.result[feature][1])\n",
    "    test12_samples.append(test12.result[feature][1])\n",
    "    test21_samples.append(test21.result[feature][1])\n",
    "    test22_samples.append(test22.result[feature][1])\n",
    "\n",
    "test_samples = np.array([\n",
    "    np.array(test11_samples),\n",
    "    np.array(test12_samples),\n",
    "    np.array(test21_samples),\n",
    "    np.array(test22_samples)\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(test_samples, columns=list(test11.result.keys()), index=[\n",
    "    'resampled, eigen', 'reflected, eigen', 'resampled, close', 'reflected, close'\n",
    "]).T\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          resampled, eigen  reflected, eigen  resampled, close  \\\n",
      "wpli              0.053815          0.068242          0.151665   \n",
      "envelope          0.452273          0.117178          0.271065   \n",
      "\n",
      "          reflected, close  \n",
      "wpli              0.367013  \n",
      "envelope          0.223778  \n"
     ]
    }
   ],
   "source": [
    "test11 = stat1.test(state='resampled', test='mannwhitneyu')\n",
    "test12 = stat1.test(state='reflected', test='mannwhitneyu')\n",
    "test21 = stat2.test(state='resampled', test='mannwhitneyu')\n",
    "test22 = stat2.test(state='reflected', test='mannwhitneyu')\n",
    "test11_samples, test12_samples, test21_samples, test22_samples = list(), list(), list(), list()\n",
    "for feature in test11.result:\n",
    "    test11_samples.append(test11.result[feature][1])\n",
    "    test12_samples.append(test12.result[feature][1])\n",
    "    test21_samples.append(test21.result[feature][1])\n",
    "    test22_samples.append(test22.result[feature][1])\n",
    "\n",
    "test_samples = np.array([\n",
    "    np.array(test11_samples),\n",
    "    np.array(test12_samples),\n",
    "    np.array(test21_samples),\n",
    "    np.array(test22_samples)\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(test_samples, columns=list(test11.result.keys()), index=[\n",
    "    'resampled, eigen', 'reflected, eigen', 'resampled, close', 'reflected, close'\n",
    "]).T\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# features = ['4-7Hz_wpli', '7-14Hz_wpli', '14-30Hz_wpli', '30-70Hz_wpli']\n",
    "features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "# features = ['4-7Hz_wpli']\n",
    "# features = ['envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_psd']\n",
    "true_data = stat1.datasets['true'][features]\n",
    "false_data = stat1.datasets['false_res'][features]\n",
    "true_data = true_data.assign(resected=True)\n",
    "false_data = false_data.assign(resected=False)\n",
    "dataset = pd.concat([true_data, false_data], axis=0)\n",
    "dataset = dataset.sample(frac = 1)\n",
    "print(dataset)\n",
    "\n",
    "# 61"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "true_data = stat1.datasets['true'][features]\n",
    "true_data_lead = lmd.lead_std(stat1.datasets['true'][features], take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "# true_data_lead = lmd.lead_mean(true_data_lead, take_mean_from=stat1.datasets['false_res'][features], axis=1)\n",
    "false_data = stat1.datasets['false'][features]\n",
    "false_res_data = stat1.datasets['false_res'][features]\n",
    "false_rand_data = stat1.random_samples()[features]\n",
    "means = pd.concat([false_data.mean(), false_res_data.mean(), false_rand_data.mean(), true_data.mean(), true_data_lead.mean()], axis=1)\n",
    "stds = pd.concat([false_data.std(), false_res_data.std(), false_rand_data.std(), true_data.std(), true_data_lead.std()], axis=1)\n",
    "\n",
    "means = pd.DataFrame(means.to_numpy(), index=features, columns=['false', 'false_res', 'false_rand', 'true', 'true_lead'])\n",
    "stds = pd.DataFrame(stds.to_numpy(), index=features, columns=['false', 'false_res', 'false_rand', 'true', 'true_lead'])\n",
    "\n",
    "print(means)\n",
    "print(stds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-129-bb4501231546>:72: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if np.isnan(tp/(tp + fp)):\n",
      "<ipython-input-129-bb4501231546>:72: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if np.isnan(tp/(tp + fp)):\n",
      "<ipython-input-129-bb4501231546>:72: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if np.isnan(tp/(tp + fp)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6264000000000011 0.25 0.9 [0.6] [233]\n",
      "Specificity 0.8956440712065717 0.125 1.0 [1.] [340]\n",
      "Sensitivity:  0.3644910270285273 0.0 1.0 [0.33333333] [91]\n",
      "Positive Predictive Value:  0.7819563767931403 0.0 1.0 [1.] [337]\n",
      "Negative Predictive Value:  0.5850666613829929 0.23076923076923078 1.0 [0.5] [83]\n"
     ]
    }
   ],
   "source": [
    "# features = ['0.5-4Hz_wpli', '4-7Hz_wpli', '7-14Hz_wpli', '14-30Hz_wpli', '30-70Hz_wpli']\n",
    "# features = ['14-30Hz_wpli', '4-7Hz_wpli']\n",
    "# features = ['4-7Hz_wpli', '0.5-4Hz_envelope', '4-7Hz_envelope', '7-14Hz_envelope', '14-30Hz_envelope', '30-70Hz_envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "features = ['wpli', 'envelope']\n",
    "# features = ['4-7Hz_envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_psd']\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "stat = stat1\n",
    "for i in range(1000):\n",
    "    # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "    # clf = AdaBoostClassifier(n_estimators=10)\n",
    "    clf = svm.SVC(class_weight={True: .9, False: 1})\n",
    "    # clf = svm.SVC(class_weight={True: 1, False: .8}, probability=True)\n",
    "    # clf = SGDClassifier()\n",
    "    # clf = KNeighborsClassifier(n_neighbors=7, metric='chebyshev')\n",
    "    # clf = LogisticRegression(class_weight={True: 1, False: .8})\n",
    "    # clf = RandomForestClassifier(max_depth=20)\n",
    "    # clf = GaussianNB()\n",
    "    # clf = LinearDiscriminantAnalysis()\n",
    "    # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "    # clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "    true_data = stat.datasets['true'][features]\n",
    "    # true_data = lmd.lead_std(stat.datasets['true'][features], take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    # false_data = stat.random_samples()[features]\n",
    "    # false_data = lmd.lead_std(stat.datasets['false_res'][features], take_std_from=stat1.datasets['true'][features], axis=1)\n",
    "    # false_data = stat1.datasets['false_res'][features]\n",
    "    # false_data = stat1.datasets['false'][features]\n",
    "    # true_data = stat1.random_samples()[features]\n",
    "    # false_data = stat.random_samples()[features]\n",
    "    false_data = stat.datasets['false_mirror'][features]\n",
    "    true_data = true_data.assign(resected=True)\n",
    "    false_data = false_data.assign(resected=False)\n",
    "    dataset = pd.concat([true_data, false_data], axis=0)\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaler = MaxAbsScaler()\n",
    "    # scaler = RobustScaler()\n",
    "\n",
    "\n",
    "\n",
    "    y = dataset['resected'].to_numpy()\n",
    "    dataset = dataset.drop(['resected'], axis=1)\n",
    "\n",
    "\n",
    "    # dataset = lmd.lead_std(dataset, take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    dataset = lmd.suppress(dataset, axis=1, optimal='max')\n",
    "    # dataset = lmd.promote(dataset, axis=1, optimal='mean')\n",
    "    # dataset = lmd.clusterize(dataset, axis=1, n_clusters=3, optimal='symclose')\n",
    "    # dataset = lmd.binarize(dataset, axis=1)\n",
    "    x = scaler.fit_transform(dataset)\n",
    "    # x = dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    # prob = clf.predict_proba(x_test).tolist()\n",
    "    # for p, x, y in zip(prob, pred, y_test):\n",
    "    #     print(y, x, p)\n",
    "\n",
    "    # df = pd.DataFrame(np.array([np.array(y_test), pred]).T, columns=['actually', 'prediction'])\n",
    "    # print(df)\n",
    "\n",
    "    acc.append(accuracy_score(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    spec.append(tn / (tn + fp))\n",
    "    sens.append(tp / (tp + fn))\n",
    "\n",
    "    if np.isnan(tp/(tp + fp)):\n",
    "        pospred.append(0)\n",
    "    else:\n",
    "        pospred.append(tp/(tp + fp))\n",
    "\n",
    "    if np.isnan((tn/(tn + fn))):\n",
    "        negpred.append(0)\n",
    "    else:\n",
    "        negpred.append(tn/(tn + fn))\n",
    "\n",
    "max_acc = np.max(np.array(acc))\n",
    "min_acc = np.min(np.array(acc))\n",
    "moda_acc, cacc = sp.stats.mode(np.array(acc))\n",
    "acc = sum(acc)/len(acc)\n",
    "max_spec = np.max(np.array(spec))\n",
    "min_spec = np.min(np.array(spec))\n",
    "moda_spec, cspec = sp.stats.mode(np.array(spec))\n",
    "spec = sum(spec)/len(spec)\n",
    "max_sens = np.max(np.array(sens))\n",
    "min_sens = np.min(np.array(sens))\n",
    "moda_sens, csens = sp.stats.mode(np.array(sens))\n",
    "sens = sum(sens)/len(sens)\n",
    "max_pospred = np.max(np.array(pospred))\n",
    "min_pospred = np.min(np.array(pospred))\n",
    "moda_pospred, cpospred = sp.stats.mode(np.array(pospred))\n",
    "pospred = sum(pospred)/len(pospred)\n",
    "max_negpred = np.max(np.array(negpred))\n",
    "min_negpred = np.min(np.array(negpred))\n",
    "moda_negpred, cnegspred = sp.stats.mode(np.array(negpred))\n",
    "negpred = sum(negpred)/len(negpred)\n",
    "print('Accuracy: ', acc, min_acc, max_acc, moda_acc, cacc)\n",
    "print('Specificity', spec, min_spec, max_spec, moda_spec, cspec)\n",
    "print('Sensitivity: ', sens, min_sens, max_sens, moda_sens, csens)\n",
    "print('Positive Predictive Value: ', pospred, min_pospred, max_pospred, moda_pospred, cpospred)\n",
    "print('Negative Predictive Value: ', negpred, min_negpred, max_negpred, moda_negpred, cnegspred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False [0.5607220940473112, 0.43927790595268884]\n",
      "False False [0.4407745752873499, 0.5592254247126499]\n",
      "False True [0.2196200078325757, 0.7803799921674244]\n",
      "True False [0.40373810243809294, 0.596261897561907]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "False False [0.44203751137848574, 0.5579624886215142]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "True False [0.5535351222273772, 0.44646487777262295]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "True False [0.47928226616888486, 0.5207177338311152]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "True True [0.27711460311389474, 0.7228853968861053]\n",
      "False True [0.2583733107196455, 0.7416266892803546]\n",
      "False True [0.36486861568763956, 0.6351313843123605]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "True False [0.4710348003184959, 0.5289651996815041]\n",
      "False True [0.2417079657337907, 0.7582920342662094]\n",
      "True True [0.24049264690145836, 0.7595073530985416]\n",
      "True False [0.5667423569451508, 0.4332576430548493]\n",
      "False True [0.3922861217527679, 0.6077138782472322]\n",
      "Accuracy:  0.45 0.45 0.45 [0.45] [1]\n",
      "Specifity 0.5833333333333334 0.5833333333333334 0.5833333333333334 [0.58333333] [1]\n",
      "Sensitivity:  0.25 0.25 0.25 [0.25] [1]\n",
      "Positive Predictive Value:  0.2857142857142857 0.2857142857142857 0.2857142857142857 [0.28571429] [1]\n",
      "Negative Predictive Value:  0.5384615384615384 0.5384615384615384 0.5384615384615384 [0.53846154] [1]\n"
     ]
    }
   ],
   "source": [
    "# features = ['0.5-4Hz_wpli', '4-7Hz_wpli', '7-14Hz_wpli', '14-30Hz_wpli', '30-70Hz_wpli']\n",
    "# features = ['14-30Hz_wpli', '4-7Hz_wpli']\n",
    "# features = ['4-7Hz_wpli', '0.5-4Hz_envelope']\n",
    "# features = ['4-7Hz_wpli']\n",
    "# features = ['envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_psd']\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "stat = stat1\n",
    "for i in range(1):\n",
    "    # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "    # clf = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "    # clf = svm.SVC(kernel='linear')\n",
    "    clf = svm.SVC(class_weight={True: .9, False: 1}, probability=True)\n",
    "    # clf = SGDClassifier()\n",
    "    # clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    # clf = LogisticRegression()\n",
    "    # clf = RandomForestClassifier(max_depth=20)\n",
    "    # clf = GaussianNB()\n",
    "    # clf = LinearDiscriminantAnalysis()\n",
    "    # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "    # clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "    true_data = stat.datasets['true'][features]\n",
    "    # true_data = lmd.lead_std(stat.datasets['true'][features], take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    false_data = stat1.random_samples()[features]\n",
    "    # false_data = lmd.lead_std(stat.datasets['false_res'][features], take_std_from=stat1.datasets['true'][features], axis=1)\n",
    "    # false_data = stat1.datasets['false_res'][features]\n",
    "    # false_data = stat1.datasets['false'][features]\n",
    "    # true_data = stat1.random_samples()[features]\n",
    "    # false_data = stat.random_samples()[features]\n",
    "    # true_data = stat1.datasets['false_mirror'][features]\n",
    "    true_data = true_data.assign(resected=True)\n",
    "    false_data = false_data.assign(resected=False)\n",
    "    dataset = pd.concat([true_data, false_data], axis=0)\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaler = MaxAbsScaler()\n",
    "    # scaler = RobustScaler()\n",
    "\n",
    "\n",
    "\n",
    "    y = dataset['resected'].to_numpy()\n",
    "    dataset = dataset.drop(['resected'], axis=1)\n",
    "\n",
    "\n",
    "    # dataset = lmd.lead_std(dataset, take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    dataset = lmd.suppress(dataset, axis=1, optimal='max')\n",
    "    # dataset = lmd.promote(dataset, axis=1, optimal='min')\n",
    "    # dataset = lmd.clusterize(dataset, axis=1, n_clusters=3, optimal='max')\n",
    "    # dataset = lmd.binarize(dataset, axis=1)\n",
    "\n",
    "    x = scaler.fit_transform(dataset)\n",
    "    # x = dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    prob = clf.predict_proba(x_test).tolist()\n",
    "    for p, x, y in zip(prob, pred, y_test):\n",
    "        print(y, x, p)\n",
    "\n",
    "    # df = pd.DataFrame(np.array([np.array(y_test), pred]).T, columns=['actually', 'prediction'])\n",
    "    # print(df)\n",
    "\n",
    "    acc.append(accuracy_score(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    spec.append(tn / (tn + fp))\n",
    "    sens.append(tp / (tp + fn))\n",
    "\n",
    "    if np.isnan(tp/(tp + fp)):\n",
    "        pospred.append(0)\n",
    "    else:\n",
    "        pospred.append(tp/(tp + fp))\n",
    "\n",
    "    if np.isnan((tn/(tn + fn))):\n",
    "        negpred.append(0)\n",
    "    else:\n",
    "        negpred.append(tn/(tn + fn))\n",
    "\n",
    "max_acc = np.max(np.array(acc))\n",
    "min_acc = np.min(np.array(acc))\n",
    "moda_acc, cacc = sp.stats.mode(np.array(acc))\n",
    "acc = sum(acc)/len(acc)\n",
    "max_spec = np.max(np.array(spec))\n",
    "min_spec = np.min(np.array(spec))\n",
    "moda_spec, cspec = sp.stats.mode(np.array(spec))\n",
    "spec = sum(spec)/len(spec)\n",
    "max_sens = np.max(np.array(sens))\n",
    "min_sens = np.min(np.array(sens))\n",
    "moda_sens, csens = sp.stats.mode(np.array(sens))\n",
    "sens = sum(sens)/len(sens)\n",
    "max_pospred = np.max(np.array(pospred))\n",
    "min_pospred = np.min(np.array(pospred))\n",
    "moda_pospred, cpospred = sp.stats.mode(np.array(pospred))\n",
    "pospred = sum(pospred)/len(pospred)\n",
    "max_negpred = np.max(np.array(negpred))\n",
    "min_negpred = np.min(np.array(negpred))\n",
    "moda_negpred, cnegspred = sp.stats.mode(np.array(negpred))\n",
    "negpred = sum(negpred)/len(negpred)\n",
    "print('Accuracy: ', acc, min_acc, max_acc, moda_acc, cacc)\n",
    "print('Specificity', spec, min_spec, max_spec, moda_spec, cspec)\n",
    "print('Sensitivity: ', sens, min_sens, max_sens, moda_sens, csens)\n",
    "print('Positive Predictive Value: ', pospred, min_pospred, max_pospred, moda_pospred, cpospred)\n",
    "print('Negative Predictive Value: ', negpred, min_negpred, max_negpred, moda_negpred, cnegspred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6406214285714303 0.5982142857142858 0.6642857142857144\n"
     ]
    }
   ],
   "source": [
    "# features = ['0.5-4Hz_wpli', '4-7Hz_wpli', '7-14Hz_wpli', '14-30Hz_wpli', '30-70Hz_wpli']\n",
    "# features = ['14-30Hz_wpli', '4-7Hz_wpli']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "features = ['wpli', 'envelope']\n",
    "# features = ['4-7Hz_wpli']\n",
    "# features = ['envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_psd']\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "stat = stat1\n",
    "for i in range(1000):\n",
    "    # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "    # clf = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "    # clf = svm.SVC(kernel='linear')\n",
    "    clf = svm.SVC(class_weight={True: .9, False: 1}, probability=True)\n",
    "    # clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    # clf = LogisticRegression()\n",
    "    # clf = RandomForestClassifier(max_depth=20)\n",
    "    # clf = GaussianNB()\n",
    "    # clf = LinearDiscriminantAnalysis()\n",
    "    # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "    # clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "\n",
    "    true_data = stat.datasets['true'][features]\n",
    "    # false_data = stat1.random_samples()[features]\n",
    "    # false_data = stat1.datasets['false_res'][features]\n",
    "    # true_data = stat1.random_samples()[features]\n",
    "    # false_data = stat.random_samples()[features]\n",
    "    # false_data = lmd.lead_std(stat.datasets['false_res'][features], take_std_from=stat.datasets['true'][features], axis=1)\n",
    "    false_data = stat.datasets['false_mirror'][features]\n",
    "    true_data = true_data.assign(resected=True)\n",
    "    false_data = false_data.assign(resected=False)\n",
    "    dataset = pd.concat([true_data, false_data], axis=0)\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaler = MaxAbsScaler()\n",
    "    # scaler = RobustScaler()\n",
    "\n",
    "\n",
    "\n",
    "    y = dataset['resected'].to_numpy()\n",
    "    dataset = dataset.drop(['resected'], axis=1)\n",
    "\n",
    "\n",
    "    # dataset = lmd.lead_std(dataset, take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    dataset = lmd.suppress(dataset, axis=1, optimal='max')\n",
    "    # dataset = lmd.promote(dataset, axis=1, optimal='min')\n",
    "    # dataset = lmd.clusterize(dataset, axis=1, n_clusters=3, optimal='max')\n",
    "    # dataset = lmd.binarize(dataset, axis=1)\n",
    "\n",
    "\n",
    "    x = scaler.fit_transform(dataset)\n",
    "    # x = dataset\n",
    "    scores = cross_val_score(clf, x, y, cv=10)\n",
    "    acc.append(scores.mean())\n",
    "\n",
    "print('Accuracy: ', sum(acc)/len(acc), min(acc), max(acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from nodestimation.mlearning.features import prepare_connectivity, prepare_data\n",
    "# con = pkl.load(open(subjects[0].data['con'], 'rb'))\n",
    "\n",
    "subjects_dir, subjects_ = find_subject_dir()\n",
    "labels = mne.read_labels_from_annot('B1C2', parc='aparc', subjects_dir=subjects_dir)\n",
    "label_names = [label.name for label in labels]\n",
    "lh_labels = [name for name in label_names if name.endswith('lh')]\n",
    "rh_labels = [name for name in label_names if name.endswith('rh')]\n",
    "\n",
    "label_ypos_lh = list()\n",
    "\n",
    "for name in lh_labels:\n",
    "    idx = label_names.index(name)\n",
    "    ypos = np.mean(labels[idx].pos[:, 1])\n",
    "    label_ypos_lh.append(ypos)\n",
    "\n",
    "try:\n",
    "    idx = label_names.index('Brain-Stem')\n",
    "\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    ypos = np.mean(labels[idx].pos[:, 1])\n",
    "    lh_labels.append('Brain-Stem')\n",
    "    label_ypos_lh.append(ypos)\n",
    "\n",
    "\n",
    "lh_labels = [label for (yp, label) in sorted(zip(label_ypos_lh, lh_labels))]\n",
    "\n",
    "rh_labels = [label[:-2] + 'rh' for label in lh_labels\n",
    "             if label != 'Brain-Stem' and label[:-2] + 'rh' in rh_labels]\n",
    "\n",
    "\n",
    "node_colors = [label.color for label in labels]\n",
    "\n",
    "node_order = lh_labels[::-1] + rh_labels\n",
    "\n",
    "node_angles = mne.viz.circular_layout(label_names, node_order, start_pos=90,\n",
    "                              group_boundaries=[0, len(label_names) // 2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# methods = [\n",
    "#     'coh',\n",
    "#     'imcoh',\n",
    "#     'plv',\n",
    "#     'ciplv',\n",
    "#     'ppc',\n",
    "#     'pli'\n",
    "# ]\n",
    "#\n",
    "# freq_bands = [\n",
    "#     '0.5-4Hz',\n",
    "#     '4-7Hz',\n",
    "#     '7-14Hz',\n",
    "#     '14-30Hz'\n",
    "# ]\n",
    "#\n",
    "# for method in methods:\n",
    "#     for freq_band in freq_bands:\n",
    "#         fig = plt.figure(num=None, figsize=(25, 25), facecolor='black')\n",
    "#         mne.viz.plot_connectivity_circle(con[freq_band][method]['con'][:, :, 0], label_names, n_lines=300,\n",
    "#                                          node_angles=node_angles, node_colors=node_colors,\n",
    "#                                          title='All-to-All Connectivity Epilepsy Condition ({} for {})'\n",
    "#                                          .format(method, freq_band), padding=8, fontsize_title=35, fontsize_colorbar=25,\n",
    "#                                          fontsize_names=20, fig=fig\n",
    "#                                          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    display = nplt.plot_glass_brain(None, display_mode='lyrz', figure=fig, axes=ax)\n",
    "    spared = [node.nilearn_coordinates for node in subject.nodes if node.type == 'spared']\n",
    "    resected = [node.nilearn_coordinates for node in subject.nodes if node.type == 'resected']\n",
    "    resection = read['resec-mni'](subject.data['resec-mni'])\n",
    "    display.add_markers(resection, marker_color=\"violet\", marker_size=1)\n",
    "    display.add_markers(np.array(spared), marker_color=\"yellow\", marker_size=100)\n",
    "    display.add_markers(np.array(resected), marker_color=\"red\", marker_size=250)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}