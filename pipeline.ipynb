{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineBuffer\n",
      "\t_DefaultPipelineBuffer__keys:    ['crop_time', 'snr', 'epochs_tmin', 'epochs_tmax', 'conductivity', 'se_method', 'centrality_metrics', 'methods', 'rfreq', 'nfreq', 'lfreq', 'hfreq', 'freq_bands']\n",
      "\tcrop_time:                       120\n",
      "\tsnr:                             0.5\n",
      "\tepochs_tmin:                     -1\n",
      "\tepochs_tmax:                     1\n",
      "\tconductivity:                    (0.3,)\n",
      "\tse_method:                       sLORETA\n",
      "\tcentrality_metrics:              ['wpli', 'envelope']\n",
      "\tmethods:                         ['eigen', 'close', 'between', 'degree']\n",
      "\trfreq:                           200\n",
      "\tnfreq:                           50\n",
      "\tlfreq:                           1\n",
      "\thfreq:                           70\n",
      "\tfreq_bands:                      (7.5, 12)\n",
      "\n",
      "917d43eac4e83a16cdf6b04ef78e4bfb\n",
      "Building of the resources files tree...\n",
      "Analysing project structure...\n",
      "Preparing data...\n",
      "All the data has been prepared. Saving the result...\n",
      "Successfully saved\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import re\n",
    "from abc import *\n",
    "from operator import itemgetter\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import mne\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors._dist_metrics import DistanceMetric\n",
    "from sklearn.utils import shuffle\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nodestimation.learning.estimation import collect_statistic, \\\n",
    "    compute_importance, collect_cross_statistic, make_selection_map, \\\n",
    "    select, separate_datasets, selected_statistic, choose_best, selected_data, make_feature_selection\n",
    "from nodestimation.processing.features import prepare_features\n",
    "from nodestimation.project import find_subject_dir, conditions_unique_code\n",
    "from nodestimation.pipeline import pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nilearn.plotting as nplt\n",
    "from nodestimation.project.actions import read\n",
    "import nodestimation as nd\n",
    "from nodestimation.learning.modification import append_series, promote\n",
    "import nodestimation.learning.modification as lmd\n",
    "from nodestimation.project.subject import Subject\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from nodestimation.learning.selection import SubjectsStatistic\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "from scipy.fftpack import fftfreq, irfft, rfft\n",
    "\n",
    "\n",
    "# subjects = pipeline(\n",
    "#     methods=['wpli', 'envelope'],\n",
    "#     freq_bands=(7.5, 12),\n",
    "#     centrality_metrics=['eigen', 'close', 'between', 'degree', ],# 'katz', 'info', 'harmonic']\n",
    "#     subjects_specificity={\n",
    "#         'M2S2': {\n",
    "#             'freq_bands': (7.5, 12.5)\n",
    "#         },\n",
    "#         'R1D2': {\n",
    "#             'freq_bands': (7.5, 11)\n",
    "#         },\n",
    "#         'S1A2': {\n",
    "#             'freq_bands': (5, 10)\n",
    "#         },\n",
    "#         'S1H1': {\n",
    "#             'freq_bands': (8, 13)\n",
    "#         },\n",
    "#         'K1V1': {\n",
    "#             'freq_bands': (7.5, 11)\n",
    "#         },\n",
    "#         'L1P1': {\n",
    "#             'freq_bands': (5, 10)\n",
    "#         },\n",
    "#         'M1G2': {\n",
    "#             'freq_bands': (7, 11)\n",
    "#         },\n",
    "#         'G1V2': {\n",
    "#             'freq_bands': (7, 11)\n",
    "#         },\n",
    "#         'G1R1': {\n",
    "#             'freq_bands': (12.5, 16.5)\n",
    "#         },\n",
    "#         'M1N2': {\n",
    "#             'freq_bands': (10, 15)\n",
    "#         },\n",
    "#         'B1R1': {\n",
    "#             'freq_bands': (6, 11)\n",
    "#         },\n",
    "#         'B1C2': {\n",
    "#             'freq_bands': (7.5, 12.5)\n",
    "#         },\n",
    "#         'J1T2': {\n",
    "#             'freq_bands': (11, 15)\n",
    "#         },\n",
    "#         'O1O2': {\n",
    "#             'freq_bands': (5.5, 9.5)\n",
    "#         },\n",
    "#     }\n",
    "# )\n",
    "\n",
    "subjects = pipeline(\n",
    "    methods=['wpli', 'envelope'],\n",
    "    freq_bands=(7.5, 12),\n",
    "    centrality_metrics=['eigen', 'close', 'between', 'degree']\n",
    "    )\n",
    "\n",
    "for subject in subjects:\n",
    "    for dataset in subject.dataset:\n",
    "        print(subject.dataset[dataset].columns)\n",
    "        # columns = subject.dataset[dataset].columns.to_list()\n",
    "        # rule = dict()\n",
    "        # for column in columns:\n",
    "        #     if 'wpli' in column:\n",
    "        #         rule.update({column: 'wpli'})\n",
    "        #     if 'envelope' in column:\n",
    "        #         rule.update({column: 'envelope'})\n",
    "        # subject.dataset[dataset] = subject.dataset[dataset].rename(columns=rule, copy=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "def sparse_graph(g: nx.Graph) -> nx.Graph:\n",
    "    con = nx.to_numpy_matrix(g)\n",
    "    out = nx.from_numpy_matrix(\n",
    "        lmd.suppress(\n",
    "            pd.DataFrame(\n",
    "                con\n",
    "            ),\n",
    "            trigger=con.mean().mean(),\n",
    "            optimal=0\n",
    "        ).to_numpy()\n",
    "    )\n",
    "    mapping = {node: label_name for node, label_name in zip(out, g)}\n",
    "    out = nx.relabel_nodes(out, mapping)\n",
    "    return out\n",
    "\n",
    "def graph_to_connectome(g: nx.Graph) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        nx.to_numpy_matrix(g),\n",
    "        index= g.nodes,\n",
    "        columns = g.nodes\n",
    "    )\n",
    "\n",
    "def labels_for_hemispheres(g: nx.Graph) -> Tuple[List[str], List[str]]:\n",
    "    labels_rh, labels_lh = list(), list()\n",
    "    for node in g.nodes:\n",
    "        if 'lh' in node:\n",
    "            labels_lh.append(node)\n",
    "        elif 'rh' in node:\n",
    "            labels_rh.append(node)\n",
    "        else:\n",
    "            raise ValueError(f'Wrong node name: {node}')\n",
    "    return labels_lh, labels_rh\n",
    "\n",
    "def hemispheres_division_modularity(g: nx.Graph) -> float:\n",
    "    labels_lh, labels_rh = labels_for_hemispheres(g)\n",
    "    return nx.algorithms.community.quality.modularity(g, [labels_lh, labels_rh])\n",
    "\n",
    "def hemispheres_division_performance(g: nx.Graph) -> float:\n",
    "    labels_lh, labels_rh = labels_for_hemispheres(g)\n",
    "    return nx.algorithms.community.quality.performance(g, [labels_lh, labels_rh])\n",
    "\n",
    "def graph_to_hemispheres(g: nx.Graph) -> Tuple[nx.Graph, nx.Graph]:\n",
    "    labels_lh, labels_rh = labels_for_hemispheres(g)\n",
    "    return g.subgraph(labels_lh), g.subgraph(labels_rh)\n",
    "\n",
    "def smallworldness(g: nx.Graph) -> Tuple[float, float]:\n",
    "    return nx.algorithms.smallworld.sigma(g), nx.algorithms.smallworld.omega(g)\n",
    "\n",
    "def s_for_hemispheres(subjects: List[Subject]) -> pd.DataFrame:\n",
    "    dataset = pd.DataFrame()\n",
    "\n",
    "    for subject in subjects:\n",
    "        resected_hemisphere = None\n",
    "        lupd, rupd = dict(), dict()\n",
    "\n",
    "        for node in subject.nodes:\n",
    "            if node.type == 'resected' and 'rh' in node.label.name:\n",
    "                lupd.update({'resected': False})\n",
    "                rupd.update({'resected': True})\n",
    "                break\n",
    "\n",
    "            elif node.type == 'resected' and 'lh' in node.label.name:\n",
    "                lupd.update({'resected': True})\n",
    "                rupd.update({'resected': False})\n",
    "                break\n",
    "\n",
    "        for freq in subject.graph:\n",
    "            for method in subject.graph[freq]:\n",
    "                G = sparse_graph(subject.graph[freq][method])\n",
    "                lh, rh = graph_to_hemispheres(G)\n",
    "                lupd.update({f's_for_{method}': nx.algorithms.smetric.s_metric(lh, normalized=False)/100000})\n",
    "                rupd.update({f's_for_{method}': nx.algorithms.smetric.s_metric(rh, normalized=False)/100000})\n",
    "\n",
    "        dataset = append_series(dataset, pd.Series(lupd), index=f'{subject.name}_lh')\n",
    "        dataset = append_series(dataset, pd.Series(rupd), index=f'{subject.name}_rh')\n",
    "\n",
    "    return dataset\n",
    "\n",
    "import time\n",
    "\n",
    "def metric_for_hemispheres(subjects: List[Subject], metric: Callable, **kwargs) -> pd.DataFrame:\n",
    "    dataset = pd.DataFrame()\n",
    "\n",
    "    for subject in subjects:\n",
    "        start = time.time()\n",
    "        resected_hemisphere = None\n",
    "        lupd, rupd = dict(), dict()\n",
    "\n",
    "        for node in subject.nodes:\n",
    "            if node.type == 'resected' and 'rh' in node.label.name:\n",
    "                lupd.update({'resected': False})\n",
    "                rupd.update({'resected': True})\n",
    "                break\n",
    "\n",
    "            elif node.type == 'resected' and 'lh' in node.label.name:\n",
    "                lupd.update({'resected': True})\n",
    "                rupd.update({'resected': False})\n",
    "                break\n",
    "\n",
    "        for freq in subject.graph:\n",
    "            for method in subject.graph[freq]:\n",
    "                G = sparse_graph(subject.graph[freq][method])\n",
    "                lh, rh = graph_to_hemispheres(G)\n",
    "                lupd.update({f'{metric.__name__}_for_{method}': metric(lh, **kwargs)})\n",
    "                rupd.update({f'{metric.__name__}_for_{method}': metric(rh, **kwargs)})\n",
    "\n",
    "        dataset = append_series(dataset, pd.Series(lupd), index=f'{subject.name}_lh')\n",
    "        dataset = append_series(dataset, pd.Series(rupd), index=f'{subject.name}_rh')\n",
    "        print(f'{subject.name}: DONE, RUNTIME: {time.time() - start}')\n",
    "\n",
    "    return dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249 75\n"
     ]
    }
   ],
   "source": [
    "# plt.imshow(\n",
    "#     pd.DataFrame(\n",
    "#         nx.to_numpy_matrix(\n",
    "#             subjects[0].graph['7.5-12.5Hz']['wpli']\n",
    "#         )\n",
    "#     ).to_numpy())\n",
    "# plt.show()\n",
    "# plt.imshow(\n",
    "#     lmd.suppress(\n",
    "#         pd.DataFrame(\n",
    "#             nx.to_numpy_matrix(\n",
    "#                 subjects[0].graph['7.5-12.5Hz']['wpli']\n",
    "#             )\n",
    "#         ),\n",
    "#         optimal=0\n",
    "#     ).to_numpy())\n",
    "# plt.show()\n",
    "#\n",
    "G = sparse_graph(subjects[0].graph['7.5-12.5Hz']['wpli'])\n",
    "lh, rh = graph_to_hemispheres(G)\n",
    "print(lh.number_of_edges(), lh.number_of_nodes())\n",
    "# nx.draw(subjects[0].graph['7.5-12.5Hz']['wpli'])\n",
    "# plt.show()\n",
    "# nx.draw(G)\n",
    "# plt.show()\n",
    "# nx.draw(lh)\n",
    "# plt.show()\n",
    "# nx.draw(rh)\n",
    "# plt.show()\n",
    "# print('all: ', smallworldness(G))\n",
    "import time\n",
    "start = time.time()\n",
    "# print(smallworldness(nx.complete_graph(5)))\n",
    "# print(time.time() - start)\n",
    "# print(smallworldness(nx.complete_graph(10)))\n",
    "# print(time.time() - start)\n",
    "# print(smallworldness(nx.complete_graph(75)))\n",
    "# print(time.time() - start)\n",
    "# print('lh: ', smallworldness(lh))\n",
    "# print('rh: ', smallworldness(rh))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M2S2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_front_inf-Opercular-rh\n",
      "\n",
      "\t7.5-12.5Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.035408499433554785\n",
      "\n",
      "\n",
      "\t s for lh 16.54554\n",
      "\n",
      "\t s for rh 13.03479\n",
      "\n",
      "\t7.5-12.5Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.0366214401086174\n",
      "\n",
      "\n",
      "\t s for lh 21.9938\n",
      "\n",
      "\t s for rh 21.89547\n",
      "R1D2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_front_sup-rh\n",
      "\n",
      "\t7.5-11Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.014056770804252355\n",
      "\n",
      "\n",
      "\t s for lh 10.05777\n",
      "\n",
      "\t s for rh 28.40998\n",
      "\n",
      "\t7.5-11Hz: envelope\n",
      "\n",
      "\themispheres division modularity: 0.0022133081422265055\n",
      "\n",
      "\n",
      "\t s for lh 27.99864\n",
      "\n",
      "\t s for rh 19.24416\n",
      "S1A2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_front_middle-lh\n",
      "\n",
      "\t5-10Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.012967834351176072\n",
      "\n",
      "\n",
      "\t s for lh 13.5604\n",
      "\n",
      "\t s for rh 12.98965\n",
      "\n",
      "\t5-10Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.030443345276433248\n",
      "\n",
      "\n",
      "\t s for lh 19.02832\n",
      "\n",
      "\t s for rh 24.35694\n",
      "S1H1\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_orbital-rh\n",
      "\tS_circular_insula_ant-rh\n",
      "\n",
      "\t8-13Hz: wpli\n",
      "\n",
      "\themispheres division modularity: 0.004095594954389742\n",
      "\n",
      "\n",
      "\t s for lh 13.29154\n",
      "\n",
      "\t s for rh 17.03113\n",
      "\n",
      "\t8-13Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.01526383078715754\n",
      "\n",
      "\n",
      "\t s for lh 23.90205\n",
      "\n",
      "\t s for rh 25.28268\n",
      "K1V1\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_temp_sup-Lateral-rh\n",
      "\tG_temporal_inf-rh\n",
      "\tG_temporal_middle-rh\n",
      "\tPole_temporal-rh\n",
      "\tS_temporal_inf-rh\n",
      "\tS_temporal_sup-rh\n",
      "\n",
      "\t7.5-11Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.003999590952882132\n",
      "\n",
      "\n",
      "\t s for lh 18.22924\n",
      "\n",
      "\t s for rh 28.45215\n",
      "\n",
      "\t7.5-11Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.04300472819180742\n",
      "\n",
      "\n",
      "\t s for lh 22.10688\n",
      "\n",
      "\t s for rh 20.89652\n",
      "L1P1\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_temp_sup-G_T_transv-rh\n",
      "\tLat_Fis-post-rh\n",
      "\tS_circular_insula_inf-rh\n",
      "\tS_temporal_transverse-rh\n",
      "\n",
      "\t5-10Hz: wpli\n",
      "\n",
      "\themispheres division modularity: 0.006280073071196657\n",
      "\n",
      "\n",
      "\t s for lh 12.28985\n",
      "\n",
      "\t s for rh 17.13233\n",
      "\n",
      "\t5-10Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.04450139465019842\n",
      "\n",
      "\n",
      "\t s for lh 10.82875\n",
      "\n",
      "\t s for rh 35.92687\n",
      "M1G2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG&S_occipital_inf-rh\n",
      "\tG_oc-temp_lat-fusifor-rh\n",
      "\tG_occipital_middle-rh\n",
      "\tPole_occipital-rh\n",
      "\n",
      "\t7-11Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.003445025411754954\n",
      "\n",
      "\n",
      "\t s for lh 16.95895\n",
      "\n",
      "\t s for rh 30.67119\n",
      "\n",
      "\t7-11Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.08220028443734051\n",
      "\n",
      "\n",
      "\t s for lh 8.92262\n",
      "\n",
      "\t s for rh 28.9158\n",
      "G1V2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_front_inf-Opercular-rh\n",
      "\tG_front_middle-rh\n",
      "\n",
      "\t7-11Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.0106871933624329\n",
      "\n",
      "\n",
      "\t s for lh 13.62582\n",
      "\n",
      "\t s for rh 11.47298\n",
      "\n",
      "\t7-11Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.03640361572905798\n",
      "\n",
      "\n",
      "\t s for lh 20.46387\n",
      "\n",
      "\t s for rh 22.91015\n",
      "G1R1\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_temporal_middle-lh\n",
      "\tPole_temporal-lh\n",
      "\n",
      "\t12.5-16.5Hz: wpli\n",
      "\n",
      "\themispheres division modularity: 0.025217214199974386\n",
      "\n",
      "\n",
      "\t s for lh 14.23456\n",
      "\n",
      "\t s for rh 14.08462\n",
      "\n",
      "\t12.5-16.5Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.052037644065192235\n",
      "\n",
      "\n",
      "\t s for lh 29.30987\n",
      "\n",
      "\t s for rh 10.96564\n",
      "M1N2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_front_middle-rh\n",
      "\tS_front_sup-rh\n",
      "\n",
      "\t10-15Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.03941763727396924\n",
      "\n",
      "\n",
      "\t s for lh 12.52491\n",
      "\n",
      "\t s for rh 11.39043\n",
      "\n",
      "\t10-15Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.04377008377966099\n",
      "\n",
      "\n",
      "\t s for lh 18.06807\n",
      "\n",
      "\t s for rh 23.65787\n",
      "S1B1\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_temporal_inf-rh\n",
      "\tPole_temporal-rh\n",
      "\tS_temporal_inf-rh\n",
      "\tS_temporal_sup-rh\n",
      "\n",
      "\t7.5-12Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.041428484496578405\n",
      "\n",
      "\n",
      "\t s for lh 9.10253\n",
      "\n",
      "\t s for rh 18.80861\n",
      "\n",
      "\t7.5-12Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.029485011288137353\n",
      "\n",
      "\n",
      "\t s for lh 26.50927\n",
      "\n",
      "\t s for rh 24.20592\n",
      "B1R1\n",
      "\n",
      "\tresected nodes:\n",
      "\tS_temporal_sup-rh\n",
      "\tS_temporal_transverse-rh\n",
      "\n",
      "\t6-11Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.027035380420713573\n",
      "\n",
      "\n",
      "\t s for lh 10.57162\n",
      "\n",
      "\t s for rh 16.94446\n",
      "\n",
      "\t6-11Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.0453852311975996\n",
      "\n",
      "\n",
      "\t s for lh 17.40611\n",
      "\n",
      "\t s for rh 23.48128\n",
      "B1C2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG&S_occipital_inf-rh\n",
      "\tG_pariet_inf-Angular-rh\n",
      "\tS_interm_prim-Jensen-rh\n",
      "\tS_oc_sup&transversal-rh\n",
      "\tS_occipital_ant-rh\n",
      "\n",
      "\t7.5-12.5Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.010994348492309125\n",
      "\n",
      "\n",
      "\t s for lh 9.33269\n",
      "\n",
      "\t s for rh 20.37064\n",
      "\n",
      "\t7.5-12.5Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.039810973313159\n",
      "\n",
      "\n",
      "\t s for lh 23.02649\n",
      "\n",
      "\t s for rh 22.66546\n",
      "J1T2\n",
      "\n",
      "\tresected nodes:\n",
      "\tS_front_middle-lh\n",
      "\n",
      "\t11-15Hz: wpli\n",
      "\n",
      "\themispheres division modularity: 0.027019155447948306\n",
      "\n",
      "\n",
      "\t s for lh 18.44555\n",
      "\n",
      "\t s for rh 17.98197\n",
      "\n",
      "\t11-15Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.062018655194234995\n",
      "\n",
      "\n",
      "\t s for lh 21.40656\n",
      "\n",
      "\t s for rh 17.20009\n",
      "O1O2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_pariet_inf-Supramar-rh\n",
      "\n",
      "\t5.5-9.5Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.02922844385562995\n",
      "\n",
      "\n",
      "\t s for lh 12.74547\n",
      "\n",
      "\t s for rh 15.35314\n",
      "\n",
      "\t5.5-9.5Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.042283137426018885\n",
      "\n",
      "\n",
      "\t s for lh 20.90655\n",
      "\n",
      "\t s for rh 25.00644\n",
      "L2M1\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_temp_sup-Plan_polar-lh\n",
      "\n",
      "\t7.5-12Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.006856752592239002\n",
      "\n",
      "\n",
      "\t s for lh 21.91141\n",
      "\n",
      "\t s for rh 16.68819\n",
      "\n",
      "\t7.5-12Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.03801658599141422\n",
      "\n",
      "\n",
      "\t s for lh 34.93321\n",
      "\n",
      "\t s for rh 16.18196\n"
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    print(subject.name)\n",
    "    print('\\n\\tresected nodes:')\n",
    "    for node in subject.nodes:\n",
    "        if node.type == 'resected':\n",
    "            print(f'\\t{node.label.name}')\n",
    "    for freq in subject.graph:\n",
    "        for method in subject.graph[freq]:\n",
    "            print(f'\\n\\t{freq}: {method}')\n",
    "            G = sparse_graph(subject.graph[freq][method])\n",
    "            lh, rh = graph_to_hemispheres(G)\n",
    "            print(f'\\n\\themispheres division modularity: {hemispheres_division_modularity(G)}\\n')\n",
    "            print('\\n\\t s for lh', nx.algorithms.smetric.s_metric(lh, normalized=False)/100000)\n",
    "            print('\\n\\t s for rh', nx.algorithms.smetric.s_metric(rh, normalized=False)/100000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M2S2: DONE, RUNTIME: 2.461754560470581\n",
      "R1D2: DONE, RUNTIME: 1.7447841167449951\n",
      "S1A2: DONE, RUNTIME: 1.638746738433838\n",
      "S1H1: DONE, RUNTIME: 1.7346491813659668\n",
      "K1V1: DONE, RUNTIME: 2.5918946266174316\n",
      "L1P1: DONE, RUNTIME: 2.626293897628784\n",
      "M1G2: DONE, RUNTIME: 2.0958216190338135\n",
      "G1V2: DONE, RUNTIME: 1.8953375816345215\n",
      "G1R1: DONE, RUNTIME: 1.8817176818847656\n",
      "M1N2: DONE, RUNTIME: 1.8960962295532227\n",
      "S1B1: DONE, RUNTIME: 1.9826669692993164\n",
      "B1R1: DONE, RUNTIME: 1.9225101470947266\n",
      "B1C2: DONE, RUNTIME: 2.224745273590088\n",
      "J1T2: DONE, RUNTIME: 2.3231253623962402\n",
      "O1O2: DONE, RUNTIME: 2.333068370819092\n",
      "L2M1: DONE, RUNTIME: 2.6737186908721924\n",
      "         resected  transitivity_for_wpli  transitivity_for_envelope\n",
      "M2S2_lh     False               0.502919                   0.496882\n",
      "M2S2_rh      True               0.495370                   0.514362\n",
      "R1D2_lh     False               0.390802                   0.553436\n",
      "R1D2_rh      True               0.583788                   0.502018\n",
      "S1A2_lh      True               0.468642                   0.515520\n",
      "S1A2_rh     False               0.465723                   0.517179\n",
      "S1H1_lh     False               0.448939                   0.511008\n",
      "S1H1_rh      True               0.486028                   0.518393\n",
      "K1V1_lh     False               0.493925                   0.476190\n",
      "K1V1_rh      True               0.607856                   0.439483\n",
      "L1P1_lh     False               0.447840                   0.423321\n",
      "L1P1_rh      True               0.501666                   0.627988\n",
      "M1G2_lh     False               0.513119                   0.364480\n",
      "M1G2_rh      True               0.610709                   0.570833\n",
      "G1V2_lh     False               0.464296                   0.534241\n",
      "G1V2_rh      True               0.442101                   0.533711\n",
      "G1R1_lh      True               0.467750                   0.596839\n",
      "G1R1_rh     False               0.456961                   0.421495\n",
      "M1N2_lh     False               0.447126                   0.466599\n",
      "M1N2_rh      True               0.425454                   0.541885\n",
      "S1B1_lh     False               0.450097                   0.536721\n",
      "S1B1_rh      True               0.546497                   0.528663\n",
      "B1R1_lh     False               0.434968                   0.478369\n",
      "B1R1_rh      True               0.506153                   0.547731\n",
      "B1C2_lh     False               0.425042                   0.547602\n",
      "B1C2_rh      True               0.520002                   0.517673\n",
      "J1T2_lh      True               0.517493                   0.501241\n",
      "J1T2_rh     False               0.547438                   0.459875\n",
      "O1O2_lh     False               0.454745                   0.506993\n",
      "O1O2_rh      True               0.496346                   0.531471\n",
      "L2M1_lh      True               0.528586                   0.597664\n",
      "L2M1_rh     False               0.504059                   0.446843\n"
     ]
    }
   ],
   "source": [
    "dataset = metric_for_hemispheres(subjects, nx.algorithms.cluster.transitivity)\n",
    "print(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5125 0.25 0.75 [0.5] [3]\n",
      "Specificity 0.1766666666666667 0.0 0.3333333333333333 [0.2] [3]\n",
      "Sensitivity:  1.0 1.0 1.0 [1.] [10]\n",
      "Positive Predictive Value:  0.45892857142857135 0.25 0.7142857142857143 [0.42857143] [3]\n",
      "Negative Predictive Value:  0.8 0.0 1.0 [1.] [8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "<ipython-input-216-f5ffdc70cb43>:44: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if np.isnan((tn/(tn + fn))):\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "<ipython-input-216-f5ffdc70cb43>:44: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if np.isnan((tn/(tn + fn))):\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/user/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "y = dataset['resected'].to_numpy()\n",
    "x = dataset.drop(['resected'], axis=1).to_numpy()\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = MaxAbsScaler()\n",
    "# scaler = RobustScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "    # clf = AdaBoostClassifier(n_estimators=10)\n",
    "    # clf = svm.SVC()\n",
    "    # clf = svm.SVC(kernel='linear', class_weight={True: .8, False: 1})\n",
    "    # clf = svm.SVC(kernel='sigmoid', class_weight={True: .8, False: 1})\n",
    "    # clf = svm.SVC(class_weight={True: .8, False: 1})\n",
    "    # clf = SGDClassifier()\n",
    "    # clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    # clf = LogisticRegression(class_weight={True: .8, False: 1})\n",
    "    # clf = RandomForestClassifier(max_depth=20)\n",
    "    # clf = GaussianNB()\n",
    "    # clf = LinearDiscriminantAnalysis()\n",
    "    clf = QuadraticDiscriminantAnalysis()\n",
    "    # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "    # clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    acc.append(accuracy_score(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    spec.append(tn / (tn + fp))\n",
    "    sens.append(tp / (tp + fn))\n",
    "\n",
    "    if np.isnan(tp/(tp + fp)):\n",
    "        pospred.append(0)\n",
    "    else:\n",
    "        pospred.append(tp/(tp + fp))\n",
    "\n",
    "    if np.isnan((tn/(tn + fn))):\n",
    "        negpred.append(0)\n",
    "    else:\n",
    "        negpred.append(tn/(tn + fn))\n",
    "\n",
    "max_acc = np.max(np.array(acc))\n",
    "min_acc = np.min(np.array(acc))\n",
    "moda_acc, cacc = sp.stats.mode(np.array(acc))\n",
    "acc = sum(acc)/len(acc)\n",
    "max_spec = np.max(np.array(spec))\n",
    "min_spec = np.min(np.array(spec))\n",
    "moda_spec, cspec = sp.stats.mode(np.array(spec))\n",
    "spec = sum(spec)/len(spec)\n",
    "max_sens = np.max(np.array(sens))\n",
    "min_sens = np.min(np.array(sens))\n",
    "moda_sens, csens = sp.stats.mode(np.array(sens))\n",
    "sens = sum(sens)/len(sens)\n",
    "max_pospred = np.max(np.array(pospred))\n",
    "min_pospred = np.min(np.array(pospred))\n",
    "moda_pospred, cpospred = sp.stats.mode(np.array(pospred))\n",
    "pospred = sum(pospred)/len(pospred)\n",
    "max_negpred = np.max(np.array(negpred))\n",
    "min_negpred = np.min(np.array(negpred))\n",
    "moda_negpred, cnegspred = sp.stats.mode(np.array(negpred))\n",
    "negpred = sum(negpred)/len(negpred)\n",
    "print('Accuracy: ', acc, min_acc, max_acc, moda_acc, cacc)\n",
    "print('Specificity', spec, min_spec, max_spec, moda_spec, cspec)\n",
    "print('Sensitivity: ', sens, min_sens, max_sens, moda_sens, csens)\n",
    "print('Positive Predictive Value: ', pospred, min_pospred, max_pospred, moda_pospred, cpospred)\n",
    "print('Negative Predictive Value: ', negpred, min_negpred, max_negpred, moda_negpred, cnegspred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M2S2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_front_inf-Opercular-rh\n",
      "\n",
      "\t7.5-12.5Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.035408499433554674\n",
      "\n",
      "\t{'G&S_cingul-Mid-Ant-rh', 'S_circular_insula_inf-lh', 'S_interm_prim-Jensen-rh', 'G_temporal_middle-lh', 'S_front_inf-rh', 'G_precentral-lh', 'G&S_frontomargin-lh', 'S_front_sup-lh', 'S_temporal_inf-rh', 'S_front_middle-rh', 'G_oc-temp_med-Lingual-rh', 'G_postcentral-lh', 'S_pericallosal-rh', 'G_pariet_inf-Angular-rh', 'Lat_Fis-ant-Horizont-lh', 'G_postcentral-rh', 'G_oc-temp_med-Parahip-rh', 'G&S_cingul-Mid-Post-lh', 'G&S_cingul-Mid-Post-rh', 'S_subparietal-lh', 'G_insular_short-lh', 'G_subcallosal-lh', 'G_front_inf-Opercular-rh', 'G_subcallosal-rh', 'S_calcarine-rh', 'G_occipital_middle-lh', 'S_cingul-Marginalis-lh', 'S_interm_prim-Jensen-lh', 'S_oc_middle&Lunatus-lh', 'G_precentral-rh', 'G_cuneus-rh', 'S_orbital_lateral-lh', 'Lat_Fis-ant-Vertical-rh', 'S_precentral-sup-part-lh', 'S_orbital-H_Shaped-rh', 'S_oc_sup&transversal-rh', 'G_pariet_inf-Angular-lh', 'G&S_subcentral-rh', 'S_parieto_occipital-rh', 'S_postcentral-rh', 'S_postcentral-lh', 'G&S_frontomargin-rh', 'S_central-rh', 'G_rectus-lh', 'G&S_paracentral-lh', 'S_orbital_med-olfact-lh', 'S_precentral-inf-part-rh', 'G_temp_sup-Plan_polar-lh', 'G&S_occipital_inf-lh', 'S_temporal_sup-lh', 'S_collat_transv_ant-lh', 'G_temp_sup-Lateral-lh', 'G_cuneus-lh', 'G&S_subcentral-lh', 'G_insular_short-rh', 'Unknown-rh', 'S_subparietal-rh', 'G_occipital_sup-lh', 'S_temporal_transverse-rh', 'G&S_cingul-Ant-lh', 'S_precentral-sup-part-rh', 'S_orbital_med-olfact-rh', 'S_intrapariet&P_trans-rh', 'Lat_Fis-ant-Vertical-lh', 'Pole_temporal-lh', 'G_temporal_inf-rh', 'G_precuneus-lh', 'S_front_inf-lh', 'G_parietal_sup-rh', 'S_oc-temp_med&Lingual-rh', 'G_front_inf-Orbital-lh', 'G_occipital_sup-rh', 'G_occipital_middle-rh', 'G_front_middle-lh', 'G_temp_sup-G_T_transv-rh', 'Pole_occipital-lh', 'Lat_Fis-ant-Horizont-rh', 'G_Ins_lg&S_cent_ins-rh', 'S_front_sup-rh', 'G_temp_sup-Lateral-rh', 'S_intrapariet&P_trans-lh', 'G_cingul-Post-ventral-lh', 'S_orbital-H_Shaped-lh', 'S_oc-temp_lat-lh', 'G_precuneus-rh', 'S_occipital_ant-lh', 'G&S_cingul-Ant-rh', 'G_oc-temp_med-Parahip-lh', 'G&S_transv_frontopol-rh', 'Pole_temporal-rh', 'G&S_occipital_inf-rh', 'S_temporal_sup-rh', 'S_circular_insula_sup-rh', 'G&S_transv_frontopol-lh', 'S_parieto_occipital-lh', 'G_temporal_inf-lh', 'G_front_inf-Triangul-rh', 'G_temp_sup-Plan_polar-rh', 'S_temporal_inf-lh', 'S_calcarine-lh', 'Lat_Fis-post-rh', 'G_pariet_inf-Supramar-rh', 'S_suborbital-rh', 'S_orbital_lateral-rh', 'S_cingul-Marginalis-rh', 'G_front_sup-lh', 'G_front_inf-Opercular-lh', 'S_pericallosal-lh', 'Unknown-lh', 'S_circular_insula_ant-rh', 'G_cingul-Post-dorsal-rh', 'G_oc-temp_lat-fusifor-rh', 'G_temp_sup-G_T_transv-lh', 'G_pariet_inf-Supramar-lh', 'S_collat_transv_post-rh', 'S_circular_insula_sup-lh', 'G&S_paracentral-rh', 'G_front_inf-Orbital-rh', 'G_cingul-Post-dorsal-lh', 'G_rectus-rh', 'G_front_middle-rh', 'S_suborbital-lh', 'S_circular_insula_ant-lh', 'G_cingul-Post-ventral-rh', 'G_temp_sup-Plan_tempo-lh', 'S_oc-temp_lat-rh', 'G_oc-temp_lat-fusifor-lh', 'G_Ins_lg&S_cent_ins-lh', 'S_circular_insula_inf-rh', 'G_front_sup-rh', 'G_temp_sup-Plan_tempo-rh', 'G_orbital-rh', 'S_temporal_transverse-lh', 'S_front_middle-lh', 'G_orbital-lh', 'G_parietal_sup-lh', 'S_oc_middle&Lunatus-rh', 'S_collat_transv_ant-rh', 'G_front_inf-Triangul-lh', 'S_collat_transv_post-lh', 'S_oc_sup&transversal-lh', 'G&S_cingul-Mid-Ant-lh', 'S_precentral-inf-part-lh', 'G_temporal_middle-rh', 'Lat_Fis-post-lh', 'S_central-lh', 'G_oc-temp_med-Lingual-lh', 'S_oc-temp_med&Lingual-lh', 'Pole_occipital-rh'}\n",
      "\t{'S_occipital_ant-rh'}\n",
      "\n",
      "\t7.5-12.5Hz: envelope\n",
      "\n",
      "\themispheres division modularity: -0.036621440108617925\n",
      "\n",
      "\t{'G&S_cingul-Mid-Ant-rh', 'S_circular_insula_inf-lh', 'S_interm_prim-Jensen-rh', 'G_temporal_middle-lh', 'S_front_inf-rh', 'G_precentral-lh', 'G&S_frontomargin-lh', 'S_front_sup-lh', 'S_temporal_inf-rh', 'S_front_middle-rh', 'G_oc-temp_med-Lingual-rh', 'G_postcentral-lh', 'S_pericallosal-rh', 'G_pariet_inf-Angular-rh', 'Lat_Fis-ant-Horizont-lh', 'G_postcentral-rh', 'G_oc-temp_med-Parahip-rh', 'G&S_cingul-Mid-Post-lh', 'G&S_cingul-Mid-Post-rh', 'S_subparietal-lh', 'G_insular_short-lh', 'G_subcallosal-lh', 'G_front_inf-Opercular-rh', 'G_subcallosal-rh', 'S_calcarine-rh', 'G_occipital_middle-lh', 'S_cingul-Marginalis-lh', 'S_interm_prim-Jensen-lh', 'S_oc_middle&Lunatus-lh', 'G_precentral-rh', 'G_cuneus-rh', 'S_precentral-sup-part-lh', 'Lat_Fis-ant-Vertical-rh', 'S_orbital_lateral-lh', 'S_orbital-H_Shaped-rh', 'S_oc_sup&transversal-rh', 'G_pariet_inf-Angular-lh', 'G&S_subcentral-rh', 'S_parieto_occipital-rh', 'S_postcentral-rh', 'S_central-rh', 'S_postcentral-lh', 'G&S_frontomargin-rh', 'G_rectus-lh', 'G&S_paracentral-lh', 'S_precentral-inf-part-rh', 'S_orbital_med-olfact-lh', 'G_temp_sup-Plan_polar-lh', 'S_temporal_sup-lh', 'G&S_occipital_inf-lh', 'S_collat_transv_ant-lh', 'G_temp_sup-Lateral-lh', 'G_cuneus-lh', 'G&S_subcentral-lh', 'G_insular_short-rh', 'Unknown-rh', 'G_occipital_sup-lh', 'S_temporal_transverse-rh', 'G&S_cingul-Ant-lh', 'S_precentral-sup-part-rh', 'S_orbital_med-olfact-rh', 'S_intrapariet&P_trans-rh', 'Lat_Fis-ant-Vertical-lh', 'G_temporal_inf-rh', 'Pole_temporal-lh', 'G_precuneus-lh', 'S_front_inf-lh', 'G_parietal_sup-rh', 'S_oc-temp_med&Lingual-rh', 'G_front_inf-Orbital-lh', 'G_occipital_middle-rh', 'G_occipital_sup-rh', 'G_front_middle-lh', 'G_temp_sup-G_T_transv-rh', 'Pole_occipital-lh', 'Lat_Fis-ant-Horizont-rh', 'G_Ins_lg&S_cent_ins-rh', 'S_front_sup-rh', 'G_temp_sup-Lateral-rh', 'S_intrapariet&P_trans-lh', 'G_cingul-Post-ventral-lh', 'S_orbital-H_Shaped-lh', 'S_occipital_ant-lh', 'G_precuneus-rh', 'S_oc-temp_lat-lh', 'G&S_cingul-Ant-rh', 'G_oc-temp_med-Parahip-lh', 'G&S_transv_frontopol-rh', 'G&S_occipital_inf-rh', 'Pole_temporal-rh', 'S_occipital_ant-rh', 'S_temporal_sup-rh', 'S_circular_insula_sup-rh', 'G&S_transv_frontopol-lh', 'S_parieto_occipital-lh', 'G_temporal_inf-lh', 'G_front_inf-Triangul-rh', 'G_temp_sup-Plan_polar-rh', 'S_temporal_inf-lh', 'S_calcarine-lh', 'Lat_Fis-post-rh', 'G_pariet_inf-Supramar-rh', 'S_suborbital-rh', 'S_orbital_lateral-rh', 'S_cingul-Marginalis-rh', 'G_front_sup-lh', 'G_front_inf-Opercular-lh', 'S_pericallosal-lh', 'Unknown-lh', 'S_circular_insula_ant-rh', 'G_cingul-Post-dorsal-rh', 'G_oc-temp_lat-fusifor-rh', 'G_temp_sup-G_T_transv-lh', 'G_pariet_inf-Supramar-lh', 'S_collat_transv_post-rh', 'S_circular_insula_sup-lh', 'G_front_inf-Orbital-rh', 'G&S_paracentral-rh', 'G_cingul-Post-dorsal-lh', 'G_rectus-rh', 'G_front_middle-rh', 'S_suborbital-lh', 'S_circular_insula_ant-lh', 'G_temp_sup-Plan_tempo-lh', 'G_cingul-Post-ventral-rh', 'S_oc-temp_lat-rh', 'G_oc-temp_lat-fusifor-lh', 'G_Ins_lg&S_cent_ins-lh', 'S_circular_insula_inf-rh', 'G_front_sup-rh', 'G_temp_sup-Plan_tempo-rh', 'G_orbital-rh', 'S_temporal_transverse-lh', 'S_front_middle-lh', 'G_orbital-lh', 'G_parietal_sup-lh', 'S_oc_middle&Lunatus-rh', 'S_collat_transv_ant-rh', 'G_front_inf-Triangul-lh', 'S_collat_transv_post-lh', 'S_oc_sup&transversal-lh', 'S_precentral-inf-part-lh', 'G&S_cingul-Mid-Ant-lh', 'G_temporal_middle-rh', 'Lat_Fis-post-lh', 'S_central-lh', 'G_oc-temp_med-Lingual-lh', 'S_oc-temp_med&Lingual-lh', 'Pole_occipital-rh'}\n",
      "\t{'S_subparietal-rh'}\n",
      "R1D2\n",
      "\n",
      "\tresected nodes:\n",
      "\tG_front_sup-rh\n",
      "\n",
      "\t7.5-11Hz: wpli\n",
      "\n",
      "\themispheres division modularity: -0.014056770804251911\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-179-8b5040f67cc6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'\\n\\themispheres division modularity: {hemispheres_division_modularity(G)}\\n'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m             \u001B[0mcomp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malgorithms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcommunity\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcentrality\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgirvan_newman\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcomp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'\\t{c}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/networkx/algorithms/community/centrality.py\u001B[0m in \u001B[0;36mgirvan_newman\u001B[0;34m(G, most_valuable_edge)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0mg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mremove_edges_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselfloop_edges\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0mg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber_of_edges\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m         \u001B[0;32myield\u001B[0m \u001B[0m_without_most_central_edges\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmost_valuable_edge\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/networkx/algorithms/community/centrality.py\u001B[0m in \u001B[0;36m_without_most_central_edges\u001B[0;34m(G, most_valuable_edge)\u001B[0m\n\u001B[1;32m    164\u001B[0m     \u001B[0mnum_new_components\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moriginal_num_components\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0mnum_new_components\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0moriginal_num_components\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 166\u001B[0;31m         \u001B[0medge\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmost_valuable_edge\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    167\u001B[0m         \u001B[0mG\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mremove_edge\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0medge\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[0mnew_components\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconnected_components\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/networkx/algorithms/community/centrality.py\u001B[0m in \u001B[0;36mmost_valuable_edge\u001B[0;34m(G)\u001B[0m\n\u001B[1;32m    136\u001B[0m             \u001B[0;31m# We have guaranteed that the graph is non-empty, so this\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m             \u001B[0;31m# dictionary will never be empty.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 138\u001B[0;31m             \u001B[0mbetweenness\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0medge_betweenness_centrality\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    139\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbetweenness\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbetweenness\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-242>\u001B[0m in \u001B[0;36medge_betweenness_centrality\u001B[0;34m(G, k, normalized, weight, seed)\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/networkx/utils/decorators.py\u001B[0m in \u001B[0;36m_random_state\u001B[0;34m(func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    467\u001B[0m         \u001B[0mnew_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    468\u001B[0m         \u001B[0mnew_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mrandom_state_index\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 469\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnew_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    470\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    471\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0m_random_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/networkx/algorithms/centrality/betweenness.py\u001B[0m in \u001B[0;36medge_betweenness_centrality\u001B[0;34m(G, k, normalized, weight, seed)\u001B[0m\n\u001B[1;32m    222\u001B[0m         \u001B[0;31m# single source shortest paths\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mweight\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# use BFS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 224\u001B[0;31m             \u001B[0mS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msigma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_single_source_shortest_path_basic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    225\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# use Dijkstra's algorithm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    226\u001B[0m             \u001B[0mS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msigma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_single_source_dijkstra_path_basic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mG\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/networkx/algorithms/centrality/betweenness.py\u001B[0m in \u001B[0;36m_single_source_shortest_path_basic\u001B[0;34m(G, s)\u001B[0m\n\u001B[1;32m    266\u001B[0m                 \u001B[0mQ\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m                 \u001B[0mD\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDv\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 268\u001B[0;31m             \u001B[0;32mif\u001B[0m \u001B[0mD\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mDv\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# this is a shortest path, count paths\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    269\u001B[0m                 \u001B[0msigma\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0msigmav\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m                 \u001B[0mP\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# predecessors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    print(subject.name)\n",
    "    print('\\n\\tresected nodes:')\n",
    "    for node in subject.nodes:\n",
    "        if node.type == 'resected':\n",
    "            print(f'\\t{node.label.name}')\n",
    "    for freq in subject.graph:\n",
    "        for method in subject.graph[freq]:\n",
    "            print(f'\\n\\t{freq}: {method}')\n",
    "            G = sparse_graph(subject.graph[freq][method])\n",
    "            c = graph_to_connectome(G)\n",
    "            lh, rh = graph_to_hemispheres(G)\n",
    "            print(f'\\n\\themispheres division modularity: {hemispheres_division_modularity(G)}\\n')\n",
    "            comp = nx.algorithms.community.centrality.girvan_newman(G)\n",
    "            for c in next(comp):\n",
    "                print(f'\\t{c}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def current_flow(G):\n",
    "    c = nx.edge_current_flow_betweenness_centrality(G)\n",
    "    return max(c, key=c.get)\n",
    "\n",
    "def heaviest(G):\n",
    "    u, v, w = max(G.edges(data=\"weight\"), key=itemgetter(2))\n",
    "    del w\n",
    "    return u, v\n",
    "\n",
    "for subject in subjects:\n",
    "    print(subject.name)\n",
    "    print('\\n\\tresected nodes:')\n",
    "    for node in subject.nodes:\n",
    "        if node.type == 'resected':\n",
    "            print(f'\\t{node.label.name}')\n",
    "    for freq in subject.graph:\n",
    "        for method in subject.graph[freq]:\n",
    "            print(f'\\n\\t{freq}: {method}')\n",
    "            G = sparse_graph(subject.graph[freq][method])\n",
    "            c = graph_to_connectome(G)\n",
    "            lh, rh = graph_to_hemispheres(G)\n",
    "            print(f'\\n\\themispheres division modularity: {hemispheres_division_modularity(G)}\\n')\n",
    "            comp = nx.algorithms.community.centrality.girvan_newman(\n",
    "                lh,\n",
    "                heaviest\n",
    "            )\n",
    "            for c in next(comp):\n",
    "                print(f'\\t{c}')\n",
    "            comp = nx.algorithms.community.centrality.girvan_newman(\n",
    "                rh,\n",
    "                heaviest\n",
    "            )\n",
    "            for c in next(comp):\n",
    "                print(f'\\t{c}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stat1 = SubjectsStatistic(subjects, 'resected', centrality_metric='eigen')\n",
    "stat2 = SubjectsStatistic(subjects, 'resected', centrality_metric='close')\n",
    "# stat3 = SubjectsStatistic(subjects, 'resected', centrality_metric='between')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subjects_brains = dict()\n",
    "c = 'eigen'\n",
    "for subject in subjects:\n",
    "    subjects_brains.update({subject: dict()})\n",
    "    lh, rh = pd.DataFrame(), pd.DataFrame()\n",
    "    resected = None\n",
    "    for i in range(len(subject.dataset[c].index)):\n",
    "        if 'lh' in subject.dataset[c].iloc[i].name:\n",
    "            if subject.dataset[c].iloc[i]['resected'] and resected is None:\n",
    "                resected = 'left'\n",
    "            lh = append_series(lh, subject.dataset[c].iloc[i][['4-7Hz_envelope', '4-7Hz_wpli']], index=subject.dataset[c].iloc[i].name)\n",
    "        else:\n",
    "            rh = append_series(rh, subject.dataset[c].iloc[i][['4-7Hz_envelope', '4-7Hz_wpli']], index=subject.dataset[c].iloc[i].name)\n",
    "            if subject.dataset[c].iloc[i]['resected'] and resected is None:\n",
    "                resected = 'right'\n",
    "    subjects_brains[subject].update({'lh': lh, 'rh': rh, 'resected': resected})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = list()\n",
    "for brain in subjects_brains:\n",
    "    if subjects_brains[brain]['resected'] == 'left':\n",
    "        y.append(True)\n",
    "        y.append(False)\n",
    "    else:\n",
    "        y.append(False)\n",
    "        y.append(True)\n",
    "y = np.array(y)\n",
    "x = list()\n",
    "for brain in subjects_brains:\n",
    "    x.append(subjects_brains[brain]['lh'].to_numpy().T)\n",
    "    x.append(subjects_brains[brain]['rh'].to_numpy().T)\n",
    "\n",
    "x = np.array(x)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    x[i] = scaler.fit_transform(x[i].T).T\n",
    "nsamples, nx, ny = x.shape\n",
    "x = x.reshape((nsamples, nx*ny))\n",
    "print(x[0, :].shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "# clf = AdaBoostClassifier(n_estimators=10)\n",
    "# clf = svm.SVC(kernel='linear')\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "# clf = svm.SVC(class_weight={True: 1, False: .8}, probability=True)\n",
    "# clf = SGDClassifier()\n",
    "# clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# clf = LogisticRegression(class_weight={True: 1, False: .8})\n",
    "# clf = RandomForestClassifier(max_depth=20)\n",
    "# clf = GaussianNB()\n",
    "# clf = LinearDiscriminantAnalysis()\n",
    "# clf = KMeans(n_clusters=2, algorithm='full')\n",
    "# clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#     s2 = subject.dataset['4-7Hz_imcoh']\n",
    "#     print(s1.corr(s2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(stat1.datasets['true'].shape)\n",
    "print(stat1.datasets['false'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          resampled, eigen  reflected, eigen  resampled, close  \\\n",
      "wpli              0.065466          0.069655          0.078691   \n",
      "envelope          0.769480          0.099622          0.567217   \n",
      "\n",
      "          reflected, close  \n",
      "wpli              0.834195  \n",
      "envelope          0.124772  \n"
     ]
    }
   ],
   "source": [
    "test11 = stat1.test(state='resampled')\n",
    "test12 = stat1.test(state='reflected')\n",
    "test21 = stat2.test(state='resampled')\n",
    "test22 = stat2.test(state='reflected')\n",
    "test11_samples, test12_samples, test21_samples, test22_samples = list(), list(), list(), list()\n",
    "for feature in test11.result:\n",
    "    test11_samples.append(test11.result[feature][1])\n",
    "    test12_samples.append(test12.result[feature][1])\n",
    "    test21_samples.append(test21.result[feature][1])\n",
    "    test22_samples.append(test22.result[feature][1])\n",
    "\n",
    "test_samples = np.array([\n",
    "    np.array(test11_samples),\n",
    "    np.array(test12_samples),\n",
    "    np.array(test21_samples),\n",
    "    np.array(test22_samples)\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(test_samples, columns=list(test11.result.keys()), index=[\n",
    "    'resampled, eigen', 'reflected, eigen', 'resampled, close', 'reflected, close'\n",
    "]).T\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          resampled, eigen  reflected, eigen  resampled, close  \\\n",
      "wpli              0.053815          0.068242          0.151665   \n",
      "envelope          0.452273          0.117178          0.271065   \n",
      "\n",
      "          reflected, close  \n",
      "wpli              0.367013  \n",
      "envelope          0.223778  \n"
     ]
    }
   ],
   "source": [
    "test11 = stat1.test(state='resampled', test='mannwhitneyu')\n",
    "test12 = stat1.test(state='reflected', test='mannwhitneyu')\n",
    "test21 = stat2.test(state='resampled', test='mannwhitneyu')\n",
    "test22 = stat2.test(state='reflected', test='mannwhitneyu')\n",
    "test11_samples, test12_samples, test21_samples, test22_samples = list(), list(), list(), list()\n",
    "for feature in test11.result:\n",
    "    test11_samples.append(test11.result[feature][1])\n",
    "    test12_samples.append(test12.result[feature][1])\n",
    "    test21_samples.append(test21.result[feature][1])\n",
    "    test22_samples.append(test22.result[feature][1])\n",
    "\n",
    "test_samples = np.array([\n",
    "    np.array(test11_samples),\n",
    "    np.array(test12_samples),\n",
    "    np.array(test21_samples),\n",
    "    np.array(test22_samples)\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(test_samples, columns=list(test11.result.keys()), index=[\n",
    "    'resampled, eigen', 'reflected, eigen', 'resampled, close', 'reflected, close'\n",
    "]).T\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# features = ['4-7Hz_wpli', '7-14Hz_wpli', '14-30Hz_wpli', '30-70Hz_wpli']\n",
    "features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "# features = ['4-7Hz_wpli']\n",
    "# features = ['envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_psd']\n",
    "true_data = stat1.datasets['true'][features]\n",
    "false_data = stat1.datasets['false_res'][features]\n",
    "true_data = true_data.assign(resected=True)\n",
    "false_data = false_data.assign(resected=False)\n",
    "dataset = pd.concat([true_data, false_data], axis=0)\n",
    "dataset = dataset.sample(frac = 1)\n",
    "print(dataset)\n",
    "\n",
    "# 61"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "true_data = stat1.datasets['true'][features]\n",
    "true_data_lead = lmd.lead_std(stat1.datasets['true'][features], take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "# true_data_lead = lmd.lead_mean(true_data_lead, take_mean_from=stat1.datasets['false_res'][features], axis=1)\n",
    "false_data = stat1.datasets['false'][features]\n",
    "false_res_data = stat1.datasets['false_res'][features]\n",
    "false_rand_data = stat1.random_samples()[features]\n",
    "means = pd.concat([false_data.mean(), false_res_data.mean(), false_rand_data.mean(), true_data.mean(), true_data_lead.mean()], axis=1)\n",
    "stds = pd.concat([false_data.std(), false_res_data.std(), false_rand_data.std(), true_data.std(), true_data_lead.std()], axis=1)\n",
    "\n",
    "means = pd.DataFrame(means.to_numpy(), index=features, columns=['false', 'false_res', 'false_rand', 'true', 'true_lead'])\n",
    "stds = pd.DataFrame(stds.to_numpy(), index=features, columns=['false', 'false_res', 'false_rand', 'true', 'true_lead'])\n",
    "\n",
    "print(means)\n",
    "print(stds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-129-bb4501231546>:72: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if np.isnan(tp/(tp + fp)):\n",
      "<ipython-input-129-bb4501231546>:72: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if np.isnan(tp/(tp + fp)):\n",
      "<ipython-input-129-bb4501231546>:72: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if np.isnan(tp/(tp + fp)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6264000000000011 0.25 0.9 [0.6] [233]\n",
      "Specificity 0.8956440712065717 0.125 1.0 [1.] [340]\n",
      "Sensitivity:  0.3644910270285273 0.0 1.0 [0.33333333] [91]\n",
      "Positive Predictive Value:  0.7819563767931403 0.0 1.0 [1.] [337]\n",
      "Negative Predictive Value:  0.5850666613829929 0.23076923076923078 1.0 [0.5] [83]\n"
     ]
    }
   ],
   "source": [
    "# features = ['0.5-4Hz_wpli', '4-7Hz_wpli', '7-14Hz_wpli', '14-30Hz_wpli', '30-70Hz_wpli']\n",
    "# features = ['14-30Hz_wpli', '4-7Hz_wpli']\n",
    "# features = ['4-7Hz_wpli', '0.5-4Hz_envelope', '4-7Hz_envelope', '7-14Hz_envelope', '14-30Hz_envelope', '30-70Hz_envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "features = ['wpli', 'envelope']\n",
    "# features = ['4-7Hz_envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_psd']\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "stat = stat1\n",
    "for i in range(1000):\n",
    "    # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "    # clf = AdaBoostClassifier(n_estimators=10)\n",
    "    clf = svm.SVC(class_weight={True: .9, False: 1})\n",
    "    # clf = svm.SVC(class_weight={True: 1, False: .8}, probability=True)\n",
    "    # clf = SGDClassifier()\n",
    "    # clf = KNeighborsClassifier(n_neighbors=7, metric='chebyshev')\n",
    "    # clf = LogisticRegression(class_weight={True: 1, False: .8})\n",
    "    # clf = RandomForestClassifier(max_depth=20)\n",
    "    # clf = GaussianNB()\n",
    "    # clf = LinearDiscriminantAnalysis()\n",
    "    # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "    # clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "    true_data = stat.datasets['true'][features]\n",
    "    # true_data = lmd.lead_std(stat.datasets['true'][features], take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    # false_data = stat.random_samples()[features]\n",
    "    # false_data = lmd.lead_std(stat.datasets['false_res'][features], take_std_from=stat1.datasets['true'][features], axis=1)\n",
    "    # false_data = stat1.datasets['false_res'][features]\n",
    "    # false_data = stat1.datasets['false'][features]\n",
    "    # true_data = stat1.random_samples()[features]\n",
    "    # false_data = stat.random_samples()[features]\n",
    "    false_data = stat.datasets['false_mirror'][features]\n",
    "    true_data = true_data.assign(resected=True)\n",
    "    false_data = false_data.assign(resected=False)\n",
    "    dataset = pd.concat([true_data, false_data], axis=0)\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaler = MaxAbsScaler()\n",
    "    # scaler = RobustScaler()\n",
    "\n",
    "\n",
    "\n",
    "    y = dataset['resected'].to_numpy()\n",
    "    dataset = dataset.drop(['resected'], axis=1)\n",
    "\n",
    "\n",
    "    # dataset = lmd.lead_std(dataset, take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    dataset = lmd.suppress(dataset, axis=1, optimal='max')\n",
    "    # dataset = lmd.promote(dataset, axis=1, optimal='mean')\n",
    "    # dataset = lmd.clusterize(dataset, axis=1, n_clusters=3, optimal='symclose')\n",
    "    # dataset = lmd.binarize(dataset, axis=1)\n",
    "    x = scaler.fit_transform(dataset)\n",
    "    # x = dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    # prob = clf.predict_proba(x_test).tolist()\n",
    "    # for p, x, y in zip(prob, pred, y_test):\n",
    "    #     print(y, x, p)\n",
    "\n",
    "    # df = pd.DataFrame(np.array([np.array(y_test), pred]).T, columns=['actually', 'prediction'])\n",
    "    # print(df)\n",
    "\n",
    "    acc.append(accuracy_score(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    spec.append(tn / (tn + fp))\n",
    "    sens.append(tp / (tp + fn))\n",
    "\n",
    "    if np.isnan(tp/(tp + fp)):\n",
    "        pospred.append(0)\n",
    "    else:\n",
    "        pospred.append(tp/(tp + fp))\n",
    "\n",
    "    if np.isnan((tn/(tn + fn))):\n",
    "        negpred.append(0)\n",
    "    else:\n",
    "        negpred.append(tn/(tn + fn))\n",
    "\n",
    "max_acc = np.max(np.array(acc))\n",
    "min_acc = np.min(np.array(acc))\n",
    "moda_acc, cacc = sp.stats.mode(np.array(acc))\n",
    "acc = sum(acc)/len(acc)\n",
    "max_spec = np.max(np.array(spec))\n",
    "min_spec = np.min(np.array(spec))\n",
    "moda_spec, cspec = sp.stats.mode(np.array(spec))\n",
    "spec = sum(spec)/len(spec)\n",
    "max_sens = np.max(np.array(sens))\n",
    "min_sens = np.min(np.array(sens))\n",
    "moda_sens, csens = sp.stats.mode(np.array(sens))\n",
    "sens = sum(sens)/len(sens)\n",
    "max_pospred = np.max(np.array(pospred))\n",
    "min_pospred = np.min(np.array(pospred))\n",
    "moda_pospred, cpospred = sp.stats.mode(np.array(pospred))\n",
    "pospred = sum(pospred)/len(pospred)\n",
    "max_negpred = np.max(np.array(negpred))\n",
    "min_negpred = np.min(np.array(negpred))\n",
    "moda_negpred, cnegspred = sp.stats.mode(np.array(negpred))\n",
    "negpred = sum(negpred)/len(negpred)\n",
    "print('Accuracy: ', acc, min_acc, max_acc, moda_acc, cacc)\n",
    "print('Specificity', spec, min_spec, max_spec, moda_spec, cspec)\n",
    "print('Sensitivity: ', sens, min_sens, max_sens, moda_sens, csens)\n",
    "print('Positive Predictive Value: ', pospred, min_pospred, max_pospred, moda_pospred, cpospred)\n",
    "print('Negative Predictive Value: ', negpred, min_negpred, max_negpred, moda_negpred, cnegspred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False [0.5607220940473112, 0.43927790595268884]\n",
      "False False [0.4407745752873499, 0.5592254247126499]\n",
      "False True [0.2196200078325757, 0.7803799921674244]\n",
      "True False [0.40373810243809294, 0.596261897561907]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "False False [0.44203751137848574, 0.5579624886215142]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "True False [0.5535351222273772, 0.44646487777262295]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "True False [0.47928226616888486, 0.5207177338311152]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "True True [0.27711460311389474, 0.7228853968861053]\n",
      "False True [0.2583733107196455, 0.7416266892803546]\n",
      "False True [0.36486861568763956, 0.6351313843123605]\n",
      "False False [0.586672234894149, 0.413327765105851]\n",
      "True False [0.4710348003184959, 0.5289651996815041]\n",
      "False True [0.2417079657337907, 0.7582920342662094]\n",
      "True True [0.24049264690145836, 0.7595073530985416]\n",
      "True False [0.5667423569451508, 0.4332576430548493]\n",
      "False True [0.3922861217527679, 0.6077138782472322]\n",
      "Accuracy:  0.45 0.45 0.45 [0.45] [1]\n",
      "Specifity 0.5833333333333334 0.5833333333333334 0.5833333333333334 [0.58333333] [1]\n",
      "Sensitivity:  0.25 0.25 0.25 [0.25] [1]\n",
      "Positive Predictive Value:  0.2857142857142857 0.2857142857142857 0.2857142857142857 [0.28571429] [1]\n",
      "Negative Predictive Value:  0.5384615384615384 0.5384615384615384 0.5384615384615384 [0.53846154] [1]\n"
     ]
    }
   ],
   "source": [
    "# features = ['0.5-4Hz_wpli', '4-7Hz_wpli', '7-14Hz_wpli', '14-30Hz_wpli', '30-70Hz_wpli']\n",
    "# features = ['14-30Hz_wpli', '4-7Hz_wpli']\n",
    "# features = ['4-7Hz_wpli', '0.5-4Hz_envelope']\n",
    "# features = ['4-7Hz_wpli']\n",
    "# features = ['envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_psd']\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "stat = stat1\n",
    "for i in range(1):\n",
    "    # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "    # clf = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "    # clf = svm.SVC(kernel='linear')\n",
    "    clf = svm.SVC(class_weight={True: .9, False: 1}, probability=True)\n",
    "    # clf = SGDClassifier()\n",
    "    # clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    # clf = LogisticRegression()\n",
    "    # clf = RandomForestClassifier(max_depth=20)\n",
    "    # clf = GaussianNB()\n",
    "    # clf = LinearDiscriminantAnalysis()\n",
    "    # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "    # clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "    true_data = stat.datasets['true'][features]\n",
    "    # true_data = lmd.lead_std(stat.datasets['true'][features], take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    false_data = stat1.random_samples()[features]\n",
    "    # false_data = lmd.lead_std(stat.datasets['false_res'][features], take_std_from=stat1.datasets['true'][features], axis=1)\n",
    "    # false_data = stat1.datasets['false_res'][features]\n",
    "    # false_data = stat1.datasets['false'][features]\n",
    "    # true_data = stat1.random_samples()[features]\n",
    "    # false_data = stat.random_samples()[features]\n",
    "    # true_data = stat1.datasets['false_mirror'][features]\n",
    "    true_data = true_data.assign(resected=True)\n",
    "    false_data = false_data.assign(resected=False)\n",
    "    dataset = pd.concat([true_data, false_data], axis=0)\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaler = MaxAbsScaler()\n",
    "    # scaler = RobustScaler()\n",
    "\n",
    "\n",
    "\n",
    "    y = dataset['resected'].to_numpy()\n",
    "    dataset = dataset.drop(['resected'], axis=1)\n",
    "\n",
    "\n",
    "    # dataset = lmd.lead_std(dataset, take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    dataset = lmd.suppress(dataset, axis=1, optimal='max')\n",
    "    # dataset = lmd.promote(dataset, axis=1, optimal='min')\n",
    "    # dataset = lmd.clusterize(dataset, axis=1, n_clusters=3, optimal='max')\n",
    "    # dataset = lmd.binarize(dataset, axis=1)\n",
    "\n",
    "    x = scaler.fit_transform(dataset)\n",
    "    # x = dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    prob = clf.predict_proba(x_test).tolist()\n",
    "    for p, x, y in zip(prob, pred, y_test):\n",
    "        print(y, x, p)\n",
    "\n",
    "    # df = pd.DataFrame(np.array([np.array(y_test), pred]).T, columns=['actually', 'prediction'])\n",
    "    # print(df)\n",
    "\n",
    "    acc.append(accuracy_score(y_test, pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    spec.append(tn / (tn + fp))\n",
    "    sens.append(tp / (tp + fn))\n",
    "\n",
    "    if np.isnan(tp/(tp + fp)):\n",
    "        pospred.append(0)\n",
    "    else:\n",
    "        pospred.append(tp/(tp + fp))\n",
    "\n",
    "    if np.isnan((tn/(tn + fn))):\n",
    "        negpred.append(0)\n",
    "    else:\n",
    "        negpred.append(tn/(tn + fn))\n",
    "\n",
    "max_acc = np.max(np.array(acc))\n",
    "min_acc = np.min(np.array(acc))\n",
    "moda_acc, cacc = sp.stats.mode(np.array(acc))\n",
    "acc = sum(acc)/len(acc)\n",
    "max_spec = np.max(np.array(spec))\n",
    "min_spec = np.min(np.array(spec))\n",
    "moda_spec, cspec = sp.stats.mode(np.array(spec))\n",
    "spec = sum(spec)/len(spec)\n",
    "max_sens = np.max(np.array(sens))\n",
    "min_sens = np.min(np.array(sens))\n",
    "moda_sens, csens = sp.stats.mode(np.array(sens))\n",
    "sens = sum(sens)/len(sens)\n",
    "max_pospred = np.max(np.array(pospred))\n",
    "min_pospred = np.min(np.array(pospred))\n",
    "moda_pospred, cpospred = sp.stats.mode(np.array(pospred))\n",
    "pospred = sum(pospred)/len(pospred)\n",
    "max_negpred = np.max(np.array(negpred))\n",
    "min_negpred = np.min(np.array(negpred))\n",
    "moda_negpred, cnegspred = sp.stats.mode(np.array(negpred))\n",
    "negpred = sum(negpred)/len(negpred)\n",
    "print('Accuracy: ', acc, min_acc, max_acc, moda_acc, cacc)\n",
    "print('Specificity', spec, min_spec, max_spec, moda_spec, cspec)\n",
    "print('Sensitivity: ', sens, min_sens, max_sens, moda_sens, csens)\n",
    "print('Positive Predictive Value: ', pospred, min_pospred, max_pospred, moda_pospred, cpospred)\n",
    "print('Negative Predictive Value: ', negpred, min_negpred, max_negpred, moda_negpred, cnegspred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6406214285714303 0.5982142857142858 0.6642857142857144\n"
     ]
    }
   ],
   "source": [
    "# features = ['0.5-4Hz_wpli', '4-7Hz_wpli', '7-14Hz_wpli', '14-30Hz_wpli', '30-70Hz_wpli']\n",
    "# features = ['14-30Hz_wpli', '4-7Hz_wpli']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_envelope']\n",
    "features = ['wpli', 'envelope']\n",
    "# features = ['4-7Hz_wpli']\n",
    "# features = ['envelope']\n",
    "# features = ['4-7Hz_wpli', '4-7Hz_psd']\n",
    "acc, spec, sens, pospred, negpred = list(), list(), list(), list(), list()\n",
    "stat = stat1\n",
    "for i in range(1000):\n",
    "    # clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=10)\n",
    "    # clf = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "    # clf = svm.SVC(kernel='linear')\n",
    "    clf = svm.SVC(class_weight={True: .9, False: 1}, probability=True)\n",
    "    # clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    # clf = LogisticRegression()\n",
    "    # clf = RandomForestClassifier(max_depth=20)\n",
    "    # clf = GaussianNB()\n",
    "    # clf = LinearDiscriminantAnalysis()\n",
    "    # clf = KMeans(n_clusters=2, algorithm='full')\n",
    "    # clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 10), max_iter=1450)\n",
    "\n",
    "    true_data = stat.datasets['true'][features]\n",
    "    # false_data = stat1.random_samples()[features]\n",
    "    # false_data = stat1.datasets['false_res'][features]\n",
    "    # true_data = stat1.random_samples()[features]\n",
    "    # false_data = stat.random_samples()[features]\n",
    "    # false_data = lmd.lead_std(stat.datasets['false_res'][features], take_std_from=stat.datasets['true'][features], axis=1)\n",
    "    false_data = stat.datasets['false_mirror'][features]\n",
    "    true_data = true_data.assign(resected=True)\n",
    "    false_data = false_data.assign(resected=False)\n",
    "    dataset = pd.concat([true_data, false_data], axis=0)\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaler = MaxAbsScaler()\n",
    "    # scaler = RobustScaler()\n",
    "\n",
    "\n",
    "\n",
    "    y = dataset['resected'].to_numpy()\n",
    "    dataset = dataset.drop(['resected'], axis=1)\n",
    "\n",
    "\n",
    "    # dataset = lmd.lead_std(dataset, take_std_from=stat1.datasets['false_res'][features], axis=1)\n",
    "    dataset = lmd.suppress(dataset, axis=1, optimal='max')\n",
    "    # dataset = lmd.promote(dataset, axis=1, optimal='min')\n",
    "    # dataset = lmd.clusterize(dataset, axis=1, n_clusters=3, optimal='max')\n",
    "    # dataset = lmd.binarize(dataset, axis=1)\n",
    "\n",
    "\n",
    "    x = scaler.fit_transform(dataset)\n",
    "    # x = dataset\n",
    "    scores = cross_val_score(clf, x, y, cv=10)\n",
    "    acc.append(scores.mean())\n",
    "\n",
    "print('Accuracy: ', sum(acc)/len(acc), min(acc), max(acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from nodestimation.mlearning.features import prepare_connectivity, prepare_data\n",
    "# con = pkl.load(open(subjects[0].data['con'], 'rb'))\n",
    "\n",
    "subjects_dir, subjects_ = find_subject_dir()\n",
    "labels = mne.read_labels_from_annot('B1C2', parc='aparc', subjects_dir=subjects_dir)\n",
    "label_names = [label.name for label in labels]\n",
    "lh_labels = [name for name in label_names if name.endswith('lh')]\n",
    "rh_labels = [name for name in label_names if name.endswith('rh')]\n",
    "\n",
    "label_ypos_lh = list()\n",
    "\n",
    "for name in lh_labels:\n",
    "    idx = label_names.index(name)\n",
    "    ypos = np.mean(labels[idx].pos[:, 1])\n",
    "    label_ypos_lh.append(ypos)\n",
    "\n",
    "try:\n",
    "    idx = label_names.index('Brain-Stem')\n",
    "\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    ypos = np.mean(labels[idx].pos[:, 1])\n",
    "    lh_labels.append('Brain-Stem')\n",
    "    label_ypos_lh.append(ypos)\n",
    "\n",
    "\n",
    "lh_labels = [label for (yp, label) in sorted(zip(label_ypos_lh, lh_labels))]\n",
    "\n",
    "rh_labels = [label[:-2] + 'rh' for label in lh_labels\n",
    "             if label != 'Brain-Stem' and label[:-2] + 'rh' in rh_labels]\n",
    "\n",
    "\n",
    "node_colors = [label.color for label in labels]\n",
    "\n",
    "node_order = lh_labels[::-1] + rh_labels\n",
    "\n",
    "node_angles = mne.viz.circular_layout(label_names, node_order, start_pos=90,\n",
    "                              group_boundaries=[0, len(label_names) // 2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# methods = [\n",
    "#     'coh',\n",
    "#     'imcoh',\n",
    "#     'plv',\n",
    "#     'ciplv',\n",
    "#     'ppc',\n",
    "#     'pli'\n",
    "# ]\n",
    "#\n",
    "# freq_bands = [\n",
    "#     '0.5-4Hz',\n",
    "#     '4-7Hz',\n",
    "#     '7-14Hz',\n",
    "#     '14-30Hz'\n",
    "# ]\n",
    "#\n",
    "# for method in methods:\n",
    "#     for freq_band in freq_bands:\n",
    "#         fig = plt.figure(num=None, figsize=(25, 25), facecolor='black')\n",
    "#         mne.viz.plot_connectivity_circle(con[freq_band][method]['con'][:, :, 0], label_names, n_lines=300,\n",
    "#                                          node_angles=node_angles, node_colors=node_colors,\n",
    "#                                          title='All-to-All Connectivity Epilepsy Condition ({} for {})'\n",
    "#                                          .format(method, freq_band), padding=8, fontsize_title=35, fontsize_colorbar=25,\n",
    "#                                          fontsize_names=20, fig=fig\n",
    "#                                          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    display = nplt.plot_glass_brain(None, display_mode='lyrz', figure=fig, axes=ax)\n",
    "    spared = [node.nilearn_coordinates for node in subject.nodes if node.type == 'spared']\n",
    "    resected = [node.nilearn_coordinates for node in subject.nodes if node.type == 'resected']\n",
    "    resection = read['resec-mni'](subject.data['resec-mni'])\n",
    "    display.add_markers(resection, marker_color=\"violet\", marker_size=1)\n",
    "    display.add_markers(np.array(spared), marker_color=\"yellow\", marker_size=100)\n",
    "    display.add_markers(np.array(resected), marker_color=\"red\", marker_size=250)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}