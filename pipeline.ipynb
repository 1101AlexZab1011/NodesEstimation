{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs, corrmap)\n",
    "import nilearn.plotting as nplt\n",
    "import pickle\n",
    "from .node_estimate import Node\n",
    "from .timewindow import TimeWindow, sliding_window\n",
    "from .parcellation import freesurf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "root= './'\n",
    "\n",
    "tree = os.walk(os.path.join(root, 'Source'))\n",
    "\n",
    "raw_files = []\n",
    "src_files = []\n",
    "inv_files = []\n",
    "bem_files = []\n",
    "fwd_files = []\n",
    "trans_files = []\n",
    "epochs_files = []\n",
    "ave_files = []\n",
    "stc_files = []\n",
    "\n",
    "subjects_found = False\n",
    "\n",
    "for walk in tree:\n",
    "    for file in walk[2]:\n",
    "        if re.search(r'.*raw\\.fif', file):\n",
    "            raw_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*src.*\\.fif', file):\n",
    "            src_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*inv.*\\.fif', file):\n",
    "            inv_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*bem.*\\.fif', file):\n",
    "            bem_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*fwd.*\\.fif', file):\n",
    "            fwd_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*trans.*\\.fif', file):\n",
    "            trans_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*epo.*\\.fif', file):\n",
    "            epochs_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*ave.*\\.fif', file):\n",
    "            ave_files.append(os.path.join(walk[0], file))\n",
    "        if re.search(r'.*stc.*\\.fif.*', file):\n",
    "            stc_files.append(os.path.join(walk[0], file))\n",
    "\n",
    "    for subdir in walk[1]:\n",
    "        if subdir == 'Subjects' or subdir == 'subjects' and not subjects_found:\n",
    "            subjects_found = True\n",
    "            subjects_dir = os.path.join(walk[0], subdir)\n",
    "        elif subdir == 'Subjects' or subdir == 'subjects' and subjects_found:\n",
    "            raise OSError(\"There are two subjects directories: {}, {}; Only one must be\".format(\n",
    "                subjects_dir, os.path.join(walk[0], subdir)\n",
    "            ))\n",
    "\n",
    "if not raw_files:\n",
    "    raise OSError(\"No one of raw files are found. Raw file must have extension \\'.fif\\' and ends with \\'raw\\'\")\n",
    "\n",
    "if not subjects_found:\n",
    "    raise OSError(\"Subjects directory not found!\")\n",
    "subjects = os.listdir(subjects_dir)\n",
    "\n",
    "subject_dirs = []\n",
    "\n",
    "for subject in subjects:\n",
    "    subject_dirs.append(os.path.join(subjects_dir, subject))\n",
    "\n",
    "raw_file = raw_files[0]\n",
    "bem_file = bem_files[0]\n",
    "src_file = src_files[0]\n",
    "fwd_file = fwd_files[0]\n",
    "trans_file = trans_files[0]\n",
    "\n",
    "res_folder = os.path.join(root, 'Pipeline', subjects[0])\n",
    "\n",
    "res_raw_folder = os.path.join(res_folder, 'Raw')\n",
    "res_bem_folder = os.path.join(res_folder, 'Bem')\n",
    "res_src_folder = os.path.join(res_folder, 'Src')\n",
    "res_fwd_folder = os.path.join(res_folder, 'Fwd')\n",
    "res_events_folder = os.path.join(res_folder, 'Events')\n",
    "res_epochs_folder = os.path.join(res_folder, 'Epochs')\n",
    "res_evoked_folder = os.path.join(res_folder, 'Evoked')\n",
    "res_cov_folder = os.path.join(res_folder, 'Cov')\n",
    "res_inv_folder = os.path.join(res_folder, 'Inv')\n",
    "res_sLORETA_folder = os.path.join(res_folder, 'sLORETA')\n",
    "res_nodes_folder = os.path.join(res_folder, 'NodesEstimate')\n",
    "\n",
    "res_raw_file = os.path.join(res_raw_folder, 'raw.fif')\n",
    "res_bem_file = os.path.join(res_bem_folder, 'raw_bem.fif')\n",
    "res_src_file = os.path.join(res_src_folder, 'raw_src_ico5.fif')\n",
    "res_fwd_file = os.path.join(res_fwd_folder, 'raw_fwd_ico5.fif')\n",
    "res_events_file = os.path.join(res_events_folder, 'raw_eve.fif')\n",
    "res_epochs_file = os.path.join(res_epochs_folder, 'raw_epo.fif')\n",
    "res_evoked_file = os.path.join(res_evoked_folder, 'raw_ave.fif')\n",
    "res_cov_file = os.path.join(res_cov_folder, 'noise_cov.fif')\n",
    "res_inv_file = os.path.join(res_inv_folder, 'raw_inv.fif')\n",
    "res_sLORETA_file = os.path.join(res_sLORETA_folder, 'sLORETA_raw_ave_inv.fif')\n",
    "res_sLORETA_file_lh = os.path.join(res_sLORETA_folder, 'sLORETA_raw_ave_inv.fif-lh.stc')\n",
    "res_sLORETA_file_rh = os.path.join(res_sLORETA_folder, 'sLORETA_raw_ave_inv.fif-rh.stc')\n",
    "res_nodes_strength_file = os.path.join(res_nodes_folder, 'nodes_strength_auc.dat')\n",
    "res_nodes_file = os.path.join(res_nodes_folder, 'nodes.pkl')\n",
    "\n",
    "subject_dir = subject_dirs[0]\n",
    "subject = subjects[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "regexp = r'(MEG [12][45][123]1|EEG 00.)'\n",
    "conductivity = (0.3,)  # for single layer\n",
    "# conductivity = (0.3, 0.006, 0.3)  # for three layers\n",
    "epochs_tmin, epochs_tmax = -3, 3\n",
    "crop_time = 120\n",
    "snr = 0.5  # use SNR smaller than 1 for raw data\n",
    "lambda2 = 1.0 / snr ** 2\n",
    "method = \"sLORETA\"\n",
    "nfreq = 50\n",
    "lfreq = 1\n",
    "hfreq = 70"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "\n",
    "    except OSError:\n",
    "        print(\"PIPELINE: creation of the directory %s failed\" % path)\n",
    "\n",
    "    else:\n",
    "        print(\"PIPELINE: successfully created the directory %s \" % path)\n",
    "\n",
    "\n",
    "@sliding_window(size=1200, overlap=0.5)\n",
    "def do_nothing(sig):\n",
    "\n",
    "    return sig\n",
    "\n",
    "\n",
    "@sliding_window(1200, 0.5)\n",
    "def pearson(signals):\n",
    "\n",
    "    nsigmals, lsignals = signals.shape\n",
    "    out = np.zeros((nsigmals, nsigmals))\n",
    "\n",
    "    for i in range(nsigmals):\n",
    "        for j in range(nsigmals):\n",
    "            out[i, j] = np.corrcoef(signals[i, :], signals[j, :])[0, 1]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def mean_across_tw(twlist):\n",
    "\n",
    "    l, w = twlist[0].data.shape\n",
    "    voxel = voxel_from_tw(twlist)\n",
    "    out = np.zeros((l, w))\n",
    "\n",
    "    for i in range(w):\n",
    "        for j in range(l):\n",
    "            out[i, j] = np.mean(voxel[i, j, :])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def voxel_from_tw(twlist):\n",
    "\n",
    "    l, w = twlist[0].data.shape\n",
    "    h = len(twlist)\n",
    "    voxel = np.zeros((l, w, h))\n",
    "\n",
    "    for i in range(h):\n",
    "        voxel[:, :, i] = twlist[i].data\n",
    "\n",
    "    return voxel\n",
    "\n",
    "\n",
    "def notchfir(raw, lfreq, nfreq, hfreq):\n",
    "\n",
    "    meg_picks = mne.pick_types(raw.info, meg=True, eeg=False, eog=False)\n",
    "    raw_filtered = raw \\\n",
    "        .load_data() \\\n",
    "        .notch_filter(nfreq, meg_picks) \\\n",
    "        .filter(l_freq=lfreq, h_freq=hfreq)\n",
    "\n",
    "    return raw_filtered\n",
    "\n",
    "\n",
    "def artifacts_clean(raw):\n",
    "\n",
    "    ica = ICA(n_components=15, random_state=97)\n",
    "    ica.fit(raw)\n",
    "    ica.exclude = ica.find_bads_eog(raw)[0] + \\\n",
    "                  ica.find_bads_ecg(raw, method='correlation', threshold=3.0)[0]\n",
    "\n",
    "    ica.apply(raw)\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "def first_processing(raw):\n",
    "\n",
    "    raw_cropped = raw.crop(tmax=crop_time)\n",
    "    raw_filtered = notchfir(raw_cropped, lfreq, nfreq, hfreq)\n",
    "    raw_reconstructed = artifacts_clean(raw_filtered)\n",
    "\n",
    "    del raw_filtered\n",
    "\n",
    "    return raw_reconstructed\n",
    "\n",
    "\n",
    "def nodes_strength(label_tc):\n",
    "\n",
    "    pearson_matrices = pearson(label_tc)\n",
    "    pears_mean = mean_across_tw(pearson_matrices)\n",
    "    n_strength = np.array([])\n",
    "\n",
    "    for i in range(pears_mean.shape[0]):\n",
    "        n_strength = np.append(n_strength, np.sum(pears_mean[i, :]))\n",
    "\n",
    "    return n_strength\n",
    "\n",
    "\n",
    "def Drs_norm(Drs, Drs_max, Drs_min):\n",
    "\n",
    "    return (Drs -Drs_min)/(Drs_max - Drs_min)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE: successfully created the directory ./Pipeline \n",
      "PIPELINE: successfully created the directory ./Pipeline/B1C2 \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./Pipeline'):\n",
    "    mkdir('./Pipeline')\n",
    "\n",
    "if not os.path.exists(res_folder):\n",
    "    mkdir(res_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ./Source/Source/B1C2_ii_run1_raw_tsss_mc_art_corr_raw.fif...\n",
      "    Range : 39000 ... 1257999 =     39.000 ...  1257.999 secs\n",
      "Ready.\n",
      "Current compensation grade : 0\n",
      "Reading 0 ... 120000  =      0.000 ...   120.000 secs...\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 70 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 70.00 Hz\n",
      "- Upper transition bandwidth: 17.50 Hz (-6 dB cutoff frequency: 78.75 Hz)\n",
      "- Filter length: 3301 samples (3.301 sec)\n",
      "\n",
      "Fitting ICA to data using 366 channels (please be patient, this may take a while)\n",
      "Inferring max_pca_components from picks\n",
      "Selecting by number: 15 components\n",
      "Fitting ICA took 19.0s.\n",
      "... filtering ICA sources\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 16384 samples (16.384 sec)\n",
      "\n",
      "... filtering target\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 16384 samples (16.384 sec)\n",
      "\n",
      "... filtering ICA sources\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 16384 samples (16.384 sec)\n",
      "\n",
      "... filtering target\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 16384 samples (16.384 sec)\n",
      "\n",
      "... filtering ICA sources\n",
      "Setting up band-pass filter from 8 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 7.75 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 16.25 Hz)\n",
      "- Filter length: 16384 samples (16.384 sec)\n",
      "\n",
      "... filtering target\n",
      "Setting up band-pass filter from 8 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 7.75 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 16.25 Hz)\n",
      "- Filter length: 16384 samples (16.384 sec)\n",
      "\n",
      "Transforming to ICA space (15 components)\n",
      "Zeroing out 1 ICA component\n",
      "PIPELINE: successfully created the directory ./Pipeline/B1C2/Raw \n",
      "Writing /home/user/PycharmProjects/MNE/NodesEstimation/Pipeline/B1C2/Raw/raw.fif\n",
      "Closing /home/user/PycharmProjects/MNE/NodesEstimation/Pipeline/B1C2/Raw/raw.fif [done]\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(res_raw_file):\n",
    "    raw = mne.io.read_raw_fif(res_raw_file)\n",
    "\n",
    "elif os.path.isfile(raw_file):\n",
    "    raw = mne.io.read_raw_fif(raw_file)\n",
    "    raw = first_processing(raw)\n",
    "    path = res_raw_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    raw.save(res_raw_file)\n",
    "\n",
    "else:\n",
    "    raise OSError('PIPELINE: Raw-file not found')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-b389057533a4>:5: RuntimeWarning: This filename (./Source/Source/source_spaces_src_oct5.fif) does not conform to MNE naming conventions. All source space files should end with -src.fif, -src.fif.gz, _src.fif, _src.fif.gz, -fwd.fif, -fwd.fif.gz, _fwd.fif, _fwd.fif.gz, -inv.fif, -inv.fif.gz, _inv.fif or _inv.fif.gz\n",
      "  src = mne.read_source_spaces(src_file)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'kind'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-b389057533a4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32melif\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0msrc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmne\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_source_spaces\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mres_src_folder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-85>\u001B[0m in \u001B[0;36mread_source_spaces\u001B[0;34m(fname, patch_stats, verbose)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/MNE/lib/python3.8/site-packages/mne/source_space.py\u001B[0m in \u001B[0;36mread_source_spaces\u001B[0;34m(fname, patch_stats, verbose)\u001B[0m\n\u001B[1;32m    628\u001B[0m                                         '_inv.fif', '_inv.fif.gz'))\n\u001B[1;32m    629\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 630\u001B[0;31m     \u001B[0mff\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtree\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfiff_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    631\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mff\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfid\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    632\u001B[0m         src = _read_source_spaces_from_tree(fid, tree, patch_stats=patch_stats,\n",
      "\u001B[0;32m<decorator-gen-6>\u001B[0m in \u001B[0;36mfiff_open\u001B[0;34m(fname, preload, verbose)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/MNE/lib/python3.8/site-packages/mne/io/open.py\u001B[0m in \u001B[0;36mfiff_open\u001B[0;34m(fname, preload, verbose)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    130\u001B[0m     \u001B[0;31m#   Check that this looks like a fif file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 131\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0mtag\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkind\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mFIFF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFIFF_FILE_ID\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    132\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'file does not start with a file id tag'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'kind'"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(res_src_file):\n",
    "    src = mne.read_source_spaces(res_src_file)\n",
    "\n",
    "elif os.path.isfile(src_file):\n",
    "    src = mne.read_source_spaces(src_file)\n",
    "    path = res_src_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    src.save(res_src_file)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Source spaces not found, creating a new one...')\n",
    "    src = mne.setup_source_space(subject, spacing='ico5', add_dist='patch', subjects_dir=subject_dir)\n",
    "    path = res_src_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    src.save(res_src_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_bem_file):\n",
    "    bem = mne.read_bem_solution(res_bem_file)\n",
    "\n",
    "elif os.path.isfile(bem_file):\n",
    "    bem = mne.read_bem_solution(bem_file)\n",
    "    path = res_bem_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_bem_solution(res_bem_file, bem)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: BEM-surface not found, creating a new one...')\n",
    "    model = mne.make_bem_model(subject=subject, ico=4, conductivity=conductivity, subjects_dir=subject_dir)\n",
    "    bem = mne.make_bem_solution(model)\n",
    "    path = res_bem_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_bem_solution(res_bem_file, bem)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_fwd_file):\n",
    "    fwd = mne.read_forward_solution(res_fwd_file)\n",
    "\n",
    "elif os.path.isfile(fwd_file):\n",
    "    fwd = mne.read_forward_solution(fwd_file)\n",
    "    path = res_fwd_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_forward_solution(res_fwd_file, fwd)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Forward solution not found, creating a new one...')\n",
    "    fwd = mne.make_forward_solution(res_raw_file, trans=trans_file, src=src, bem=bem, meg=True, eeg=False,\n",
    "                                    mindist=5.0, n_jobs=1, verbose=True)\n",
    "    path = res_fwd_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_forward_solution(res_fwd_file, fwd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events = np.array([[\n",
    "        raw.first_samp + raw.time_as_index(crop_time/2 - 30)[0],\n",
    "        0,\n",
    "        1\n",
    "    ]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "raw.plot(events=events, start=0, duration=120, color='gray', event_color={1: 'r'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_epochs_file):\n",
    "    epochs = mne.read_epochs(res_epochs_file)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Epochs not found, creating a new one...')\n",
    "    epochs = mne.Epochs(raw, events, tmin=epochs_tmin, tmax=epochs_tmax,\n",
    "                        preload=True)\n",
    "    path = res_epochs_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    epochs.save(res_epochs_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_evoked_file):\n",
    "    evoked = mne.read_evokeds(res_evoked_file)\n",
    "else:\n",
    "    print('PIPELINE: Evokeds not found, creating a new one...')\n",
    "    evoked = epochs.average()\n",
    "    path = res_evoked_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_evokeds(res_evoked_file, evoked)\n",
    "\n",
    "    evoked = [evoked]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evoked[0].plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_cov_file):\n",
    "    noise_cov = mne.read_cov(res_cov_file)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Noise covariance not found, creating a new one...')\n",
    "    noise_cov = mne.compute_covariance(epochs.copy().pick_types(meg=True, eeg=False, eog=False), tmin=epochs_tmin, tmax=0,\n",
    "                                       method='empirical')\n",
    "    path = res_cov_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.write_cov(res_cov_file, noise_cov)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_inv_file):\n",
    "    inv = mne.minimum_norm.read_inverse_operator(res_inv_file)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Inverse operator not found, creating a new one...')\n",
    "    inv = mne.minimum_norm.make_inverse_operator(raw.info, fwd, noise_cov)\n",
    "    path = res_inv_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    mne.minimum_norm.write_inverse_operator(res_inv_file, inv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_sLORETA_file_lh) and os.path.isfile(res_sLORETA_file_rh):\n",
    "    stc = mne.read_source_estimate(res_sLORETA_file_lh)\n",
    "    stc.__add__(mne.read_source_estimate(res_sLORETA_file_rh))\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: sLORETA not found, creating a new one...')\n",
    "    stc = mne.minimum_norm.apply_inverse(evoked[0], inv, lambda2, 'sLORETA')\n",
    "    path = res_sLORETA_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    stc.save(res_sLORETA_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# kwargs = dict(initial_time=0.08, hemi='both', subjects_dir=subject_dir,\n",
    "#               size=(600, 600), subject=subject)\n",
    "# brain = stc.plot(figure=1, **kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = mne.read_labels_from_annot(subject, parc='aparc', subjects_dir=subject_dir)\n",
    "\n",
    "label_tc = stc.extract_label_time_course(labels, src=inv['src'], mode='mean_flip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_nodes_strength_file):\n",
    "    n_strength = np.fromfile(res_nodes_strength_file,\n",
    "                      dtype=float)\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Node strength not found, compute a new one')\n",
    "    n_strength = nodes_strength(label_tc)\n",
    "    path = res_nodes_folder\n",
    "\n",
    "    mkdir(path)\n",
    "\n",
    "    n_strength.tofile(res_nodes_strength_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nodes strength\n",
    "\n",
    "# plt.plot(n_strength, 'o')\n",
    "# plt.title('Node Strength')\n",
    "# plt.xlabel('node: number')\n",
    "# plt.ylabel('node: strength')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_strength_sorted = np.sort(n_strength)\n",
    "n_strength_sorted_rev = np.flip(n_strength_sorted)\n",
    "resected_nodes = 15\n",
    "\n",
    "Drs_max = np.sum(n_strength_sorted_rev[0:resected_nodes])/np.sum(n_strength_sorted[resected_nodes + 1:len(n_strength)-1])\n",
    "Drs_min = np.sum(n_strength_sorted[0:resected_nodes])/np.sum(n_strength_sorted[resected_nodes + 1:len(n_strength)-1])\n",
    "Drs = np.sum(n_strength[0:resected_nodes])/np.sum(n_strength_sorted[resected_nodes + 1:len(n_strength)-1])\n",
    "\n",
    "u_stat_max, p_val_max = mannwhitneyu(n_strength_sorted_rev[0:resected_nodes],\n",
    "                                 n_strength_sorted_rev[resected_nodes + 1:len(n_strength)-1])\n",
    "u_stat_min, p_val_min = mannwhitneyu(n_strength_sorted[0:resected_nodes],\n",
    "                                 n_strength_sorted[resected_nodes + 1:len(n_strength)-1])\n",
    "u_stat, p_val = mannwhitneyu(n_strength[0:resected_nodes],\n",
    "                             n_strength[resected_nodes + 1:len(n_strength)-1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Node Strength, Drs; First n values\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(n_strength[0:resected_nodes], 'o', color='m')\n",
    "ax1.set_title('removed')\n",
    "ax2.plot(n_strength[resected_nodes + 1:len(n_strength)-1], 'o', color='b')\n",
    "fig.suptitle('Node Strength, Drs = {}, u-stat = {}'.format(Drs_norm(Drs, Drs_max, Drs_min), u_stat))\n",
    "ax2.set_title('spared')\n",
    "fig.show()\n",
    "\n",
    "# Node Strength, Drs; Resected above spared\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(n_strength_sorted_rev[0:resected_nodes], 'o', color='m')\n",
    "ax1.set_title('removed')\n",
    "ax2.plot(n_strength_sorted_rev[resected_nodes + 1:len(n_strength)-1], 'o', color='b')\n",
    "fig.suptitle('Node Strength, Drs = {}, u-stat = {}'.format(Drs_norm(Drs_max, Drs_max, Drs_min), u_stat_max))\n",
    "ax2.set_title('spared')\n",
    "fig.show()\n",
    "\n",
    "# Node Strength, Drs; Spared above resected\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(n_strength_sorted[0:resected_nodes], 'o', color='m')\n",
    "ax1.set_title('removed')\n",
    "ax2.plot(n_strength_sorted[resected_nodes + 1:len(n_strength)-1], 'o', color='b')\n",
    "fig.suptitle('Node Strength, Drs = {}, u-stat = {}'.format(Drs_norm(Drs_min, Drs_max, Drs_min), u_stat_min))\n",
    "ax2.set_title('spared')\n",
    "fig.show()\n",
    "\n",
    "del n_strength_sorted, n_strength_sorted_rev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import sklearn.metrics as sm\n",
    "# arr = n_strength\n",
    "#\n",
    "# for i in range(arr.shape[0]):\n",
    "#     arr[i] = int(np.round(arr[i]))\n",
    "#\n",
    "# print(sm.roc_auc_score(arr[0:resected_nodes], arr[resected_nodes+1:], multi_class='ovo'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to show one node\n",
    "\n",
    "# coordinates = np.array([0])\n",
    "# node_str = np.zeros(coordinates.shape[0])\n",
    "# nplt.plot_markers(np.array([0, 0]), np.array([\n",
    "#     freesurf_dict['bankssts-lh'],\n",
    "#     np.array([1000, 1000, 1000]) ## plot markers does not work with one node\n",
    "# ]))\n",
    "# nplt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to show all of nodes from freesurf_dict\n",
    "\n",
    "# coord_from_dict = list(freesurf_dict.values())\n",
    "# del coord_from_dict[0], coord_from_dict[34]\n",
    "# coordinates = np.array(coord_from_dict)\n",
    "# node_str = np.zeros(coordinates.shape[0])\n",
    "# nplt.plot_markers(node_str, coordinates)\n",
    "# nplt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to show nodes in label pos coordinates\n",
    "\n",
    "arr = []\n",
    "for label in labels:\n",
    "    arr.append(label.pos.mean(axis=0)*1000)\n",
    "coordinates = np.array(arr)\n",
    "nplt.plot_markers(n_strength, coordinates, node_cmap='black_red_r')\n",
    "nplt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.isfile(res_nodes_file):\n",
    "    print('Reading nodes...')\n",
    "    nodes = pickle.load(open(res_nodes_file, 'rb'))\n",
    "\n",
    "else:\n",
    "    print('PIPELINE: Nodes file not found, create new one')\n",
    "\n",
    "    if not os.path.exists(res_nodes_folder):\n",
    "        mkdir(res_nodes_folder)\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    for i in range(len(n_strength)):\n",
    "        nodes.append(Node(n_strength[i], label_tc[i, :], labels[i]))\n",
    "\n",
    "    pickle.dump(nodes, open(res_nodes_file, 'wb'))\n",
    "\n",
    "coordinates = []\n",
    "for node in nodes:\n",
    "    coordinates.append(node.nilearn_coordinates)\n",
    "\n",
    "nplt.plot_markers(n_strength, coordinates, node_cmap='black_red_r')\n",
    "nplt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del nodes, stc, src, raw, fwd, arr, coordinates,\\\n",
    "    n_strength, bem, labels, label_tc, inv, noise_cov"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}